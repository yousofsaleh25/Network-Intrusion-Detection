{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd25dfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "sns.set_theme()\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "641dc8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = \"\"\"duration: continuous.\n",
    "protocol_type: symbolic.\n",
    "service: symbolic.\n",
    "flag: symbolic.\n",
    "src_bytes: continuous.\n",
    "dst_bytes: continuous.\n",
    "land: symbolic.\n",
    "wrong_fragment: continuous.\n",
    "urgent: continuous.\n",
    "hot: continuous.\n",
    "num_failed_logins: continuous.\n",
    "logged_in: symbolic.\n",
    "num_compromised: continuous.\n",
    "root_shell: continuous.\n",
    "su_attempted: continuous.\n",
    "num_root: continuous.\n",
    "num_file_creations: continuous.\n",
    "num_shells: continuous.\n",
    "num_access_files: continuous.\n",
    "num_outbound_cmds: continuous.\n",
    "is_host_login: symbolic.\n",
    "is_guest_login: symbolic.\n",
    "count: continuous.\n",
    "srv_count: continuous.\n",
    "serror_rate: continuous.\n",
    "srv_serror_rate: continuous.\n",
    "rerror_rate: continuous.\n",
    "srv_rerror_rate: continuous.\n",
    "same_srv_rate: continuous.\n",
    "diff_srv_rate: continuous.\n",
    "srv_diff_host_rate: continuous.\n",
    "dst_host_count: continuous.\n",
    "dst_host_srv_count: continuous.\n",
    "dst_host_same_srv_rate: continuous.\n",
    "dst_host_diff_srv_rate: continuous.\n",
    "dst_host_same_src_port_rate: continuous.\n",
    "dst_host_srv_diff_host_rate: continuous.\n",
    "dst_host_serror_rate: continuous.\n",
    "dst_host_srv_serror_rate: continuous.\n",
    "dst_host_rerror_rate: continuous.\n",
    "dst_host_srv_rerror_rate: continuous.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e1c4c82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['duration', 'protocol_type', 'service', 'flag', 'src_bytes']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = features.split(\"\\n\")\n",
    "fes = []\n",
    "for fe in f:\n",
    "    #print(fe.split(':')[0])\n",
    "    fes.append(fe.split(':')[0])\n",
    "fes[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8eed3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"kddcup/kddcup.csv\", names=fes)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6c9a61ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4898431 entries, 0 to 4898430\n",
      "Data columns (total 42 columns):\n",
      " #   Column                       Dtype  \n",
      "---  ------                       -----  \n",
      " 0   duration                     int64  \n",
      " 1   protocol_type                object \n",
      " 2   service                      object \n",
      " 3   flag                         object \n",
      " 4   src_bytes                    int64  \n",
      " 5   dst_bytes                    int64  \n",
      " 6   land                         int64  \n",
      " 7   wrong_fragment               int64  \n",
      " 8   urgent                       int64  \n",
      " 9   hot                          int64  \n",
      " 10  num_failed_logins            int64  \n",
      " 11  logged_in                    int64  \n",
      " 12  num_compromised              int64  \n",
      " 13  root_shell                   int64  \n",
      " 14  su_attempted                 int64  \n",
      " 15  num_root                     int64  \n",
      " 16  num_file_creations           int64  \n",
      " 17  num_shells                   int64  \n",
      " 18  num_access_files             int64  \n",
      " 19  num_outbound_cmds            int64  \n",
      " 20  is_host_login                int64  \n",
      " 21  is_guest_login               int64  \n",
      " 22  count                        int64  \n",
      " 23  srv_count                    int64  \n",
      " 24  serror_rate                  float64\n",
      " 25  srv_serror_rate              float64\n",
      " 26  rerror_rate                  float64\n",
      " 27  srv_rerror_rate              float64\n",
      " 28  same_srv_rate                float64\n",
      " 29  diff_srv_rate                float64\n",
      " 30  srv_diff_host_rate           float64\n",
      " 31  dst_host_count               int64  \n",
      " 32  dst_host_srv_count           int64  \n",
      " 33  dst_host_same_srv_rate       float64\n",
      " 34  dst_host_diff_srv_rate       float64\n",
      " 35  dst_host_same_src_port_rate  float64\n",
      " 36  dst_host_srv_diff_host_rate  float64\n",
      " 37  dst_host_serror_rate         float64\n",
      " 38  dst_host_srv_serror_rate     float64\n",
      " 39  dst_host_rerror_rate         float64\n",
      " 40  dst_host_srv_rerror_rate     float64\n",
      " 41                               object \n",
      "dtypes: float64(15), int64(23), object(4)\n",
      "memory usage: 1.5+ GB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "05f8a08e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_count</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.898431e+06</td>\n",
       "      <td>4.898431e+06</td>\n",
       "      <td>4.898431e+06</td>\n",
       "      <td>4.898431e+06</td>\n",
       "      <td>4.898431e+06</td>\n",
       "      <td>4.898431e+06</td>\n",
       "      <td>4.898431e+06</td>\n",
       "      <td>4.898431e+06</td>\n",
       "      <td>4.898431e+06</td>\n",
       "      <td>4.898431e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>4.898431e+06</td>\n",
       "      <td>4.898431e+06</td>\n",
       "      <td>4.898431e+06</td>\n",
       "      <td>4.898431e+06</td>\n",
       "      <td>4.898431e+06</td>\n",
       "      <td>4.898431e+06</td>\n",
       "      <td>4.898431e+06</td>\n",
       "      <td>4.898431e+06</td>\n",
       "      <td>4.898431e+06</td>\n",
       "      <td>4.898431e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.834243e+01</td>\n",
       "      <td>1.834621e+03</td>\n",
       "      <td>1.093623e+03</td>\n",
       "      <td>5.716116e-06</td>\n",
       "      <td>6.487792e-04</td>\n",
       "      <td>7.961733e-06</td>\n",
       "      <td>1.243766e-02</td>\n",
       "      <td>3.205108e-05</td>\n",
       "      <td>1.435290e-01</td>\n",
       "      <td>8.088304e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>2.329811e+02</td>\n",
       "      <td>1.892142e+02</td>\n",
       "      <td>7.537132e-01</td>\n",
       "      <td>3.071111e-02</td>\n",
       "      <td>6.050520e-01</td>\n",
       "      <td>6.464107e-03</td>\n",
       "      <td>1.780911e-01</td>\n",
       "      <td>1.778859e-01</td>\n",
       "      <td>5.792780e-02</td>\n",
       "      <td>5.765941e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.233298e+02</td>\n",
       "      <td>9.414311e+05</td>\n",
       "      <td>6.450123e+05</td>\n",
       "      <td>2.390833e-03</td>\n",
       "      <td>4.285434e-02</td>\n",
       "      <td>7.215084e-03</td>\n",
       "      <td>4.689782e-01</td>\n",
       "      <td>7.299408e-03</td>\n",
       "      <td>3.506116e-01</td>\n",
       "      <td>3.856481e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>6.402094e+01</td>\n",
       "      <td>1.059128e+02</td>\n",
       "      <td>4.111860e-01</td>\n",
       "      <td>1.085432e-01</td>\n",
       "      <td>4.809877e-01</td>\n",
       "      <td>4.125978e-02</td>\n",
       "      <td>3.818382e-01</td>\n",
       "      <td>3.821774e-01</td>\n",
       "      <td>2.309428e-01</td>\n",
       "      <td>2.309777e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.500000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.550000e+02</td>\n",
       "      <td>4.900000e+01</td>\n",
       "      <td>4.100000e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.200000e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.550000e+02</td>\n",
       "      <td>2.550000e+02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.032000e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.550000e+02</td>\n",
       "      <td>2.550000e+02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.000000e-02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.832900e+04</td>\n",
       "      <td>1.379964e+09</td>\n",
       "      <td>1.309937e+09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>1.400000e+01</td>\n",
       "      <td>7.700000e+01</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>7.479000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>2.550000e+02</td>\n",
       "      <td>2.550000e+02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           duration     src_bytes     dst_bytes          land  wrong_fragment  \\\n",
       "count  4.898431e+06  4.898431e+06  4.898431e+06  4.898431e+06    4.898431e+06   \n",
       "mean   4.834243e+01  1.834621e+03  1.093623e+03  5.716116e-06    6.487792e-04   \n",
       "std    7.233298e+02  9.414311e+05  6.450123e+05  2.390833e-03    4.285434e-02   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00    0.000000e+00   \n",
       "25%    0.000000e+00  4.500000e+01  0.000000e+00  0.000000e+00    0.000000e+00   \n",
       "50%    0.000000e+00  5.200000e+02  0.000000e+00  0.000000e+00    0.000000e+00   \n",
       "75%    0.000000e+00  1.032000e+03  0.000000e+00  0.000000e+00    0.000000e+00   \n",
       "max    5.832900e+04  1.379964e+09  1.309937e+09  1.000000e+00    3.000000e+00   \n",
       "\n",
       "             urgent           hot  num_failed_logins     logged_in  \\\n",
       "count  4.898431e+06  4.898431e+06       4.898431e+06  4.898431e+06   \n",
       "mean   7.961733e-06  1.243766e-02       3.205108e-05  1.435290e-01   \n",
       "std    7.215084e-03  4.689782e-01       7.299408e-03  3.506116e-01   \n",
       "min    0.000000e+00  0.000000e+00       0.000000e+00  0.000000e+00   \n",
       "25%    0.000000e+00  0.000000e+00       0.000000e+00  0.000000e+00   \n",
       "50%    0.000000e+00  0.000000e+00       0.000000e+00  0.000000e+00   \n",
       "75%    0.000000e+00  0.000000e+00       0.000000e+00  0.000000e+00   \n",
       "max    1.400000e+01  7.700000e+01       5.000000e+00  1.000000e+00   \n",
       "\n",
       "       num_compromised  ...  dst_host_count  dst_host_srv_count  \\\n",
       "count     4.898431e+06  ...    4.898431e+06        4.898431e+06   \n",
       "mean      8.088304e-03  ...    2.329811e+02        1.892142e+02   \n",
       "std       3.856481e+00  ...    6.402094e+01        1.059128e+02   \n",
       "min       0.000000e+00  ...    0.000000e+00        0.000000e+00   \n",
       "25%       0.000000e+00  ...    2.550000e+02        4.900000e+01   \n",
       "50%       0.000000e+00  ...    2.550000e+02        2.550000e+02   \n",
       "75%       0.000000e+00  ...    2.550000e+02        2.550000e+02   \n",
       "max       7.479000e+03  ...    2.550000e+02        2.550000e+02   \n",
       "\n",
       "       dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
       "count            4.898431e+06            4.898431e+06   \n",
       "mean             7.537132e-01            3.071111e-02   \n",
       "std              4.111860e-01            1.085432e-01   \n",
       "min              0.000000e+00            0.000000e+00   \n",
       "25%              4.100000e-01            0.000000e+00   \n",
       "50%              1.000000e+00            0.000000e+00   \n",
       "75%              1.000000e+00            4.000000e-02   \n",
       "max              1.000000e+00            1.000000e+00   \n",
       "\n",
       "       dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
       "count                 4.898431e+06                 4.898431e+06   \n",
       "mean                  6.050520e-01                 6.464107e-03   \n",
       "std                   4.809877e-01                 4.125978e-02   \n",
       "min                   0.000000e+00                 0.000000e+00   \n",
       "25%                   0.000000e+00                 0.000000e+00   \n",
       "50%                   1.000000e+00                 0.000000e+00   \n",
       "75%                   1.000000e+00                 0.000000e+00   \n",
       "max                   1.000000e+00                 1.000000e+00   \n",
       "\n",
       "       dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
       "count          4.898431e+06              4.898431e+06          4.898431e+06   \n",
       "mean           1.780911e-01              1.778859e-01          5.792780e-02   \n",
       "std            3.818382e-01              3.821774e-01          2.309428e-01   \n",
       "min            0.000000e+00              0.000000e+00          0.000000e+00   \n",
       "25%            0.000000e+00              0.000000e+00          0.000000e+00   \n",
       "50%            0.000000e+00              0.000000e+00          0.000000e+00   \n",
       "75%            0.000000e+00              0.000000e+00          0.000000e+00   \n",
       "max            1.000000e+00              1.000000e+00          1.000000e+00   \n",
       "\n",
       "       dst_host_srv_rerror_rate  \n",
       "count              4.898431e+06  \n",
       "mean               5.765941e-02  \n",
       "std                2.309777e-01  \n",
       "min                0.000000e+00  \n",
       "25%                0.000000e+00  \n",
       "50%                0.000000e+00  \n",
       "75%                0.000000e+00  \n",
       "max                1.000000e+00  \n",
       "\n",
       "[8 rows x 38 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1f6759c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 842.4x595.44 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['label'] = data[\"\"]\n",
    "data.drop(axis=1, columns=[\"\"])\n",
    "data['label'].value_counts().plot(kind='bar')\n",
    "plt.title(\"Target Label Distribution\", fontsize=15)\n",
    "plt.xlabel(\"Target Labels\", fontsize=13)\n",
    "plt.ylabel(\"Instances/label\", fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "08b6b6d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e71f53e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a60ddd6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 842.4x595.44 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['label'].value_counts().plot(kind='bar')\n",
    "plt.title(\"Target Label Distribution\", fontsize=15)\n",
    "plt.xlabel(\"Target Labels\", fontsize=13)\n",
    "plt.ylabel(\"Instances/label\", fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d58144de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['normal.', 'buffer_overflow.', 'loadmodule.', 'perl.', 'neptune.',\n",
       "       'smurf.', 'guess_passwd.', 'pod.', 'teardrop.', 'portsweep.',\n",
       "       'ipsweep.', 'land.', 'ftp_write.', 'back.', 'imap.', 'satan.',\n",
       "       'phf.', 'nmap.', 'multihop.', 'warezmaster.', 'warezclient.',\n",
       "       'spy.', 'rootkit.'], dtype=object)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8c27b2fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>215</td>\n",
       "      <td>45076</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "      <td>normal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>162</td>\n",
       "      <td>4528</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "      <td>normal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>236</td>\n",
       "      <td>1228</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "      <td>normal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>233</td>\n",
       "      <td>2032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "      <td>normal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>239</td>\n",
       "      <td>486</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "      <td>normal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4898426</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>212</td>\n",
       "      <td>2288</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "      <td>normal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4898427</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>219</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "      <td>normal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4898428</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>218</td>\n",
       "      <td>3610</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "      <td>normal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4898429</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>219</td>\n",
       "      <td>1234</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "      <td>normal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4898430</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>219</td>\n",
       "      <td>1098</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "      <td>normal.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1074992 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         duration protocol_type service flag  src_bytes  dst_bytes  land  \\\n",
       "0               0           tcp    http   SF        215      45076     0   \n",
       "1               0           tcp    http   SF        162       4528     0   \n",
       "2               0           tcp    http   SF        236       1228     0   \n",
       "3               0           tcp    http   SF        233       2032     0   \n",
       "4               0           tcp    http   SF        239        486     0   \n",
       "...           ...           ...     ...  ...        ...        ...   ...   \n",
       "4898426         0           tcp    http   SF        212       2288     0   \n",
       "4898427         0           tcp    http   SF        219        236     0   \n",
       "4898428         0           tcp    http   SF        218       3610     0   \n",
       "4898429         0           tcp    http   SF        219       1234     0   \n",
       "4898430         0           tcp    http   SF        219       1098     0   \n",
       "\n",
       "         wrong_fragment  urgent  hot  ...  dst_host_same_srv_rate  \\\n",
       "0                     0       0    0  ...                     0.0   \n",
       "1                     0       0    0  ...                     1.0   \n",
       "2                     0       0    0  ...                     1.0   \n",
       "3                     0       0    0  ...                     1.0   \n",
       "4                     0       0    0  ...                     1.0   \n",
       "...                 ...     ...  ...  ...                     ...   \n",
       "4898426               0       0    0  ...                     1.0   \n",
       "4898427               0       0    0  ...                     1.0   \n",
       "4898428               0       0    0  ...                     1.0   \n",
       "4898429               0       0    0  ...                     1.0   \n",
       "4898430               0       0    0  ...                     1.0   \n",
       "\n",
       "         dst_host_diff_srv_rate  dst_host_same_src_port_rate  \\\n",
       "0                           0.0                         0.00   \n",
       "1                           0.0                         1.00   \n",
       "2                           0.0                         0.50   \n",
       "3                           0.0                         0.33   \n",
       "4                           0.0                         0.25   \n",
       "...                         ...                          ...   \n",
       "4898426                     0.0                         0.33   \n",
       "4898427                     0.0                         0.25   \n",
       "4898428                     0.0                         0.20   \n",
       "4898429                     0.0                         0.17   \n",
       "4898430                     0.0                         0.14   \n",
       "\n",
       "         dst_host_srv_diff_host_rate  dst_host_serror_rate  \\\n",
       "0                               0.00                   0.0   \n",
       "1                               0.00                   0.0   \n",
       "2                               0.00                   0.0   \n",
       "3                               0.00                   0.0   \n",
       "4                               0.00                   0.0   \n",
       "...                              ...                   ...   \n",
       "4898426                         0.05                   0.0   \n",
       "4898427                         0.05                   0.0   \n",
       "4898428                         0.05                   0.0   \n",
       "4898429                         0.05                   0.0   \n",
       "4898430                         0.05                   0.0   \n",
       "\n",
       "         dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
       "0                            0.00                   0.0   \n",
       "1                            0.00                   0.0   \n",
       "2                            0.00                   0.0   \n",
       "3                            0.00                   0.0   \n",
       "4                            0.00                   0.0   \n",
       "...                           ...                   ...   \n",
       "4898426                      0.01                   0.0   \n",
       "4898427                      0.01                   0.0   \n",
       "4898428                      0.01                   0.0   \n",
       "4898429                      0.01                   0.0   \n",
       "4898430                      0.01                   0.0   \n",
       "\n",
       "         dst_host_srv_rerror_rate             label  \n",
       "0                             0.0  normal.  normal.  \n",
       "1                             0.0  normal.  normal.  \n",
       "2                             0.0  normal.  normal.  \n",
       "3                             0.0  normal.  normal.  \n",
       "4                             0.0  normal.  normal.  \n",
       "...                           ...      ...      ...  \n",
       "4898426                       0.0  normal.  normal.  \n",
       "4898427                       0.0  normal.  normal.  \n",
       "4898428                       0.0  normal.  normal.  \n",
       "4898429                       0.0  normal.  normal.  \n",
       "4898430                       0.0  normal.  normal.  \n",
       "\n",
       "[1074992 rows x 43 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "d6fa40e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = d.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "2798ae5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>215</td>\n",
       "      <td>45076</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "      <td>normal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>162</td>\n",
       "      <td>4528</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "      <td>normal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>236</td>\n",
       "      <td>1228</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "      <td>normal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>233</td>\n",
       "      <td>2032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "      <td>normal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>239</td>\n",
       "      <td>486</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "      <td>normal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4898426</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>212</td>\n",
       "      <td>2288</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "      <td>normal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4898427</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>219</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "      <td>normal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4898428</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>218</td>\n",
       "      <td>3610</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "      <td>normal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4898429</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>219</td>\n",
       "      <td>1234</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "      <td>normal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4898430</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>219</td>\n",
       "      <td>1098</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "      <td>normal.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1074992 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         duration protocol_type service flag  src_bytes  dst_bytes  land  \\\n",
       "0               0           tcp    http   SF        215      45076     0   \n",
       "1               0           tcp    http   SF        162       4528     0   \n",
       "2               0           tcp    http   SF        236       1228     0   \n",
       "3               0           tcp    http   SF        233       2032     0   \n",
       "4               0           tcp    http   SF        239        486     0   \n",
       "...           ...           ...     ...  ...        ...        ...   ...   \n",
       "4898426         0           tcp    http   SF        212       2288     0   \n",
       "4898427         0           tcp    http   SF        219        236     0   \n",
       "4898428         0           tcp    http   SF        218       3610     0   \n",
       "4898429         0           tcp    http   SF        219       1234     0   \n",
       "4898430         0           tcp    http   SF        219       1098     0   \n",
       "\n",
       "         wrong_fragment  urgent  hot  ...  dst_host_same_srv_rate  \\\n",
       "0                     0       0    0  ...                     0.0   \n",
       "1                     0       0    0  ...                     1.0   \n",
       "2                     0       0    0  ...                     1.0   \n",
       "3                     0       0    0  ...                     1.0   \n",
       "4                     0       0    0  ...                     1.0   \n",
       "...                 ...     ...  ...  ...                     ...   \n",
       "4898426               0       0    0  ...                     1.0   \n",
       "4898427               0       0    0  ...                     1.0   \n",
       "4898428               0       0    0  ...                     1.0   \n",
       "4898429               0       0    0  ...                     1.0   \n",
       "4898430               0       0    0  ...                     1.0   \n",
       "\n",
       "         dst_host_diff_srv_rate  dst_host_same_src_port_rate  \\\n",
       "0                           0.0                         0.00   \n",
       "1                           0.0                         1.00   \n",
       "2                           0.0                         0.50   \n",
       "3                           0.0                         0.33   \n",
       "4                           0.0                         0.25   \n",
       "...                         ...                          ...   \n",
       "4898426                     0.0                         0.33   \n",
       "4898427                     0.0                         0.25   \n",
       "4898428                     0.0                         0.20   \n",
       "4898429                     0.0                         0.17   \n",
       "4898430                     0.0                         0.14   \n",
       "\n",
       "         dst_host_srv_diff_host_rate  dst_host_serror_rate  \\\n",
       "0                               0.00                   0.0   \n",
       "1                               0.00                   0.0   \n",
       "2                               0.00                   0.0   \n",
       "3                               0.00                   0.0   \n",
       "4                               0.00                   0.0   \n",
       "...                              ...                   ...   \n",
       "4898426                         0.05                   0.0   \n",
       "4898427                         0.05                   0.0   \n",
       "4898428                         0.05                   0.0   \n",
       "4898429                         0.05                   0.0   \n",
       "4898430                         0.05                   0.0   \n",
       "\n",
       "         dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
       "0                            0.00                   0.0   \n",
       "1                            0.00                   0.0   \n",
       "2                            0.00                   0.0   \n",
       "3                            0.00                   0.0   \n",
       "4                            0.00                   0.0   \n",
       "...                           ...                   ...   \n",
       "4898426                      0.01                   0.0   \n",
       "4898427                      0.01                   0.0   \n",
       "4898428                      0.01                   0.0   \n",
       "4898429                      0.01                   0.0   \n",
       "4898430                      0.01                   0.0   \n",
       "\n",
       "         dst_host_srv_rerror_rate             label  \n",
       "0                             0.0  normal.  normal.  \n",
       "1                             0.0  normal.  normal.  \n",
       "2                             0.0  normal.  normal.  \n",
       "3                             0.0  normal.  normal.  \n",
       "4                             0.0  normal.  normal.  \n",
       "...                           ...      ...      ...  \n",
       "4898426                       0.0  normal.  normal.  \n",
       "4898427                       0.0  normal.  normal.  \n",
       "4898428                       0.0  normal.  normal.  \n",
       "4898429                       0.0  normal.  normal.  \n",
       "4898430                       0.0  normal.  normal.  \n",
       "\n",
       "[1074992 rows x 43 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "736638a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          True\n",
       "1          True\n",
       "2          True\n",
       "3          True\n",
       "4          True\n",
       "           ... \n",
       "4898426    True\n",
       "4898427    True\n",
       "4898428    True\n",
       "4898429    True\n",
       "4898430    True\n",
       "Name: label, Length: 1074992, dtype: bool"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'] == 'normal.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "f89ca764",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\envs\\py\\lib\\site-packages\\pandas\\core\\indexing.py:1817: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    }
   ],
   "source": [
    "data[data['label'] == 'normal.'].loc[:, 'label'] = 'norm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "88cec1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data['label'].unique()\n",
    "for l in labels:\n",
    "    if l == 'normal.':\n",
    "        condition = data['label'] == 'normal.'\n",
    "        data['label'] = np.where(condition,\n",
    "                                 \"Normal\", data['label'])\n",
    "    else:\n",
    "        condition = data['label'] == l\n",
    "        data['label'] = np.where(condition,\n",
    "                                 \"Attack\", data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "a2d34e0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtkAAAIeCAYAAABuoBOSAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABJR0lEQVR4nO3de1zUdb7H8ffgDGhCGu6M98jMLNdMa0ztAmqb3ERTszVJTltptpuaaxghilQeL4u3LrjVtlborumm4AWw1kJXLVOzvKSdFpVVUS6C4qBynfOHj+Yc8hLqbxjQ1/Px4NHM93f7/Mbm59svn/mNyel0OgUAAADAMF6eLgAAAAC41hCyAQAAAIMRsgEAAACDEbIBAAAAgxGyAQAAAIMRsgEAAACDEbIBXBdiYmLUsWPHi/707dvXI3VVVFTogw8+uOjyw4cPq2PHjtq2bdsVH2PEiBGaNGnSFW8vSR07dlRqauoFly1fvrzaa3nnnXfKbrcrKipKmzZtuuJajh49qjVr1lxynf+/v+XLl6tTp0412vfFnDlzRosXL3Y9f/PNN/XII49c1T4BXJ/Mni4AAGrDpEmTNGHCBEnnwtvQoUOVlJSkLl26SJIaNGjgkbrS0tI0ffp0PfXUUx45vlEaNGig9evXS5IqKytVUFCgv//973r22Wf11ltv6eGHH5Z0LrSazTX7qyc2NlbNmzdXeHj4Rde5nP3VxAcffKBly5YpMjJSkvT000+7HgPA5SBkA7gu+Pn5yc/PT5JUWloqSWrSpImsVqsny9K19H1g//+1bNGihaZNm6bCwkK99tprCgwMlMViUdOmTWu8v5q8Npezvys5ZuPGjdW4cWNDjwHg+kC7CABIqqqqUlJSkvr166fOnTvLbrdrzJgxKiwslCRt2bJFd911l5KSknTfffdpxIgRkqTvvvtOw4YNU5cuXRQaGqply5apY8eOOnz4sCSprKxMM2bM0IMPPqh77rlHTz75pL799lvXPidOnCjpXDvG8uXLr6j2ffv2aeTIkbLb7ercubOCg4OVkpJSbR2Hw6GxY8eqS5cu6t2793ktKtu2bXOdx8MPP6zZs2e7/jFyNaKionT06FF98803kqq3d5w+fVqvvPKK7r//ft111116/PHH9eWXX0o6197z5ZdfasWKFerYsaNr2ylTpmjw4MHq3r27Pv/88wu2nyxevFgPPvigunXrphdffNH1ZyhduO3lp7Hly5dr/vz5OnLkiDp27KgtW7ac1y6Sk5Oj8ePHq2fPnurWrZt+//vf69ChQ67lffv21V//+leNHj1ad999tx544AG99dZbV/06Aqh/CNkAIGnhwoX66KOPFBcXp7Vr12r27Nnavn27FixY4FqnrKxMW7Zs0bJlyxQXF6fc3Fz97ne/02233aYVK1Zo3LhxSkxMrLbfiRMnauvWrZo3b54++eQT9ezZUyNGjNCBAwfUrVs3TZkyRZK0ceNGhYWFXXbdp0+f1tNPPy2bzaalS5cqNTVV3bt3V1xcnAoKClzrZWRkqE2bNkpJSdHo0aOVmJiojIwMSdLevXv1zDPP6JFHHtGqVav0+uuv64svvtDUqVOv4JWs7qeA/D//8z/nLXvjjTf073//W++//77S0tJ055136oUXXtDp06c1adIk2e12hYaGauPGja5tli1bplGjRik5OVn33XffefusrKzUJ598oqSkJL3//vv68ccf9corr9So1rCwMI0cOVItWrTQxo0b1a1bt2rLHQ6HnnjiCZ08eVLvv/++kpOTderUKT355JM6deqUa7358+erT58+Wr16tZ566im9+eabV9VTD6B+ImQDgKR27dpp5syZCgwMVOvWrRUUFKSHHnrovHD47LPPKiAgQB07dtTHH3+sm266SQkJCWrfvr1CQkI0ZswY17rZ2dlKT0/XjBkzZLfb1a5dO73wwguy2+1auHChvL295evrK+lcq0XDhg0vu+4zZ87oqaeeUlxcnG699Va1b99ezz33nMrLy3Xw4EHXenfffbcmTpyoW2+9VcOGDVNERIQ+/PBDSdL777+voKAgPfPMMwoICFCvXr2UkJCg5cuXKy8v7wpezf9z4403SjoXUH8uOztbjRs3Vps2bdS2bVu9/PLLevPNN9WgQQP5+fnJYrGoYcOG1dpQunTpopCQEN1xxx2u1+7n/vSnP6lLly665557FB8fr8zMTGVnZ/9irQ0bNtQNN9ygBg0ayGq1ytvbu9ry1NRUFRcXa86cOfr1r3+tzp07a/78+Tp58qRWrlzpWq9Pnz767W9/q7Zt22rkyJG68cYbXb+9AHD9oCcbAHTu1/w7duzQ3LlzdeDAAe3fv19ZWVmy2+3V1mvbtq3r8ffff6+77rqr2ocm77333mrLJenxxx+vto+ysjKVlZUZUnezZs00fPhwpaSkaO/evTp48KD27dsn6dys7k9+PivbuXNnffbZZ5LOzWRnZ2dXW+en3uSsrCzZbLYrru+ncP1T2P7/nnnmGf3+979Xr1691K1bNz300EMaMGCAfHx8Lrq/Nm3aXPJ4TZo0Ufv27V3PO3fuLEn68ccfFRAQcCWn4PLjjz+qXbt21frA/f391b59+2r/GLvllluqbefn56fy8vKrOjaA+oeQDQCSkpKS9N5772nw4MF66KGH9Nxzz+mjjz5STk5OtfX+/2xzgwYNVFVVddF9WiwWSdKSJUvOm6X++SzplcrNzdWwYcPUvHlz9enTR71795bNZtOQIUOqreflVf0Xl06n01WDxWLRo48+qpEjR563/6v9YOhP/9C48847z1tmt9u1fv16bdy4URs3btTixYu1YMECLV26VB06dLjg/n5ptv9C5yn935/Fz1VUVPziOfzSsauqqqrt/0J/ttfSB1wB1AztIgAg6b333tPYsWM1efJkDR06VL/+9a+VnZ19yXDUsWNH7dmzp9qM8Xfffed6/FNQPH78uAICAlw/H3zwgdatWydJMplMV1X3mjVrVFJSosWLF+u5555T3759VVRUJKl6sNu7d2+17b755hvddtttkqTbbrtNWVlZ1WosLCzUzJkzVVJSclX1/e1vf1Pbtm3Pm0mXpLfeekvffPONHnnkESUkJOjTTz+VxWJRZmampCt7bU6cOKGjR4+6nn/zzTcymUyuc7VYLNVaV37eRnKpY7Zv314HDhzQiRMnXGOFhYU6cOBAtdlzAJAI2QAgSWrZsqU2btyorKws/fjjj3r11Ve1Y8eOS7Z1DB8+XIWFhUpISFBWVpbWrVun+fPnSzoX1gICAhQWFqbJkydr/fr1+s9//qO5c+dqyZIlrlD20+3hdu3adclAu3PnTm3YsKHaz8GDB9WiRQs5HA6tXbtWR44c0bp16xQfHy9J1WrfsmWL3njjDe3fv18ffPCB0tPT9fzzz0uSRo4cqZ07d2r69OnKysrS119/rZdfflmnTp26rJns/Px85efnKzc3V7t27dKUKVP0+eefKz4+/oLh9ciRI0pISNCWLVt05MgRrVy5UqdOndLdd9/tem0OHz6sI0eO1LgGk8mk8ePHa9euXdqyZYteffVVRUREqHXr1pKkrl27aunSpdq3b5/27Nmj+Pj4ajPPjRs31smTJ7V///7z7q4yYMAA+fv7649//KP27NmjPXv26I9//KNuvPHGS97LG8D1iXYRAJA0c+ZMvfrqqxo0aJBuvPFG3XfffZowYYL+/Oc/68yZMxfc5le/+pXeffdd/fd//7cGDhyogIAADR8+XG+99ZarfeD111/X7NmzFRsbq1OnTql9+/Z688031atXL0lSjx49dN999+mJJ57QhAkT9Lvf/e6i9f3c6NGj9eKLL2rXrl16/fXXdfr0ad188836/e9/r3fffVe7du1SYGCgJOm3v/2tvv/+e7333ntq0aKFZsyY4aqhY8eOeueddzR//nz97W9/k5+fn/r06eO6vWBNVFZW6sEHH5R0ro2mWbNm6tKlixYtWqR77rnngtvExcVp5syZmjBhgk6cOKGAgABNnz7dddeQyMhIvfTSSwoLC9M///nPGtVhtVr1yCOP6Nlnn1VFRYVCQ0MVGxvrWj516lRNnTpVQ4cOlc1m07hx45Sbm+taHhwcrH/84x8aMGCAZs+eXW3fPj4+ev/99zVjxgw9+eSTatCggXr16qXFixdfsOccwPXN5KRRDACuyL///W+dOnWqWivEmjVrFBMTox07dhj6TYQAgPqFdhEAuEJHjx5VVFSU0tLSlJOTo6+//lpvvPGGwsLCCNgAcJ1jJhsArsKiRYuUnJysnJwcNW3aVKGhoRo/frwaNWrk6dIAAB5EyAYAAAAMRrsIAAAAYDBCNgAAAGAwQjYAAABgMD7+fglFRSWqqqJlHZ7VrJmvjh93/PKKAHCd4LqIusDLy6Sbbmp80eWE7EuoqnISslEn8P8hAFTHdRF1He0iAAAAgMEI2QAAAIDBCNkAAACAwQjZAAAAgMEI2QAAAIDBCNkAAACAwQjZAAAAgMEI2QAAAIDBCNkAAACAwQjZAAAAgMEI2QAAAIDBCNkAAACAwQjZAAAAgMEI2QAAAIDBCNkAAACAwQjZAAAAgMEI2QAAAIDBCNkAAACAwcyeLgDXLr8bG6mhD/+LGcFq9fN0CfXa2dIKnSo+4+kyAADXERIQ3Kahj1kRE1I9XQagVbMH6pSniwAAXFdoFwEAAAAMVishOzU1VeHh4QoPD9fMmTMlSXv37tWQIUMUHBysSZMmqaKiQpKUk5OjyMhIhYSE6Pnnn1dJSYkkqbi4WKNGjVJoaKgiIyOVn58vSSorK1N0dLRCQ0M1aNAgZWVlSZKcTqdmzpypkJAQhYWFafv27bVxqgAAAID7Q/aZM2c0bdo0JScnKzU1Vdu2bdPmzZsVHR2tyZMna+3atXI6nVq6dKkkKSEhQcOHD1dGRoY6d+6spKQkSdK8efNkt9uVnp6uoUOHatq0aZKk5ORkNWrUSOnp6YqNjVVMTIwkae3atcrKylJaWprefvttxcTEuII8AAAA4E5uD9mVlZWqqqrSmTNnVFFRoYqKCpnNZp09e1Zdu3aVJA0ePFgZGRkqLy/X1q1bFRwcXG1ckjIzMxURESFJ6t+/vzZs2KDy8nJlZmZqwIABkqTu3burqKhIOTk5Wr9+vcLCwuTl5aV27dqpVatW2rFjh7tPFwAAAHD/Bx99fX01btw4hYaGqmHDhrrvvvtksVhktVpd61itVuXm5qqoqEi+vr4ym83VxiUpLy/PtY3ZbJavr68KCwurjf+0zbFjx5SXlyebzXbeOAAAAOBubg/Z+/bt0yeffKIvvvhCfn5+eumll7Rp06bz1jOZTHI6nRccvxgvrwtPxHt5eV1wXxdb/2KaNfO9rPUB1F3cBhG4tvCeRl3n9pC9ceNG9erVS82aNZN0rgXk/fffV0FBgWud/Px82Ww2+fv7y+FwqLKyUg0aNHCNS5LNZlNBQYFatGihiooKORwONW3aVDabTfn5+QoICKi2r+bNm7s+HPn/xy/H8eMOVVWdH9ZRM1wAUZfk53MTP+BaYbX68Z6Gx3l5mS45Iev2nuw77rhDmzdv1unTp+V0OvX555/rvvvuk4+Pj+uOHykpKQoMDJTFYpHdbldaWlq1cUkKCgpSSkqKJCktLU12u10Wi0VBQUFKTT13L+Zt27bJx8dHrVq1UmBgoFatWqXKykplZ2fr4MGDuuuuu9x9ugAAAIBMzgv1VRjs3Xff1fLly2WxWHTXXXcpPj5eBw4cUFxcnEpKStSpUydNnz5d3t7eOnLkiGJiYnT8+HG1bNlSc+bMUZMmTXTixAnFxMTo0KFD8vPzU2Jiotq0aaPS0lJNmTJFu3fvlre3t15//XX9+te/ltPp1KxZs7RhwwZJ0iuvvKIHH3zwsupmJvvqWK1+fBkN6oRVswcy6wVcQ5jJRl3wSzPZtRKy6ytC9tUhZKOuIGQD1xZCNuoCj7eLAAAAANcbQjYAAABgMEI2AAAAYDBCNgAAAGAwQjYAAABgMEI2AAAAYDBCNgAAAGAwQjYAAABgMEI2AAAAYDBCNgAAAGAwQjYAAABgMEI2AAAAYDBCNgAAAGAwQjYAAABgMEI2AAAAYDBCNgAAAGAwQjYAAABgMEI2AAAAYDBCNgAAAGAwQjYAAABgMEI2AAAAYDBCNgAAAGAwQjYAAABgMEI2AAAAYDBCNgAAAGAwQjYAAABgMEI2AAAAYDBCNgAAAGAwQjYAAABgMEI2AAAAYDBCNgAAAGAwQjYAAABgMEI2AAAAYDBCNgAAAGAwQjYAAABgMEI2AAAAYDBCNgAAAGAwQjYAAABgMEI2AAAAYDBCNgAAAGAwQjYAAABgMEI2AAAAYDBCNgAAAGAwQjYAAABgMLO7D7Bs2TItWrTI9fzw4cMaOHCgfvOb32j69OkqLS1VaGioxo8fL0nau3ev4uLi5HA4ZLfblZCQILPZrJycHEVHR+v48eNq166dEhMT1bhxYxUXF+ull17SoUOH5O/vr3nz5slqtaqsrEyTJk3S7t271bBhQyUmJqp9+/buPl0AAADA/TPZQ4cOVWpqqlJTU5WYmKhmzZpp5MiRio2NVVJSktLS0rR7926tX79ekhQdHa3Jkydr7dq1cjqdWrp0qSQpISFBw4cPV0ZGhjp37qykpCRJ0rx582S325Wenq6hQ4dq2rRpkqTk5GQ1atRI6enpio2NVUxMjLtPFQAAAJBUy+0iU6dO1fjx43Xo0CEFBASobdu2MpvNioiIUEZGho4cOaKzZ8+qa9eukqTBgwcrIyND5eXl2rp1q4KDg6uNS1JmZqYiIiIkSf3799eGDRtUXl6uzMxMDRgwQJLUvXt3FRUVKScnpzZPFwAAANcpt7eL/GTz5s06e/asQkNDtXr1almtVtcym82m3Nxc5eXlVRu3Wq3Kzc1VUVGRfH19ZTabq41LqraN2WyWr6+vCgsLL7ivY8eOqVWrVjWuuVkz36s6ZwB1h9Xq5+kSABiI9zTquloL2UuWLNHvfvc7SZLT6Txvuclkuuzxi/HyuvAE/cXGL+b4cYeqqs4/NmqGCyDqkvz8U54uAYBBrFY/3tPwOC8v0yUnZGulXaSsrExbt25V3759JUnNmzdXQUGBa3leXp5sNtt54/n5+bLZbPL395fD4VBlZWW1cencLPhP21RUVMjhcKhp06ay2WzKz88/b18AAACAu9VKyP7hhx90yy236IYbbpAk3X333Tpw4ICys7NVWVmp1atXKzAwUK1bt5aPj4+2b98uSUpJSVFgYKAsFovsdrvS0tKqjUtSUFCQUlJSJElpaWmy2+2yWCwKCgpSamqqJGnbtm3y8fG5rFYRAAAA4ErVSrvIoUOH1KJFC9dzHx8fzZgxQ2PGjFFpaamCgoIUEhIiSUpMTFRcXJxKSkrUqVMnRUVFSZLi4+MVExOjBQsWqGXLlpozZ44kady4cYqJiVF4eLj8/PyUmJgoSRoxYoSmTJmi8PBweXt7a9asWbVxqgAAAIBMzgs1PEMSPdlXy2r1U8SEVE+XAWjV7IH0bwLXEHqyURfUiZ5sAAAA4HpCyAYAAAAMRsgGAAAADEbIBgAAAAxGyAYAAAAMRsgGAAAADEbIBgAAAAxGyAYAAAAMRsgGAAAADEbIBgAAAAxGyAYAAAAMRsgGAAAADEbIBgAAAAxGyAYAAAAMRsgGAAAADEbIBgAAAAxGyAYAAAAMRsgGAAAADEbIBgAAAAxGyAYAAAAMRsgGAAAADEbIBgAAAAxGyAYAAAAMRsgGAAAADEbIBgAAAAxGyAYAAAAMRsgGAAAADEbIBgAAAAxGyAYAAAAMRsgGAAAADEbIBgAAAAxGyAYAAAAMRsgGAAAADEbIBgAAAAxGyAYAAAAMRsgGAAAADEbIBgAAAAxGyAYAAAAMRsgGAAAADEbIBgAAAAxGyAYAAAAMRsgGAAAADEbIBgAAAAxGyAYAAAAMVish+/PPP9fgwYMVEhKi119/XZK0efNmRUREqF+/fpo7d65r3b1792rIkCEKDg7WpEmTVFFRIUnKyclRZGSkQkJC9Pzzz6ukpESSVFxcrFGjRik0NFSRkZHKz8+XJJWVlSk6OlqhoaEaNGiQsrKyauNUAQAAAPeH7EOHDik+Pl5JSUlatWqVvv/+e61fv16xsbFKSkpSWlqadu/erfXr10uSoqOjNXnyZK1du1ZOp1NLly6VJCUkJGj48OHKyMhQ586dlZSUJEmaN2+e7Ha70tPTNXToUE2bNk2SlJycrEaNGik9PV2xsbGKiYlx96kCAAAAkmohZH/22WcKCwtTixYtZLFYNHfuXDVq1EgBAQFq27atzGazIiIilJGRoSNHjujs2bPq2rWrJGnw4MHKyMhQeXm5tm7dquDg4GrjkpSZmamIiAhJUv/+/bVhwwaVl5crMzNTAwYMkCR1795dRUVFysnJcffpAgAAADK7+wDZ2dmyWCx65plnlJ+frz59+qhDhw6yWq2udWw2m3Jzc5WXl1dt3Gq1Kjc3V0VFRfL19ZXZbK42LqnaNmazWb6+viosLLzgvo4dO6ZWrVrVuPZmzXyv6twB1B1Wq5+nSwBgIN7TqOvcHrIrKyu1bds2JScn64YbbtDvf/97NWrU6Lz1TCaTnE7nZY1fjJfXhSfoLzZ+McePO1RVdf6xUTNcAFGX5Oef8nQJAAxitfrxnobHeXmZLjkh6/Z2kV/96lfq1auX/P391bBhQz388MPatGmTCgoKXOvk5eXJZrOpefPm1cbz8/Nls9nk7+8vh8OhysrKauPSuVnwn7apqKiQw+FQ06ZNZbPZXB+C/Pk2AAAAgDu5PWT36dNHGzduVHFxsSorK/Wvf/1LISEhOnDggLKzs1VZWanVq1crMDBQrVu3lo+Pj7Zv3y5JSklJUWBgoCwWi+x2u9LS0qqNS1JQUJBSUlIkSWlpabLb7bJYLAoKClJqaqokadu2bfLx8bmsVhEAAADgSpmcF+rFMNg//vEPffDBByovL9cDDzyguLg4bdmyRdOnT1dpaamCgoL0yiuvyGQyad++fYqLi1NJSYk6deqk6dOny9vbW0eOHFFMTIyOHz+uli1bas6cOWrSpIlOnDihmJgYHTp0SH5+fkpMTFSbNm1UWlqqKVOmaPfu3fL29tbrr7+uX//615dVN+0iV8dq9VPEhFRPlwFo1eyB/GoZuIbQLoK64JfaRWolZNdXhOyrQ8hGXUHIBq4thGzUBR7vyQYAAACuN4RsAAAAwGCEbAAAAMBghGwAAADAYIRsAAAAwGCEbAAAAMBghGwAAADAYIRsAAAAwGCEbAAAAMBghGwAAADAYIRsAAAAwGCEbAAAAMBghGwAAADAYIRsAAAAwGCEbAAAAMBghGwAAADAYIRsAAAAwGCEbAAAAMBghGwAAADAYIRsAAAAwGCEbAAAAMBghGwAAADAYIRsAAAAwGCEbAAAAMBghGwAAADAYIRsAAAAwGCEbAAAAMBghGwAAADAYIRsAAAAwGCEbAAAAMBghGwAAADAYIRsAAAAwGCEbAAAAMBghGwAAADAYIRsAAAAwGCEbAAAAMBghGwAAADAYIRsAAAAwGCEbAAAAMBghGwAAADAYIRsAAAAwGCEbAAAAMBghGwAAADAYLUSsqOiohQeHq6BAwdq4MCB+u6777Rq1SqFhYXpkUce0eLFi13rbt68WREREerXr5/mzp3rGt+7d6+GDBmi4OBgTZo0SRUVFZKknJwcRUZGKiQkRM8//7xKSkokScXFxRo1apRCQ0MVGRmp/Pz82jhVAAAAwP0h2+l0av/+/UpNTXX9tGjRQnPnztXf/vY3paam6uOPP9a///1vnT17VrGxsUpKSlJaWpp2796t9evXS5Kio6M1efJkrV27Vk6nU0uXLpUkJSQkaPjw4crIyFDnzp2VlJQkSZo3b57sdrvS09M1dOhQTZs2zd2nCgAAAEiqhZC9f/9+mUwmjRw5UgMGDNCiRYu0efNm9ezZU02bNtUNN9yg4OBgZWRkaOfOnQoICFDbtm1lNpsVERGhjIwMHTlyRGfPnlXXrl0lSYMHD1ZGRobKy8u1detWBQcHVxuXpMzMTEVEREiS+vfvrw0bNqi8vNzdpwsAAADIfKmFP80iX0pQUNAllxcXF6tXr16aOnWqzp49q6ioKIWGhspqtbrWsdls2rlzp/Ly8s4bz83NPW/carUqNzdXRUVF8vX1ldlsrjYuqdo2ZrNZvr6+KiwsVPPmzX/xnAAAAICrccmQnZCQcMmNTSaT1q1bd8l1unXrpm7dukmSbrjhBj322GOaPn26Ro8efd6+nE7nBY9xueMX4+V1eRP3zZr5Xtb6AOouq9XP0yUAMBDvadR1lwzZn3/++VUfYNu2bSovL1evXr0knevRbt26tQoKClzr5OXlyWazqXnz5jUaz8/Pl81mk7+/vxwOhyorK9WgQQPXuHRuFrygoEAtWrRQRUWFHA6HmjZtelm1Hz/uUFXV+UEeNcMFEHVJfv4pT5cAwCBWqx/vaXicl5fpkhOyNZ7azc7O1ty5c/XKK6/o5MmT+uSTT2q03alTpzRr1iyVlpbK4XBoxYoV+tOf/qQvv/xShYWFOnPmjD799FMFBgbq7rvv1oEDB5Sdna3KykqtXr1agYGBat26tXx8fLR9+3ZJUkpKigIDA2WxWGS325WWllZtXDrXxpKSkiJJSktLk91ul8ViqenpAgAAAFfskjPZP1m/fr0mTpyovn37au3atXrxxRc1f/58FRQU6Lnnnrvktn369NF3332nRx99VFVVVRo+fLjuvfdejR8/XlFRUSovL9djjz2mLl26SJJmzJihMWPGqLS0VEFBQQoJCZEkJSYmKi4uTiUlJerUqZOioqIkSfHx8YqJidGCBQvUsmVLzZkzR5I0btw4xcTEKDw8XH5+fkpMTLziFwkAAAC4HCbnhRqbf2bAgAGaPHmyunfvru7du2vr1q3KysrSM888o8zMzFoo0zNoF7k6VqufIiakeroMQKtmD+RXy8A1hHYR1AWGtIscPXpUdrtd0v99sLBdu3auL34BAAAA8H9qFLLvuOMOffzxx9XG0tPT1bFjR7cUBQAAANRnNerJjouL0zPPPKMlS5bo9OnTGjFihPbv36+//OUv7q4PAAAAqHdqFLI7duyotWvXav369crJyZHValXv3r3VpEkTd9cHAAAA1Ds1voVfRUWFKioqZDKZ5O3tze3wAAAAgIuoUcjeunWr+vbtq4ULF2rr1q1KSkpSv379tG/fPnfXBwAAANQ7NWoXSUhI0OTJk/Xoo4+6xpYsWaKpU6dqyZIl7qoNAAAAqJdqNJOdl5eniIiIamNDhgzRDz/84JaiAAAAgPqsRiH74YcfPm/GeuXKlXrggQfcUhQAAABQn12yXWTIkCEymUwqLS3VihUrtGjRIrVq1UoFBQX64YcfXF9QAwAAAOD/XDJkP/nkk7VVBwAAAHDNuGTIHjRo0CU3PnnypKHFAAAAANeCGt1dZMeOHZo9e7Zyc3NVVVUl6dx9swsLC7Vr1y63FggAAADUNzX64OPUqVPVoUMHhYWFqUOHDhozZoxuvPFGjR8/3t31AQAAAPVOjUJ2dna2Jk2apMGDB6u4uFiPPvqo5s2bp08++cTd9QEAAAD1To1Ctr+/v6qqqtS6dWvt379fktS+fXvl5ua6tTgAAACgPqpRyL7nnnsUFxens2fPqn379vrggw/08ccf66abbnJ3fQAAAEC9U6OQHRcXJ4vFotLSUsXGxurvf/+73nzzTb3yyivurg8AAACod2p0d5GmTZtq2rRpkqRmzZpp7dq1bi0KAAAAqM8uGbJnzZr1izuYOHGiYcUAAAAA14JLhuyioqLaqgMAAAC4ZlwyZAcFBemhhx5S48aNa6seAAAAoN67ZMjetm2b5s+fr5YtW6p3797q06eP2rZtW1u1AQAAAPXSJUN2XFycJOnHH3/UF198oejoaJWUlCgoKEi9e/fWvffeK5PJVCuFAgAAAPVFjW7h16FDB40aNUpLlizRhx9+qPbt2+ujjz7Sww8/7O76AAAAgHqnRrfwk6SSkhI1btxYTZo0kY+Pj5544gnZ7XZ31gYAAADUSzWayV65cqUCAwMlSYmJiZo2bZqio6O1cOFCtxYHAAAA1Ec1Ctl/+ctf9Pbbb6u8vFxLly7V22+/rY8//liLFi1yd30AAABAvVOjdpFjx46pZ8+e+uqrr9SwYUN17dpVkuRwONxZGwAAAFAv1Shkt2jRQp999plWrVqlBx54QJK0bNky3XLLLe6sDQAAAKiXahSyY2JiFBsbKx8fH73//vvavHmzEhMT9dZbb7m7PgAAAKDeqVHIvv/++5WZmel6brPZtHHjRlksFnfVBQAAANRbNfrgoyR9/fXXeumllxQVFaVTp05pwYIFqqysdGdtAAAAQL1Uo5C9fPlyvfTSS7rlllu0Z88emUwmffbZZ5o1a5a76wMAAADqnRqF7HfeeUfvvfeeXnjhBXl5ecnf31/vvfee1qxZ4+76AAAAgHqnRiH7xIkTuu222yRJJpNJkvSrX/1K5eXl7qsMAAAAqKdqFLLvuecevfHGG9XGPvzwQ9f9sgEAAAD8nxrdXWTKlCkaPXq0lixZIofDob59+6phw4Z655133F0fAAAAUO/UKGS3bNlSK1as0K5du5STkyOr1aquXbvKbK7R5gAAAMB1pcY92RMnTpSvr69CQ0P11VdfKTY2lq9VBwAAAC6gRiE7Li5OktSsWTNJ0qOPPipJio+Pd09VAAAAQD1Wo36Pr7/+Wps2bXJ9w2ObNm302muvKTAw0K3FAQAAAPVRjWayGzZsqJycnGpjeXl5aty4sVuKAgAAAOqzGs1kP/744xo5cqRGjBihFi1aKDc3V8nJyRo2bJi76wMAAADqnRqF7D/84Q9q1qyZ0tLSVFBQoObNm2vUqFEaMmRIjQ80c+ZMFRUVacaMGdq7d6/i4uLkcDhkt9uVkJAgs9msnJwcRUdH6/jx42rXrp0SExPVuHFjFRcX66WXXtKhQ4fk7++vefPmyWq1qqysTJMmTdLu3bvVsGFDJSYmqn379nI6nZo1a5a++OILeXl56bXXXtO99957xS8SAAAAcDlq1C5iMpn0xBNPKDk5Wenp6frggw8uK2B/+eWXWrFihet5dHS0Jk+erLVr18rpdGrp0qWSpISEBA0fPlwZGRnq3LmzkpKSJEnz5s2T3W5Xenq6hg4dqmnTpkmSkpOT1ahRI6Wnpys2NlYxMTGSpLVr1yorK0tpaWl6++23FRMTo4qKihrXCwAAAFyNGoXsnJwcxcfH66mnnlJUVFS1n19y4sQJzZ07V6NHj5YkHTlyRGfPnnV9W+TgwYOVkZGh8vJybd26VcHBwdXGJSkzM1MRERGSpP79+2vDhg0qLy9XZmamBgwYIEnq3r27ioqKlJOTo/Xr1yssLExeXl5q166dWrVqpR07dlzeKwMAAABcoRq1i7z88styOp36zW9+47rDSE1NmTJF48eP19GjRyWd+8Ck1Wp1LbdarcrNzVVRUZF8fX1dX3Dz0/jPtzGbzfL19VVhYeEF93Xs2DHl5eXJZrOdN365mjXzvextANRNVqufp0sAYCDe06jrahSy9+zZow0bNsjX9/JC57Jly9SyZUv16tVLy5cvlyQ5nc7z1jOZTBcdvxgvrwtPwnt5eV1wXxdb/1KOH3eoqur8faFmuACiLsnPP+XpEgAYxGr14z0Nj/PyMl1yQrZGIfvmm29WcXHxZYfstLQ05efna+DAgTp58qROnz4tk8mkgoIC1zr5+fmy2Wzy9/eXw+FQZWWlGjRo4BqXJJvNpoKCArVo0UIVFRVyOBxq2rSpbDab8vPzFRAQUG1fzZs3V35+/nnHAAAAAGpDjUJ279699dRTT2nAgAG66aabqi2LjIy86HYLFy50PV6+fLm+/vprTZ8+Xf3799f27dt17733KiUlRYGBgbJYLLLb7UpLS1NERIRrXJKCgoKUkpKi0aNHKy0tTXa7XRaLRUFBQUpNTZXdbte2bdvk4+OjVq1aKTAwUJ988on69++vw4cP6+DBg7rrrruu5PUBAAAALluNQvb27dvVvHlzbdmypdq4yWS6ZMi+mMTERMXFxamkpESdOnVyfYAyPj5eMTExWrBggVq2bKk5c+ZIksaNG6eYmBiFh4fLz89PiYmJkqQRI0ZoypQpCg8Pl7e3t2bNmiVJCgkJ0c6dO10fipw2bZoaNmx42XUCAAAAV8LkvFADMyTRk321rFY/RUxI9XQZgFbNHkj/JnANoScbdYEhPdmlpaVavXq1cnNzVVVVJUmqqKjQ/v379cYbbxhTKQAAAHCNqFHInjhxonbt2qWbbrpJZ8+e1a9+9Stt27ZNgwcPdnd9AAAAQL1To5C9adMmrVmzRrm5ufrzn/+spKQkpaSkaM2aNe6uDwAAAKh3anTzaIvFoubNm+vWW2/Vvn37JEkRERHavXu3W4sDAAAA6qMahexbbrlFmZmZrvtkHzp0SAUFBaqsrHRrcQAAAEB9VKN2kbFjx2rMmDFasWKFoqKiNGTIEDVo0EBhYWHurg8AAACod2oUsnv16qV//etf8vHx0VNPPaUuXbqopKREDz30kLvrAwAAAOqdGrWLPP7442rUqJG8vM6tfs899+ihhx5SaGioW4sDAAAA6qOLzmQfPnxYiYmJcjqd+v777zVu3Lhqyx0OhxwOh9sLBAAAAOqbi4bsNm3aqHv37ioqKtK6devUoUOHasu9vb318ssvu71AAAAAoL65ZE92ZGSkJOn2229Xv379aqUgAAAAoL6rUU/2fffdpzfffFOStHPnToWFhWn48OHKzs52a3EAAABAfVSjkD1lyhTt2rVLTqdTU6dO1QMPPKDu3btr8uTJ7q4PAAAAqHdqdAu/b7/9Vp999pmOHTumH374QQsXLpSfn5+6d+/u7voAAACAeqdGM9llZWWSpC+++EKdOnVSkyZNVFRUJB8fH7cWBwAAANRHNZrJ7tu3r/7rv/5LBw8e1IsvvqgDBw5owoQJCg4Odnd9AAAAQL1To5CdkJCg1NRU+fj4KCIiQtnZ2erfv7+ioqLcXR8AAABQ79QoZFssFj322GOu5wEBAXr66afdVhQAAABQn9UoZG/atEmvv/66srOz5XQ6qy3bu3evWwoDAAAA6qsahezp06erd+/eGjBggMzmGm0CAAAAXLdqlJiPHDmiCRMmELABAACAGqjRLfx69Oih7du3u7sWAAAA4JpQo6lpPz8/Pfvss+ratav8/f2rLZs/f75bCgMAAADqqxqF7ICAAD333HPurgUAAAC4JlwyZC9evFiSdNNNN9VKMQAAAMC14JIhOyMj45Ibm0wmRUZGGloQAAAAUN9dMmQnJyfXVh0AAADANaNGdxcBAAAAUHOEbAAAAMBghGwAAADAYIRsAAAAwGCEbAAAAMBghGwAAADAYIRsAAAAwGCEbAAAAMBghGwAAADAYIRsAAAAwGCEbAAAAMBghGwAAADAYIRsAAAAwGCEbAAAAMBghGwAAADAYIRsAAAAwGCEbAAAAMBgtRKy58+fr7CwMIWHh2vhwoWSpM2bNysiIkL9+vXT3LlzXevu3btXQ4YMUXBwsCZNmqSKigpJUk5OjiIjIxUSEqLnn39eJSUlkqTi4mKNGjVKoaGhioyMVH5+viSprKxM0dHRCg0N1aBBg5SVlVUbpwoAAAC4P2R//fXX+uqrr7Ry5Up98sknSk5O1r59+xQbG6ukpCSlpaVp9+7dWr9+vSQpOjpakydP1tq1a+V0OrV06VJJUkJCgoYPH66MjAx17txZSUlJkqR58+bJbrcrPT1dQ4cO1bRp0yRJycnJatSokdLT0xUbG6uYmBh3nyoAAAAgqRZC9n333aePPvpIZrNZx48fV2VlpYqLixUQEKC2bdvKbDYrIiJCGRkZOnLkiM6ePauuXbtKkgYPHqyMjAyVl5dr69atCg4OrjYuSZmZmYqIiJAk9e/fXxs2bFB5ebkyMzM1YMAASVL37t1VVFSknJwcd58uAAAAIHNtHMRiseiNN97QX//6V4WEhCgvL09Wq9W13GazKTc397xxq9Wq3NxcFRUVydfXV2azudq4pGrbmM1m+fr6qrCw8IL7OnbsmFq1alXjups1872q8wZQd1itfp4uAYCBeE+jrquVkC1JY8eO1ciRIzV69GgdPHjwvOUmk0lOp/Oyxi/Gy+vCE/QXG7+Y48cdqqo6/9ioGS6AqEvy8095ugQABrFa/XhPw+O8vEyXnJB1e7tIVlaW9u7dK0lq1KiR+vXrpy1btqigoMC1Tl5enmw2m5o3b15tPD8/XzabTf7+/nI4HKqsrKw2Lp2bBf9pm4qKCjkcDjVt2lQ2m831IcifbwMAAAC4k9tD9uHDhxUXF6eysjKVlZVp3bp1GjZsmA4cOKDs7GxVVlZq9erVCgwMVOvWreXj46Pt27dLklJSUhQYGCiLxSK73a60tLRq45IUFBSklJQUSVJaWprsdrssFouCgoKUmpoqSdq2bZt8fHwuq1UEAAAAuFJubxcJCgrSd999p0cffVQNGjRQv379FB4eLn9/f40ZM0alpaUKCgpSSEiIJCkxMVFxcXEqKSlRp06dFBUVJUmKj49XTEyMFixYoJYtW2rOnDmSpHHjxikmJkbh4eHy8/NTYmKiJGnEiBGaMmWKwsPD5e3trVmzZrn7VAEAAABJksl5oYZnSKIn+2pZrX6KmJDq6TIArZo9kP5N4BpCTzbqAo/3ZAMAAADXG0I2AAAAYDBCNgAAAGAwQjYAAABgMEI2AAAAYDBCNgAAAGAwQjYAAABgMEI2AAAAYDBCNgAAAGAwQjYAAABgMEI2AAAAYDBCNgAAAGAwQjYAAABgMEI2AAAAYDCzpwsAAOB64ndjIzX04a/fq2W1+nm6hHrvbGmFThWf8XQZ1yze5QAA1KKGPmZFTEj1dBmAVs0eqFOeLuIaRrsIAAAAYDBCNgAAAGAwQjYAAABgMEI2AAAAYDBCNgAAAGAwQjYAAABgMEI2AAAAYDBCNgAAAGAwQjYAAABgMEI2AAAAYDBCNgAAAGAwQjYAAABgMEI2AAAAYDBCNgAAAGAwQjYAAABgMEI2AAAAYDBCNgAAAGAwQjYAAABgMEI2AAAAYDBCNgAAAGAwQjYAAABgMEI2AAAAYDBCNgAAAGAwQjYAAABgMEI2AAAAYDBCNgAAAGAwQjYAAABgsFoJ2W+99ZbCw8MVHh6uWbNmSZI2b96siIgI9evXT3PnznWtu3fvXg0ZMkTBwcGaNGmSKioqJEk5OTmKjIxUSEiInn/+eZWUlEiSiouLNWrUKIWGhioyMlL5+fmSpLKyMkVHRys0NFSDBg1SVlZWbZwqAAAA4P6QvXnzZm3cuFErVqxQSkqK9uzZo9WrVys2NlZJSUlKS0vT7t27tX79eklSdHS0Jk+erLVr18rpdGrp0qWSpISEBA0fPlwZGRnq3LmzkpKSJEnz5s2T3W5Xenq6hg4dqmnTpkmSkpOT1ahRI6Wnpys2NlYxMTHuPlUAAABAUi2EbKvVqpiYGHl7e8tisah9+/Y6ePCgAgIC1LZtW5nNZkVERCgjI0NHjhzR2bNn1bVrV0nS4MGDlZGRofLycm3dulXBwcHVxiUpMzNTERERkqT+/ftrw4YNKi8vV2ZmpgYMGCBJ6t69u4qKipSTk+Pu0wUAAADcH7I7dOjgCs0HDx5UWlqaTCaTrFarax2bzabc3Fzl5eVVG7darcrNzVVRUZF8fX1lNpurjUuqto3ZbJavr68KCwsvuK9jx465+3QBAAAAmWvrQD/++KOee+45vfzyyzKbzTpw4EC15SaTSU6n87ztLjV+MV5eF/63w8XGL6ZZM9/LWh9A3WW1+nm6BACoc7g2uk+thOzt27dr7Nixio2NVXh4uL7++msVFBS4lufl5clms6l58+bVxvPz82Wz2eTv7y+Hw6HKyko1aNDANS6dmwUvKChQixYtVFFRIYfDoaZNm8pmsyk/P18BAQHV9nU5jh93qKrq/ICPmuGNi7okP/+Up0sAJHFtRN3CtfHKeXmZLjkh6/Z2kaNHj+oPf/iDEhMTFR4eLkm6++67deDAAWVnZ6uyslKrV69WYGCgWrduLR8fH23fvl2SlJKSosDAQFksFtntdqWlpVUbl6SgoCClpKRIktLS0mS322WxWBQUFKTU1FRJ0rZt2+Tj46NWrVq5+3QBAAAA989kv//++yotLdWMGTNcY8OGDdOMGTM0ZswYlZaWKigoSCEhIZKkxMRExcXFqaSkRJ06dVJUVJQkKT4+XjExMVqwYIFatmypOXPmSJLGjRunmJgYhYeHy8/PT4mJiZKkESNGaMqUKQoPD5e3t7fr1oEAAACAu5mcF2p4hiTaRa6W1eqniAmpni4D0KrZA/mVKOoMro2oK7g2Xh2Pt4sAAAAA1xtCNgAAAGAwQjYAAABgMEI2AAAAYDBCNgAAAGAwQjYAAABgMEI2AAAAYDBCNgAAAGAwQjYAAABgMEI2AAAAYDBCNgAAAGAwQjYAAABgMEI2AAAAYDBCNgAAAGAwQjYAAABgMEI2AAAAYDBCNgAAAGAwQjYAAABgMEI2AAAAYDBCNgAAAGAwQjYAAABgMEI2AAAAYDBCNgAAAGAwQjYAAABgMEI2AAAAYDBCNgAAAGAwQjYAAABgMEI2AAAAYDBCNgAAAGAwQjYAAABgMEI2AAAAYDBCNgAAAGAwQjYAAABgMEI2AAAAYDBCNgAAAGAwQjYAAABgMEI2AAAAYDBCNgAAAGAwQjYAAABgMEI2AAAAYDBCNgAAAGAwQjYAAABgMEI2AAAAYDBCNgAAAGCwWgvZDodD/fv31+HDhyVJmzdvVkREhPr166e5c+e61tu7d6+GDBmi4OBgTZo0SRUVFZKknJwcRUZGKiQkRM8//7xKSkokScXFxRo1apRCQ0MVGRmp/Px8SVJZWZmio6MVGhqqQYMGKSsrq7ZOFQAAANe5WgnZ3333nZ544gkdPHhQknT27FnFxsYqKSlJaWlp2r17t9avXy9Jio6O1uTJk7V27Vo5nU4tXbpUkpSQkKDhw4crIyNDnTt3VlJSkiRp3rx5stvtSk9P19ChQzVt2jRJUnJysho1aqT09HTFxsYqJiamNk4VAAAAqJ2QvXTpUsXHx8tms0mSdu7cqYCAALVt21Zms1kRERHKyMjQkSNHdPbsWXXt2lWSNHjwYGVkZKi8vFxbt25VcHBwtXFJyszMVEREhCSpf//+2rBhg8rLy5WZmakBAwZIkrp3766ioiLl5OTUxukCAADgOmeujYP8NLv8k7y8PFmtVtdzm82m3Nzc88atVqtyc3NVVFQkX19fmc3mauM/35fZbJavr68KCwsvuK9jx46pVatWNa67WTPfyz9ZAHWS1ern6RIAoM7h2ug+tRKyf87pdJ43ZjKZLnv8Yry8LjxBf7Hxizl+3KGqqvOPjZrhjYu6JD//lKdLACRxbUTdwrXxynl5mS45IeuRu4s0b95cBQUFrud5eXmy2Wznjefn58tms8nf318Oh0OVlZXVxqVzs+A/bVNRUSGHw6GmTZvKZrO5PgT5820AAAAAd/JIyL777rt14MABZWdnq7KyUqtXr1ZgYKBat24tHx8fbd++XZKUkpKiwMBAWSwW2e12paWlVRuXpKCgIKWkpEiS0tLSZLfbZbFYFBQUpNTUVEnStm3b5OPjc1mtIgAAAMCV8ki7iI+Pj2bMmKExY8aotLRUQUFBCgkJkSQlJiYqLi5OJSUl6tSpk6KioiRJ8fHxiomJ0YIFC9SyZUvNmTNHkjRu3DjFxMQoPDxcfn5+SkxMlCSNGDFCU6ZMUXh4uLy9vTVr1ixPnCoAAACuQybnhRqeIYme7KtltfopYkKqp8sAtGr2QPoOUWdwbURdwbXx6tTJnmwAAADgWkbIBgAAAAxGyAYAAAAMRsgGAAAADEbIBgAAAAxGyAYAAAAMRsgGAAAADEbIBgAAAAxGyAYAAAAMRsgGAAAADEbIBgAAAAxGyAYAAAAMRsgGAAAADEbIBgAAAAxGyAYAAAAMRsgGAAAADEbIBgAAAAxGyAYAAAAMRsgGAAAADEbIBgAAAAxGyAYAAAAMRsgGAAAADEbIBgAAAAxGyAYAAAAMRsgGAAAADEbIBgAAAAxGyAYAAAAMRsgGAAAADEbIBgAAAAxGyAYAAAAMRsgGAAAADEbIBgAAAAxGyAYAAAAMRsgGAAAADEbIBgAAAAxGyAYAAAAMRsgGAAAADEbIBgAAAAxGyAYAAAAMRsgGAAAADEbIBgAAAAxGyAYAAAAMRsgGAAAADEbIBgAAAAx2TYfsVatWKSwsTI888ogWL17s6XIAAABwnTB7ugB3yc3N1dy5c7V8+XJ5e3tr2LBh6tGjh2677TZPlwYAAIBr3DUbsjdv3qyePXuqadOmkqTg4GBlZGTohRdeqPE+vLxMbqru+mG7qZGnSwAk8X5G3cK1EXUF18Yr90uv3TUbsvPy8mS1Wl3PbTabdu7ceVn7uOmmxkaXdd15P66fp0sAJEnNmvl6ugTAhWsj6gquje5zzfZkO53O88ZMJv61BgAAAPe7ZkN28+bNVVBQ4Hqel5cnm83mwYoAAABwvbhmQ/b999+vL7/8UoWFhTpz5ow+/fRTBQYGerosAAAAXAeu2Z7s5s2ba/z48YqKilJ5ebkee+wxdenSxdNlAQAA4Dpgcl6oeRkAAADAFbtm20UAAAAATyFkAwAAAAYjZAMAAAAGI2QDAAAABiNkAwAAAAYjZAMAgDrt0KFD540lJyd7oBKg5gjZAACgTnv22WeVnZ0tSfrhhx80dOhQ/fOf//RwVcClcZ9soA654447ZDKZJEk/f2uaTCbt3bvXE2UBgEd98803iouL0/33369PP/1Uf/zjH/Xoo496uizgkgjZAACgztu3b5+effZZzZ49Wz169PB0OcAvImQDddDx48e1atUqlZSUyOl0qqqqSocPH9asWbM8XRoA1JoL/XbPZDLJ6XTy2z3UeWZPFwDgfC+88IJuvvlmffvtt/rNb36jTZs26Y477vB0WQBQq/bt23fe2E8BG6jr+OAjUAcVFRVp5syZ6tu3r/r166fk5GT9+OOPni4LADxiy5YtGjZsmCTpwIEDevjhh/XNN994uCrg0gjZQB3UpEkTSVK7du20b98++fn5qaKiwsNVAYBnzJgxQ6+++qok6dZbb9W7776radOmebgq4NJoFwHqoJ49e2rs2LF6+eWX9fTTT2vPnj3y8fHxdFkA4BGlpaW6/fbbXc/bt2/PxAPqPD74CNRR//nPf3TzzTdrz5492rp1q8LCwmSz2TxdFgDUuhdeeEEBAQEaOHCgJGnNmjU6ePCg5s+f7+HKgIsjZAN1UFlZmTZu3Kji4uJq49wXFsD16OTJk5o3b562bdsms9ksu92usWPHys/Pz9OlARdFyAbqoP/6r/+S0+lU69atq41Pnz7dQxUBQN3hdDp1+PBhtW3b1tOlABdFTzZQBxUVFWnlypWeLgMA6oTk5GTNnTtXZ86ccY21bt2ar1ZHncbdRYA6qGfPntq8ebOqqqo8XQoAeNzChQuVmpqqsLAwffbZZ5o2bZruvvtuT5cFXBIz2UAd1KpVKz399NPVvumMbzcDcL1q1qyZ2rZtq44dO+p//ud/NHjwYC1atMjTZQGXRMgG6qCPPvpIn3/+uVq1auXpUgDA4xo1aqSvvvpKHTt21D//+U/ddddd530wHKhraBcB6iCbzaamTZt6ugwAqBMmT56szz//XA899JBOnDih0NBQPfnkk54uC7gk7i4C1EHjxo3Trl27dM8998hisbjGubsIgOvRpk2b9MADD1Qb+/TTT9WvXz8PVQT8MtpFgDqod+/e6t27t6fLAACPSktLU1lZmd544w2NHTvWNV5RUaF33nmHkI06jZAN1EGrVq3SX//6V0+XAQAe5XA4tGPHDpWUlGjLli2u8QYNGmj8+PEerAz4ZYRsoA4qLS3V0aNH1bJlS0+XAgAe8/jjj+vxxx/XokWLzuvB/vbbbz1TFFBDhGygDiosLFTfvn3VrFkz+fj4uG7ht27dOk+XBgC1Zvv27aqqqlJycrLuuOMO/fQxsoqKCk2dOlVr1671cIXAxRGygTroL3/5i6dLAACP27x5s77++mvl5eVp/vz5rnGLxaJBgwZ5sDLgl3F3EaAOcjqd+vvf/66vvvpKFRUV6tmzp5588kl5eXHXTQDXn5SUFD366KMqLy/Xp59+qiVLlmj37t3asWOHp0sDLoqQDdRBM2fOVHZ2toYMGSKn06nly5erTZs2io2N9XRpAFDrDh06pI8//lgrVqzQyZMnNXr0aA0fPlz+/v6eLg24KEI2UAcNGDBAKSkprpnriooKRUREKD093cOVAUDt+eyzz7RkyRJ9//33+s1vfqOQkBDXF9MAdR092UAdVFlZqYqKCnl7e7ueN2jQwMNVAUDtGjNmjEJCQrRkyRIFBARIkkwmk4erAmqGkA3UQREREYqKilJ4eLgkac2aNa7HAHC9WLlypVasWKHhw4erdevWCg8PV2VlpafLAmqEdhGgDsnJyXE9zszM1JYtW+R0OtWjRw/16dNHrVq18mB1AOAZlZWV+uKLL7RixQqtX79e999/vyIjIxUUFOTp0oCLImQDdUjfvn1lMpn087dlfn6+KioqtHfvXg9VBgB1Q2FhoVJTU7VixQqtXLnS0+UAF0XIBuqwkpISzZw5Uxs3btRrr72mBx54wNMlAQCAGuCmu0Ad9eWXX2rAgAGSzvUlErABAKg/+OAjUMecPn1aM2bMYPYaAIB6jJlsoA758ssvFRERIUlatWoVARsAgHqKnmygDrnjjjtkNptls9mq3QvW6XTKZDJp3bp1HqwOAADUFCEbqEOOHDlyyeWtW7eupUoAAMDVIGQDAAAABqMnGwAAADAYIRsAcJ5Dhw55ugQAqNcI2QBQhzz77LPq1q2bunXrpk6dOqlz586u51OmTKmVGtatW6fx48dfcNnhw4fVsWNHlZSUXPZ+R4wYoUWLFl32dlu2bFGPHj0uezsA8CTukw0Adchf/vIX1+OxY8eqQ4cOGjNmTK3WcPLkSVVVVdXqMQHgWsNMNgDUE4cOHdLo0aMVFBSkLl26aNiwYcrKypIkvfnmm3ruuecUFhamwMBAORwOffrppwoODlaPHj0UGxurYcOGafny5ZKkEydOKDo6Wr169VLfvn317rvvyul0aufOnYqPj9fevXuv6D7tX375pYYNG6aePXvqnnvu0dixY3XmzBnX8n379mnQoEHq1q2bXnzxRZ04ccK17G9/+5v69eunHj166A9/+IPy8/PP239ZWZleeeUV9ejRQw8++KDGjh2roqKiy64TANyNkA0A9URcXJxuvfVWrVu3Tl999ZVuuukm/fnPf3Yt/+qrrzRv3jytWbNG+fn5io6OVmxsrDZu3Kibb75ZO3bscK07ceJE173XP/roI61cuVLLly9Xly5dlJCQoDvvvFObNm26rPpOnz6tF154QSNHjtRXX32ltLQ07d69W6tXr3atk5mZqZkzZ+pf//qXzpw5o9dee02SlJ6ernfffVdvv/22NmzYoLZt216wZSU1NVVZWVn64osv9Nlnn+n06dP66KOPLvelBAC3I2QDQD0xY8YMjR07VpWVlcrJyVHTpk2Vm5vrWn7nnXfq9ttvl5+fn9asWaMHHnhAQUFBslgseu6552Sz2SRJ+fn52rBhg1555RXdcMMNatOmjZ555hktW7bsqurz8fHRihUr9PDDD+vUqVPKy8s7r8YRI0bo9ttvl6+vr1588UWtXbtWlZWV+sc//qGnnnpKHTp0kI+Pj/74xz/qu+++04EDB847RnZ2tlasWKGioiK9++67Gjdu3FXVDQDuQE82ANQT+/fv15/+9Cfl5ubqtttuk8lk0v//qgOr1ep6nJeXp5YtW7qem0wm1/OjR4/K6XTqkUcecS2vqqpS06ZNr6q+Bg0a6PPPP9eHH34oSerYsaPOnDlTrcZWrVq5Hjdv3lzl5eU6ceKEjh49qnnz5umtt96qVnNOTo7M5v/7q2rAgAFyOBxavny5pk2bpttvv12vvvqqunTpclW1A4DRCNkAUA+UlZXphRde0PTp0xUSEiJJeuutt7RlyxbXOiaTyfW4ZcuW2rlzp+u50+l0zShbrVaZzWZt3rxZ3t7eks592PFK7hjy/33zzTd6++23tWzZMt1yyy2SpKioqGrrFBQUuB7n5OSoYcOG8vf3l9Vq1dNPP63HHnvMtTwrK0tt27at1uZy8OBB9ezZU8OHD1dRUZHefvttTZw4URkZGVdVOwAYjXYRAKgHysvLVVpaqkaNGkmSvv32W3388ccqLy+/4Pr9+/fX5s2b9a9//UsVFRX68MMPdezYMUnnAvi9996rP/3pTzp79qxOnDihsWPHau7cuZIkb29vlZSU6FJfCJyXl6djx465fk6ePCmHwyEvLy81bNhQlZWVSklJ0bZt21RRUeHaLjk5WQcOHFBxcbHmzp2rwYMHy2QyadCgQVq4cKGys7NVVVWl5ORkPf7449U+NCmdu73ghAkTVFBQoCZNmqhx48ZXPQMPAO7ATDYA1AONGzdWQkKC4uLidPr0ad1888367W9/q8WLF1cLsT9p27atpk+frvj4eDkcDgUHB6tVq1ayWCySpDlz5ui///u/1bdvX1VWViowMFDx8fGSpO7du7v+u2nTJvn4+Jy3/59m038SERGhWbNmKSQkRBEREfLy8lLnzp01aNAg1x1QJKlPnz4aNWqUiouL9cgjjyg6OlqSNHDgQJ04cUIjR45UQUGBbr31Vr3zzjtq0qRJteNERUXpP//5jyIiInT27Fl17txZ06dPv4pXFgDcw+S81FQFAKBeysnJ0enTp3Xbbbe5xu6//37NmjVLDz74oAcrA4DrA+0iAHANysvLU1RUlA4dOqSqqir9/e9/V1lZmbp27erp0gDgukC7CABcg7p27apRo0ZpxIgROnnypNq3b68///nP8vX19XRpAHBdoF0EAAAAMBjtIgAAAIDBCNkAAACAwQjZAAAAgMEI2QAAAIDBCNkAAACAwQjZAAAAgMH+F24KFYfuES9hAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 842.4x595.44 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['label'].value_counts().plot(kind='bar')\n",
    "plt.title(\"Target Label Distribution\", fontsize=15)\n",
    "plt.xlabel(\"Target Labels\", fontsize=13)\n",
    "plt.ylabel(\"Instances/label\", fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "1b6919ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(axis=1, columns=[''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "253ca84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1074992 entries, 0 to 4898430\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count    Dtype \n",
      "---  ------         --------------    ----- \n",
      " 0   protocol_type  1074992 non-null  object\n",
      " 1   service        1074992 non-null  object\n",
      " 2   flag           1074992 non-null  object\n",
      " 3   label          1074992 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 41.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df_cat = data.select_dtypes(exclude=[np.number])\n",
    "df_cat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "12713878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1074992</td>\n",
       "      <td>1074992</td>\n",
       "      <td>1074992</td>\n",
       "      <td>1074992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3</td>\n",
       "      <td>70</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>978540</td>\n",
       "      <td>580507</td>\n",
       "      <td>786840</td>\n",
       "      <td>812814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       protocol_type  service     flag    label\n",
       "count        1074992  1074992  1074992  1074992\n",
       "unique             3       70       11        2\n",
       "top              tcp     http       SF   Normal\n",
       "freq          978540   580507   786840   812814"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "c9d84e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_original = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "55c9ff31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Name protocol_type\n",
      "Top 2 Features occupy 98.89% of the data\n",
      "Feature Name service\n",
      "Top 3 Features occupy 81.47% of the data\n",
      "Feature Name flag\n",
      "Top 2 Features occupy 92.13% of the data\n"
     ]
    }
   ],
   "source": [
    "n_features = [2, 3, 2]\n",
    "for feature, num in zip(df_cat.columns, n_features):\n",
    "    #print(num)\n",
    "    if data[feature].nunique()>num:\n",
    "        where_condition = data[feature].isin(data[feature].value_counts().head(num).index)\n",
    "        percent = where_condition.sum()/data.shape[0]\n",
    "        print(f\"Feature Name {feature}\")\n",
    "        print(f\"Top {num} Features occupy {round(percent*100,2)}% of the data\")\n",
    "        #df[feature] = np.where(where_condition,\n",
    "        #                      data[feature], \"OTHER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "20a795bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Name service\n",
      "Top 4 Features occupy 85.82% of the data\n",
      "Feature Name flag\n",
      "Top 2 Features occupy 92.13% of the data\n"
     ]
    }
   ],
   "source": [
    "n_features = [3, 4, 2]\n",
    "for feature, num in zip(df_cat.columns, n_features):\n",
    "    #print(num)\n",
    "    if data[feature].nunique()>num:\n",
    "        where_condition = data[feature].isin(data[feature].value_counts().head(num).index)\n",
    "        percent = where_condition.sum()/data.shape[0]\n",
    "        print(f\"Feature Name {feature}\")\n",
    "        print(f\"Top {num} Features occupy {round(percent*100,2)}% of the data\")\n",
    "        data[feature] = np.where(where_condition,\n",
    "                              data[feature], \"OTHER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "7902ce27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1074992</td>\n",
       "      <td>1074992</td>\n",
       "      <td>1074992</td>\n",
       "      <td>1074992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>978540</td>\n",
       "      <td>580507</td>\n",
       "      <td>786840</td>\n",
       "      <td>812814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       protocol_type  service     flag    label\n",
       "count        1074992  1074992  1074992  1074992\n",
       "unique             3        5        3        2\n",
       "top              tcp     http       SF   Normal\n",
       "freq          978540   580507   786840   812814"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.select_dtypes(exclude=[np.number]).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "1a1bbd98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 842.4x595.44 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.select_dtypes(exclude=[np.number])['protocol_type'].value_counts().plot(kind='barh').invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "95744a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(df, des=''):\n",
    "    path = r\"kddcup\\preprocessing\"\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    if not os.listdir(path):\n",
    "        version = \"v1\"\n",
    "    else:\n",
    "        final = os.listdir(path)[-1]\n",
    "        version = f\"v{int(final[-5])+1}\"\n",
    "    #print(os.listdir(path))\n",
    "    file = os.path.join(path, f\"{des}_{version}\")\n",
    "    file += \".csv\"\n",
    "    #data = np.array(df)\n",
    "    df.to_csv(file, index=False)\n",
    "    print(f\"Version {version} Data is Saved Successfully in Path: {file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "ac8e6a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version v1 Data is Saved Successfully in Path: kddcup\\preprocessing\\_v1.csv\n"
     ]
    }
   ],
   "source": [
    "save_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33eb7a26",
   "metadata": {},
   "source": [
    "# OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ac628839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Dell\\\\Desktop\\\\Network Intrusion Detection'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4328caa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('kddcup\\preprocessing\\_v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ce64bb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data.drop(columns=['label'], axis=1)\n",
    "y_train_ = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f6a5ecd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_features = X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5be1999f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(old_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "82e01756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['duration', 'protocol_type', 'service', 'flag', 'src_bytes',\n",
       "       'dst_bytes', 'land', 'wrong_fragment', 'urgent', 'hot',\n",
       "       'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell',\n",
       "       'su_attempted', 'num_root', 'num_file_creations', 'num_shells',\n",
       "       'num_access_files', 'num_outbound_cmds', 'is_host_login',\n",
       "       'is_guest_login', 'count', 'srv_count', 'serror_rate',\n",
       "       'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate',\n",
       "       'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count',\n",
       "       'dst_host_srv_count', 'dst_host_same_srv_rate',\n",
       "       'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate',\n",
       "       'dst_host_srv_diff_host_rate', 'dst_host_serror_rate',\n",
       "       'dst_host_srv_serror_rate', 'dst_host_rerror_rate',\n",
       "       'dst_host_srv_rerror_rate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "da20c269",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers = [('encoder', OneHotEncoder(sparse=False), [1,2,3])]\n",
    "ct = ColumnTransformer(transformers=transformers, remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0f6ecc7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1074992, 41)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "efbb1778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1074992, 49)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.array(ct.fit_transform(X_train))\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5d19b6aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_features = [f for f in old_features if f not in ['flag', 'service', 'protocol_type']]\n",
    "len(new_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9b701ae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for label in list(data['flag'].value_counts().index):\n",
    "    new_features.insert(0, f\"flag={label}\")\n",
    "    \n",
    "for label in list(data['service'].value_counts().index):\n",
    "    new_features.insert(0, f\"service={label}\")\n",
    "    \n",
    "for label in list(data['protocol_type'].value_counts().index):\n",
    "    new_features.insert(0, f\"protocol_type={label}\")\n",
    "    \n",
    "len(new_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "87203a21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['protocol_type=icmp',\n",
       " 'protocol_type=udp',\n",
       " 'protocol_type=tcp',\n",
       " 'service=domain_u',\n",
       " 'service=smtp',\n",
       " 'service=OTHER',\n",
       " 'service=private',\n",
       " 'service=http',\n",
       " 'flag=OTHER',\n",
       " 'flag=S0',\n",
       " 'flag=SF',\n",
       " 'duration',\n",
       " 'src_bytes',\n",
       " 'dst_bytes',\n",
       " 'land',\n",
       " 'wrong_fragment',\n",
       " 'urgent',\n",
       " 'hot',\n",
       " 'num_failed_logins',\n",
       " 'logged_in',\n",
       " 'num_compromised',\n",
       " 'root_shell',\n",
       " 'su_attempted',\n",
       " 'num_root',\n",
       " 'num_file_creations',\n",
       " 'num_shells',\n",
       " 'num_access_files',\n",
       " 'num_outbound_cmds',\n",
       " 'is_host_login',\n",
       " 'is_guest_login',\n",
       " 'count',\n",
       " 'srv_count',\n",
       " 'serror_rate',\n",
       " 'srv_serror_rate',\n",
       " 'rerror_rate',\n",
       " 'srv_rerror_rate',\n",
       " 'same_srv_rate',\n",
       " 'diff_srv_rate',\n",
       " 'srv_diff_host_rate',\n",
       " 'dst_host_count',\n",
       " 'dst_host_srv_count',\n",
       " 'dst_host_same_srv_rate',\n",
       " 'dst_host_diff_srv_rate',\n",
       " 'dst_host_same_src_port_rate',\n",
       " 'dst_host_srv_diff_host_rate',\n",
       " 'dst_host_serror_rate',\n",
       " 'dst_host_srv_serror_rate',\n",
       " 'dst_host_rerror_rate',\n",
       " 'dst_host_srv_rerror_rate']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "183540c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       1.0000e+00, 0.0000e+00, 2.1500e+02, 4.5076e+04, 0.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       1.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_one_hot = pd.DataFrame(X_train, columns=new_features)\n",
    "df_one_hot.iloc[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a991328e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       1.0000e+00, 0.0000e+00, 2.1500e+02, 4.5076e+04, 0.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       1.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "464629ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version v2 Data is Saved Successfully in Path: kddcup\\preprocessing\\one_hot_v2.csv\n"
     ]
    }
   ],
   "source": [
    "save_data(df_one_hot,des='one_hot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa003598",
   "metadata": {},
   "source": [
    "# Train a Base Line Model with all Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "402f65fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_models():\n",
    "    RS = 32\n",
    "    estimators = {\n",
    "        \"DecisionTree\": DecisionTreeClassifier(random_state=RS),\n",
    "        \"RandomForest\" : RandomForestClassifier(random_state=RS, n_jobs=-1),\n",
    "        \"ExtraTrees\": ExtraTreesClassifier(random_state=RS,n_jobs=-1),\n",
    "        \"GradientBoosting\": GradientBoostingClassifier(random_state=RS),\n",
    "        \"XGBoost\": XGBClassifier(random_state=RS, use_label_encoder=False,\n",
    "                                 n_jobs=-1),\n",
    "        \"AdaBoost\": AdaBoostClassifier(random_state=RS),\n",
    "        \"SVC\": Pipeline([('scaler', StandardScaler()),\n",
    "                         ('svc', LinearSVC(random_state=RS))]),\n",
    "        \"LogisticRegression\": Pipeline([('scaler', StandardScaler()),\n",
    "                                        ('lg', LogisticRegression(random_state=RS))]),\n",
    "        \"Lasso\": Pipeline([('scaler', StandardScaler()),\n",
    "                                        ('lasso', SGDClassifier(random_state=RS, penalty='l2'))]),\n",
    "        \"Ridge\": Pipeline([('scaler', StandardScaler()),\n",
    "                                        ('ridge', SGDClassifier(random_state=RS, penalty='l1'))]),\n",
    "        \"ElasticNet\": Pipeline([('scaler', StandardScaler()),\n",
    "                                        ('ElasticNet', SGDClassifier(random_state=RS, penalty=\"elasticnet\"))])\n",
    "        \n",
    "    }\n",
    "    return estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "7e8de105",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "0f51b48d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Normal', 'Attack'], dtype=object)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d3bfb17e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_15296\\1906299040.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y_train_[y_train_ == 'Attack'] = 1\n",
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_15296\\1906299040.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y_train_[y_train_ == 'Normal'] = 0\n"
     ]
    }
   ],
   "source": [
    "y_train_[y_train_ == 'Attack'] = 1\n",
    "y_train_[y_train_ == 'Normal'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "3e38d163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=object)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "fa8e7037",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train_, random_state=32,\n",
    "                                                      stratify=y_train_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1f0994f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DecisionTree', 0.9999913177648454, 0.9997581377349785, 1.0, 0.9994508176714669, 0.999964400685541, 0.9995575558776413, 0.9999822000259371, 0.99950418392488]\n",
      "['RandomForest', 0.9999913177648454, 0.9998548826409871, 0.9999898286121142, 0.9999236827645155, 0.9999745719182437, 0.9994812724082691, 0.9999822002069862, 0.9997024286400988]\n",
      "['ExtraTrees', 0.9999913177648454, 0.9998102311459062, 1.0, 0.9997558221164118, 0.999964400685541, 0.9994660157143946, 0.9999822000259371, 0.9996108979102929]\n",
      "['GradientBoosting', 0.9994629417397215, 0.9995088335541101, 0.9996383860814293, 0.9996791688946605, 0.9981590068808389, 0.9983065069799375, 0.998898148737197, 0.9989923664122138]\n",
      "[16:22:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "['XGBoost', 0.999987596806922, 0.9998883712622978, 0.9999847428405779, 0.9999236932468524, 0.999964400685541, 0.9996185826531391, 0.999974571659606, 0.9997711146715496]\n",
      "['AdaBoost', 0.9977599833301085, 0.9977934719514192, 0.9974619678175477, 0.9972896824181545, 0.9933429281961828, 0.993653215348234, 0.9953981867938663, 0.9954681278706315]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SVC', 0.9954269427121318, 0.9955088037864468, 0.9937256266696691, 0.9936318438497422, 0.9874842981595154, 0.9879166984514456, 0.9905951315074574, 0.9907660293926389]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LogisticRegression', 0.9954095782418225, 0.995601827734532, 0.9939425902979037, 0.9942407814107782, 0.9871944180274929, 0.987687848043329, 0.9905570113106643, 0.990953481608474]\n",
      "['Lasso', 0.996097955457653, 0.9962381115394348, 0.9960009638702466, 0.996094831032256, 0.9879674317128865, 0.9884506827370508, 0.9919679330065359, 0.9922580348733028]\n",
      "['Ridge', 0.995921830115945, 0.996022295979877, 0.9921147610248265, 0.992378654122247, 0.9911561131651351, 0.9913036844915707, 0.9916352054055705, 0.9918408780405894]\n",
      "['ElasticNet', 0.9962914452696702, 0.9965022995519967, 0.9951873161999745, 0.9957792955260533, 0.9895795720962403, 0.9898542985734992, 0.9923755221109859, 0.9928079571537873]\n"
     ]
    }
   ],
   "source": [
    "models = define_models()\n",
    "results = []\n",
    "for model_name, model in models.items():\n",
    "    result = []\n",
    "    model.fit(X_train, list(y_train.values))\n",
    "    #print(40*\"_\")\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_valid = model.predict(X_valid)\n",
    "    precision_train = precision_score(list(y_train.values), y_pred_train)\n",
    "    precision_valid = precision_score(list(y_valid.values), y_pred_valid)\n",
    "    recal_train = recall_score(list(y_train.values), y_pred_train)\n",
    "    recal_valid = recall_score(list(y_valid.values), y_pred_valid)\n",
    "    f1_train = f1_score(list(y_train.values), y_pred_train)\n",
    "    f1_valid = f1_score(list(y_valid.values), y_pred_valid)\n",
    "    acc_train = accuracy_score(list(y_train.values), y_pred_train)\n",
    "    acc_valid = accuracy_score(list(y_valid.values), y_pred_valid)\n",
    "    result.extend([model_name ,acc_train, acc_valid, precision_train, precision_valid, recal_train,\n",
    "                  recal_valid, f1_train, f1_valid])\n",
    "    print(result)\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "550fd453",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(data=results,\n",
    "                       columns=[\"Model\", \"Acc_train\" ,\"Acc_valid\",\n",
    "                                \"Precision_train\", \"Precision_valid\",\"Recall_train\",\n",
    "                                \"Recall_valid\", \"F1-score_train\", \"F1-score_valid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c89a0006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Acc_train</th>\n",
       "      <th>Acc_valid</th>\n",
       "      <th>Precision_train</th>\n",
       "      <th>Precision_valid</th>\n",
       "      <th>Recall_train</th>\n",
       "      <th>Recall_valid</th>\n",
       "      <th>F1-score_train</th>\n",
       "      <th>F1-score_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999758</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999451</td>\n",
       "      <td>0.999964</td>\n",
       "      <td>0.999558</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999855</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>0.999924</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.999481</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ExtraTrees</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999810</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999756</td>\n",
       "      <td>0.999964</td>\n",
       "      <td>0.999466</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>0.999463</td>\n",
       "      <td>0.999509</td>\n",
       "      <td>0.999638</td>\n",
       "      <td>0.999679</td>\n",
       "      <td>0.998159</td>\n",
       "      <td>0.998307</td>\n",
       "      <td>0.998898</td>\n",
       "      <td>0.998992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>0.999888</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999924</td>\n",
       "      <td>0.999964</td>\n",
       "      <td>0.999619</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.999771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.997760</td>\n",
       "      <td>0.997793</td>\n",
       "      <td>0.997462</td>\n",
       "      <td>0.997290</td>\n",
       "      <td>0.993343</td>\n",
       "      <td>0.993653</td>\n",
       "      <td>0.995398</td>\n",
       "      <td>0.995468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.995427</td>\n",
       "      <td>0.995509</td>\n",
       "      <td>0.993726</td>\n",
       "      <td>0.993632</td>\n",
       "      <td>0.987484</td>\n",
       "      <td>0.987917</td>\n",
       "      <td>0.990595</td>\n",
       "      <td>0.990766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.995410</td>\n",
       "      <td>0.995602</td>\n",
       "      <td>0.993943</td>\n",
       "      <td>0.994241</td>\n",
       "      <td>0.987194</td>\n",
       "      <td>0.987688</td>\n",
       "      <td>0.990557</td>\n",
       "      <td>0.990953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.996098</td>\n",
       "      <td>0.996238</td>\n",
       "      <td>0.996001</td>\n",
       "      <td>0.996095</td>\n",
       "      <td>0.987967</td>\n",
       "      <td>0.988451</td>\n",
       "      <td>0.991968</td>\n",
       "      <td>0.992258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.995922</td>\n",
       "      <td>0.996022</td>\n",
       "      <td>0.992115</td>\n",
       "      <td>0.992379</td>\n",
       "      <td>0.991156</td>\n",
       "      <td>0.991304</td>\n",
       "      <td>0.991635</td>\n",
       "      <td>0.991841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>0.996291</td>\n",
       "      <td>0.996502</td>\n",
       "      <td>0.995187</td>\n",
       "      <td>0.995779</td>\n",
       "      <td>0.989580</td>\n",
       "      <td>0.989854</td>\n",
       "      <td>0.992376</td>\n",
       "      <td>0.992808</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Acc_train  Acc_valid  Precision_train  \\\n",
       "0         DecisionTree   0.999991   0.999758         1.000000   \n",
       "1         RandomForest   0.999991   0.999855         0.999990   \n",
       "2           ExtraTrees   0.999991   0.999810         1.000000   \n",
       "3     GradientBoosting   0.999463   0.999509         0.999638   \n",
       "4              XGBoost   0.999988   0.999888         0.999985   \n",
       "5             AdaBoost   0.997760   0.997793         0.997462   \n",
       "6                  SVC   0.995427   0.995509         0.993726   \n",
       "7   LogisticRegression   0.995410   0.995602         0.993943   \n",
       "8                Lasso   0.996098   0.996238         0.996001   \n",
       "9                Ridge   0.995922   0.996022         0.992115   \n",
       "10          ElasticNet   0.996291   0.996502         0.995187   \n",
       "\n",
       "    Precision_valid  Recall_train  Recall_valid  F1-score_train  \\\n",
       "0          0.999451      0.999964      0.999558        0.999982   \n",
       "1          0.999924      0.999975      0.999481        0.999982   \n",
       "2          0.999756      0.999964      0.999466        0.999982   \n",
       "3          0.999679      0.998159      0.998307        0.998898   \n",
       "4          0.999924      0.999964      0.999619        0.999975   \n",
       "5          0.997290      0.993343      0.993653        0.995398   \n",
       "6          0.993632      0.987484      0.987917        0.990595   \n",
       "7          0.994241      0.987194      0.987688        0.990557   \n",
       "8          0.996095      0.987967      0.988451        0.991968   \n",
       "9          0.992379      0.991156      0.991304        0.991635   \n",
       "10         0.995779      0.989580      0.989854        0.992376   \n",
       "\n",
       "    F1-score_valid  \n",
       "0         0.999504  \n",
       "1         0.999702  \n",
       "2         0.999611  \n",
       "3         0.998992  \n",
       "4         0.999771  \n",
       "5         0.995468  \n",
       "6         0.990766  \n",
       "7         0.990953  \n",
       "8         0.992258  \n",
       "9         0.991841  \n",
       "10        0.992808  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "52f5fdf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_cfed3_row0_col1, #T_cfed3_row0_col3, #T_cfed3_row0_col5, #T_cfed3_row0_col7, #T_cfed3_row1_col1, #T_cfed3_row1_col3, #T_cfed3_row1_col4, #T_cfed3_row1_col5, #T_cfed3_row1_col7, #T_cfed3_row2_col1, #T_cfed3_row2_col3, #T_cfed3_row2_col5, #T_cfed3_row2_col7, #T_cfed3_row4_col1, #T_cfed3_row4_col2, #T_cfed3_row4_col3, #T_cfed3_row4_col4, #T_cfed3_row4_col5, #T_cfed3_row4_col6, #T_cfed3_row4_col7, #T_cfed3_row4_col8 {\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_cfed3_row0_col2, #T_cfed3_row0_col8 {\n",
       "  background-color: #be242e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_cfed3_row0_col4 {\n",
       "  background-color: #cb3e38;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_cfed3_row0_col6, #T_cfed3_row1_col2, #T_cfed3_row1_col8 {\n",
       "  background-color: #b50927;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_cfed3_row1_col6 {\n",
       "  background-color: #b70d28;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_cfed3_row2_col2, #T_cfed3_row2_col8 {\n",
       "  background-color: #ba162b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_cfed3_row2_col4 {\n",
       "  background-color: #bb1b2c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_cfed3_row2_col6 {\n",
       "  background-color: #b8122a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_cfed3_row3_col1, #T_cfed3_row3_col7 {\n",
       "  background-color: #da5a49;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_cfed3_row3_col2, #T_cfed3_row3_col8 {\n",
       "  background-color: #d24b40;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_cfed3_row3_col3 {\n",
       "  background-color: #c43032;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_cfed3_row3_col4 {\n",
       "  background-color: #c0282f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_cfed3_row3_col5 {\n",
       "  background-color: #e26952;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_cfed3_row3_col6 {\n",
       "  background-color: #d95847;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_cfed3_row5_col1, #T_cfed3_row5_col7 {\n",
       "  background-color: #e0dbd8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_cfed3_row5_col2, #T_cfed3_row5_col8 {\n",
       "  background-color: #e2dad5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_cfed3_row5_col3 {\n",
       "  background-color: #f7b497;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_cfed3_row5_col4 {\n",
       "  background-color: #f6bda2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_cfed3_row5_col5 {\n",
       "  background-color: #d8dce2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_cfed3_row5_col6 {\n",
       "  background-color: #dddcdc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_cfed3_row6_col1, #T_cfed3_row6_col2, #T_cfed3_row6_col8, #T_cfed3_row7_col1, #T_cfed3_row7_col5, #T_cfed3_row7_col6, #T_cfed3_row7_col7, #T_cfed3_row9_col3, #T_cfed3_row9_col4 {\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_cfed3_row6_col3 {\n",
       "  background-color: #7da0f9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_cfed3_row6_col4, #T_cfed3_row8_col2, #T_cfed3_row8_col8 {\n",
       "  background-color: #6f92f3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_cfed3_row6_col5, #T_cfed3_row7_col2, #T_cfed3_row7_col8 {\n",
       "  background-color: #4055c8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_cfed3_row6_col6 {\n",
       "  background-color: #3f53c6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_cfed3_row6_col7 {\n",
       "  background-color: #3c4ec2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_cfed3_row7_col3 {\n",
       "  background-color: #86a9fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_cfed3_row7_col4 {\n",
       "  background-color: #8caffe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_cfed3_row8_col1, #T_cfed3_row8_col7 {\n",
       "  background-color: #6a8bef;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_cfed3_row8_col3, #T_cfed3_row8_col4 {\n",
       "  background-color: #dbdcde;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_cfed3_row8_col5 {\n",
       "  background-color: #4c66d6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_cfed3_row8_col6 {\n",
       "  background-color: #4e68d8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_cfed3_row9_col1 {\n",
       "  background-color: #5d7ce6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_cfed3_row9_col2, #T_cfed3_row9_col8 {\n",
       "  background-color: #5f7fe8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_cfed3_row9_col5 {\n",
       "  background-color: #a2c1ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_cfed3_row9_col6 {\n",
       "  background-color: #9fbfff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_cfed3_row9_col7 {\n",
       "  background-color: #5e7de7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_cfed3_row10_col1, #T_cfed3_row10_col7 {\n",
       "  background-color: #799cf8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_cfed3_row10_col2, #T_cfed3_row10_col8 {\n",
       "  background-color: #85a8fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_cfed3_row10_col3 {\n",
       "  background-color: #bcd2f7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_cfed3_row10_col4 {\n",
       "  background-color: #cfdaea;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_cfed3_row10_col5 {\n",
       "  background-color: #7699f6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_cfed3_row10_col6 {\n",
       "  background-color: #7597f6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_cfed3_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th class=\"col_heading level0 col1\" >Acc_train</th>\n",
       "      <th class=\"col_heading level0 col2\" >Acc_valid</th>\n",
       "      <th class=\"col_heading level0 col3\" >Precision_train</th>\n",
       "      <th class=\"col_heading level0 col4\" >Precision_valid</th>\n",
       "      <th class=\"col_heading level0 col5\" >Recall_train</th>\n",
       "      <th class=\"col_heading level0 col6\" >Recall_valid</th>\n",
       "      <th class=\"col_heading level0 col7\" >F1-score_train</th>\n",
       "      <th class=\"col_heading level0 col8\" >F1-score_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_cfed3_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_cfed3_row0_col0\" class=\"data row0 col0\" >DecisionTree</td>\n",
       "      <td id=\"T_cfed3_row0_col1\" class=\"data row0 col1\" >0.999991</td>\n",
       "      <td id=\"T_cfed3_row0_col2\" class=\"data row0 col2\" >0.999758</td>\n",
       "      <td id=\"T_cfed3_row0_col3\" class=\"data row0 col3\" >1.000000</td>\n",
       "      <td id=\"T_cfed3_row0_col4\" class=\"data row0 col4\" >0.999451</td>\n",
       "      <td id=\"T_cfed3_row0_col5\" class=\"data row0 col5\" >0.999964</td>\n",
       "      <td id=\"T_cfed3_row0_col6\" class=\"data row0 col6\" >0.999558</td>\n",
       "      <td id=\"T_cfed3_row0_col7\" class=\"data row0 col7\" >0.999982</td>\n",
       "      <td id=\"T_cfed3_row0_col8\" class=\"data row0 col8\" >0.999504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cfed3_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_cfed3_row1_col0\" class=\"data row1 col0\" >RandomForest</td>\n",
       "      <td id=\"T_cfed3_row1_col1\" class=\"data row1 col1\" >0.999991</td>\n",
       "      <td id=\"T_cfed3_row1_col2\" class=\"data row1 col2\" >0.999855</td>\n",
       "      <td id=\"T_cfed3_row1_col3\" class=\"data row1 col3\" >0.999990</td>\n",
       "      <td id=\"T_cfed3_row1_col4\" class=\"data row1 col4\" >0.999924</td>\n",
       "      <td id=\"T_cfed3_row1_col5\" class=\"data row1 col5\" >0.999975</td>\n",
       "      <td id=\"T_cfed3_row1_col6\" class=\"data row1 col6\" >0.999481</td>\n",
       "      <td id=\"T_cfed3_row1_col7\" class=\"data row1 col7\" >0.999982</td>\n",
       "      <td id=\"T_cfed3_row1_col8\" class=\"data row1 col8\" >0.999702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cfed3_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_cfed3_row2_col0\" class=\"data row2 col0\" >ExtraTrees</td>\n",
       "      <td id=\"T_cfed3_row2_col1\" class=\"data row2 col1\" >0.999991</td>\n",
       "      <td id=\"T_cfed3_row2_col2\" class=\"data row2 col2\" >0.999810</td>\n",
       "      <td id=\"T_cfed3_row2_col3\" class=\"data row2 col3\" >1.000000</td>\n",
       "      <td id=\"T_cfed3_row2_col4\" class=\"data row2 col4\" >0.999756</td>\n",
       "      <td id=\"T_cfed3_row2_col5\" class=\"data row2 col5\" >0.999964</td>\n",
       "      <td id=\"T_cfed3_row2_col6\" class=\"data row2 col6\" >0.999466</td>\n",
       "      <td id=\"T_cfed3_row2_col7\" class=\"data row2 col7\" >0.999982</td>\n",
       "      <td id=\"T_cfed3_row2_col8\" class=\"data row2 col8\" >0.999611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cfed3_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_cfed3_row3_col0\" class=\"data row3 col0\" >GradientBoosting</td>\n",
       "      <td id=\"T_cfed3_row3_col1\" class=\"data row3 col1\" >0.999463</td>\n",
       "      <td id=\"T_cfed3_row3_col2\" class=\"data row3 col2\" >0.999509</td>\n",
       "      <td id=\"T_cfed3_row3_col3\" class=\"data row3 col3\" >0.999638</td>\n",
       "      <td id=\"T_cfed3_row3_col4\" class=\"data row3 col4\" >0.999679</td>\n",
       "      <td id=\"T_cfed3_row3_col5\" class=\"data row3 col5\" >0.998159</td>\n",
       "      <td id=\"T_cfed3_row3_col6\" class=\"data row3 col6\" >0.998307</td>\n",
       "      <td id=\"T_cfed3_row3_col7\" class=\"data row3 col7\" >0.998898</td>\n",
       "      <td id=\"T_cfed3_row3_col8\" class=\"data row3 col8\" >0.998992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cfed3_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_cfed3_row4_col0\" class=\"data row4 col0\" >XGBoost</td>\n",
       "      <td id=\"T_cfed3_row4_col1\" class=\"data row4 col1\" >0.999988</td>\n",
       "      <td id=\"T_cfed3_row4_col2\" class=\"data row4 col2\" >0.999888</td>\n",
       "      <td id=\"T_cfed3_row4_col3\" class=\"data row4 col3\" >0.999985</td>\n",
       "      <td id=\"T_cfed3_row4_col4\" class=\"data row4 col4\" >0.999924</td>\n",
       "      <td id=\"T_cfed3_row4_col5\" class=\"data row4 col5\" >0.999964</td>\n",
       "      <td id=\"T_cfed3_row4_col6\" class=\"data row4 col6\" >0.999619</td>\n",
       "      <td id=\"T_cfed3_row4_col7\" class=\"data row4 col7\" >0.999975</td>\n",
       "      <td id=\"T_cfed3_row4_col8\" class=\"data row4 col8\" >0.999771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cfed3_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_cfed3_row5_col0\" class=\"data row5 col0\" >AdaBoost</td>\n",
       "      <td id=\"T_cfed3_row5_col1\" class=\"data row5 col1\" >0.997760</td>\n",
       "      <td id=\"T_cfed3_row5_col2\" class=\"data row5 col2\" >0.997793</td>\n",
       "      <td id=\"T_cfed3_row5_col3\" class=\"data row5 col3\" >0.997462</td>\n",
       "      <td id=\"T_cfed3_row5_col4\" class=\"data row5 col4\" >0.997290</td>\n",
       "      <td id=\"T_cfed3_row5_col5\" class=\"data row5 col5\" >0.993343</td>\n",
       "      <td id=\"T_cfed3_row5_col6\" class=\"data row5 col6\" >0.993653</td>\n",
       "      <td id=\"T_cfed3_row5_col7\" class=\"data row5 col7\" >0.995398</td>\n",
       "      <td id=\"T_cfed3_row5_col8\" class=\"data row5 col8\" >0.995468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cfed3_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_cfed3_row6_col0\" class=\"data row6 col0\" >SVC</td>\n",
       "      <td id=\"T_cfed3_row6_col1\" class=\"data row6 col1\" >0.995427</td>\n",
       "      <td id=\"T_cfed3_row6_col2\" class=\"data row6 col2\" >0.995509</td>\n",
       "      <td id=\"T_cfed3_row6_col3\" class=\"data row6 col3\" >0.993726</td>\n",
       "      <td id=\"T_cfed3_row6_col4\" class=\"data row6 col4\" >0.993632</td>\n",
       "      <td id=\"T_cfed3_row6_col5\" class=\"data row6 col5\" >0.987484</td>\n",
       "      <td id=\"T_cfed3_row6_col6\" class=\"data row6 col6\" >0.987917</td>\n",
       "      <td id=\"T_cfed3_row6_col7\" class=\"data row6 col7\" >0.990595</td>\n",
       "      <td id=\"T_cfed3_row6_col8\" class=\"data row6 col8\" >0.990766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cfed3_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_cfed3_row7_col0\" class=\"data row7 col0\" >LogisticRegression</td>\n",
       "      <td id=\"T_cfed3_row7_col1\" class=\"data row7 col1\" >0.995410</td>\n",
       "      <td id=\"T_cfed3_row7_col2\" class=\"data row7 col2\" >0.995602</td>\n",
       "      <td id=\"T_cfed3_row7_col3\" class=\"data row7 col3\" >0.993943</td>\n",
       "      <td id=\"T_cfed3_row7_col4\" class=\"data row7 col4\" >0.994241</td>\n",
       "      <td id=\"T_cfed3_row7_col5\" class=\"data row7 col5\" >0.987194</td>\n",
       "      <td id=\"T_cfed3_row7_col6\" class=\"data row7 col6\" >0.987688</td>\n",
       "      <td id=\"T_cfed3_row7_col7\" class=\"data row7 col7\" >0.990557</td>\n",
       "      <td id=\"T_cfed3_row7_col8\" class=\"data row7 col8\" >0.990953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cfed3_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_cfed3_row8_col0\" class=\"data row8 col0\" >Lasso</td>\n",
       "      <td id=\"T_cfed3_row8_col1\" class=\"data row8 col1\" >0.996098</td>\n",
       "      <td id=\"T_cfed3_row8_col2\" class=\"data row8 col2\" >0.996238</td>\n",
       "      <td id=\"T_cfed3_row8_col3\" class=\"data row8 col3\" >0.996001</td>\n",
       "      <td id=\"T_cfed3_row8_col4\" class=\"data row8 col4\" >0.996095</td>\n",
       "      <td id=\"T_cfed3_row8_col5\" class=\"data row8 col5\" >0.987967</td>\n",
       "      <td id=\"T_cfed3_row8_col6\" class=\"data row8 col6\" >0.988451</td>\n",
       "      <td id=\"T_cfed3_row8_col7\" class=\"data row8 col7\" >0.991968</td>\n",
       "      <td id=\"T_cfed3_row8_col8\" class=\"data row8 col8\" >0.992258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cfed3_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_cfed3_row9_col0\" class=\"data row9 col0\" >Ridge</td>\n",
       "      <td id=\"T_cfed3_row9_col1\" class=\"data row9 col1\" >0.995922</td>\n",
       "      <td id=\"T_cfed3_row9_col2\" class=\"data row9 col2\" >0.996022</td>\n",
       "      <td id=\"T_cfed3_row9_col3\" class=\"data row9 col3\" >0.992115</td>\n",
       "      <td id=\"T_cfed3_row9_col4\" class=\"data row9 col4\" >0.992379</td>\n",
       "      <td id=\"T_cfed3_row9_col5\" class=\"data row9 col5\" >0.991156</td>\n",
       "      <td id=\"T_cfed3_row9_col6\" class=\"data row9 col6\" >0.991304</td>\n",
       "      <td id=\"T_cfed3_row9_col7\" class=\"data row9 col7\" >0.991635</td>\n",
       "      <td id=\"T_cfed3_row9_col8\" class=\"data row9 col8\" >0.991841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cfed3_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_cfed3_row10_col0\" class=\"data row10 col0\" >ElasticNet</td>\n",
       "      <td id=\"T_cfed3_row10_col1\" class=\"data row10 col1\" >0.996291</td>\n",
       "      <td id=\"T_cfed3_row10_col2\" class=\"data row10 col2\" >0.996502</td>\n",
       "      <td id=\"T_cfed3_row10_col3\" class=\"data row10 col3\" >0.995187</td>\n",
       "      <td id=\"T_cfed3_row10_col4\" class=\"data row10 col4\" >0.995779</td>\n",
       "      <td id=\"T_cfed3_row10_col5\" class=\"data row10 col5\" >0.989580</td>\n",
       "      <td id=\"T_cfed3_row10_col6\" class=\"data row10 col6\" >0.989854</td>\n",
       "      <td id=\"T_cfed3_row10_col7\" class=\"data row10 col7\" >0.992376</td>\n",
       "      <td id=\"T_cfed3_row10_col8\" class=\"data row10 col8\" >0.992808</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1f417cc4b20>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "398c443e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('kddcup\\\\results\\\\all_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fd9a39",
   "metadata": {},
   "source": [
    "# Feature Selection with Orange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "bcc968dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('kddcup/preprocessing/one_hot_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "aa05d50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ = X_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "c3c9581b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>protocol_type=icmp</th>\n",
       "      <th>protocol_type=udp</th>\n",
       "      <th>protocol_type=tcp</th>\n",
       "      <th>service=domain_u</th>\n",
       "      <th>service=smtp</th>\n",
       "      <th>service=OTHER</th>\n",
       "      <th>service=private</th>\n",
       "      <th>service=http</th>\n",
       "      <th>flag=OTHER</th>\n",
       "      <th>flag=S0</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_count</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   protocol_type=icmp  protocol_type=udp  protocol_type=tcp  service=domain_u  \\\n",
       "0                 0.0                1.0                0.0               0.0   \n",
       "1                 0.0                1.0                0.0               0.0   \n",
       "2                 0.0                1.0                0.0               0.0   \n",
       "3                 0.0                1.0                0.0               0.0   \n",
       "4                 0.0                1.0                0.0               0.0   \n",
       "\n",
       "   service=smtp  service=OTHER  service=private  service=http  flag=OTHER  \\\n",
       "0           0.0            1.0              0.0           0.0         0.0   \n",
       "1           0.0            1.0              0.0           0.0         0.0   \n",
       "2           0.0            1.0              0.0           0.0         0.0   \n",
       "3           0.0            1.0              0.0           0.0         0.0   \n",
       "4           0.0            1.0              0.0           0.0         0.0   \n",
       "\n",
       "   flag=S0  ...  dst_host_count  dst_host_srv_count  dst_host_same_srv_rate  \\\n",
       "0      0.0  ...             0.0                 0.0                     0.0   \n",
       "1      0.0  ...             1.0                 1.0                     1.0   \n",
       "2      0.0  ...             2.0                 2.0                     1.0   \n",
       "3      0.0  ...             3.0                 3.0                     1.0   \n",
       "4      0.0  ...             4.0                 4.0                     1.0   \n",
       "\n",
       "   dst_host_diff_srv_rate  dst_host_same_src_port_rate  \\\n",
       "0                     0.0                         0.00   \n",
       "1                     0.0                         1.00   \n",
       "2                     0.0                         0.50   \n",
       "3                     0.0                         0.33   \n",
       "4                     0.0                         0.25   \n",
       "\n",
       "   dst_host_srv_diff_host_rate  dst_host_serror_rate  \\\n",
       "0                          0.0                   0.0   \n",
       "1                          0.0                   0.0   \n",
       "2                          0.0                   0.0   \n",
       "3                          0.0                   0.0   \n",
       "4                          0.0                   0.0   \n",
       "\n",
       "   dst_host_srv_serror_rate  dst_host_rerror_rate  dst_host_srv_rerror_rate  \n",
       "0                       0.0                   0.0                       0.0  \n",
       "1                       0.0                   0.0                       0.0  \n",
       "2                       0.0                   0.0                       0.0  \n",
       "3                       0.0                   0.0                       0.0  \n",
       "4                       0.0                   0.0                       0.0  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "aaac6c7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Info. gain</th>\n",
       "      <th>Gain ratio</th>\n",
       "      <th>Ï‡Â²</th>\n",
       "      <th>ReliefF</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>duration</th>\n",
       "      <td>0.023905</td>\n",
       "      <td>0.044353</td>\n",
       "      <td>43248.009189</td>\n",
       "      <td>0.0038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>protocol_type=icmp</th>\n",
       "      <td>0.005353</td>\n",
       "      <td>0.060931</td>\n",
       "      <td>9536.671847</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>protocol_type=tcp</th>\n",
       "      <td>0.008409</td>\n",
       "      <td>0.019306</td>\n",
       "      <td>960.404776</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>protocol_type=udp</th>\n",
       "      <td>0.020374</td>\n",
       "      <td>0.051269</td>\n",
       "      <td>20186.857387</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>service=OTHER</th>\n",
       "      <td>0.019971</td>\n",
       "      <td>0.033904</td>\n",
       "      <td>28282.340226</td>\n",
       "      <td>0.1740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>service=domain_u</th>\n",
       "      <td>0.017885</td>\n",
       "      <td>0.069328</td>\n",
       "      <td>15049.243399</td>\n",
       "      <td>0.0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>service=http</th>\n",
       "      <td>0.318602</td>\n",
       "      <td>0.320082</td>\n",
       "      <td>179962.182996</td>\n",
       "      <td>0.0240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>service=private</th>\n",
       "      <td>0.440454</td>\n",
       "      <td>0.637750</td>\n",
       "      <td>568684.256737</td>\n",
       "      <td>0.2040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>service=smtp</th>\n",
       "      <td>0.031381</td>\n",
       "      <td>0.072012</td>\n",
       "      <td>28147.010045</td>\n",
       "      <td>0.0340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flag=OTHER</th>\n",
       "      <td>0.026982</td>\n",
       "      <td>0.067874</td>\n",
       "      <td>43301.789919</td>\n",
       "      <td>0.0660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Info. gain  Gain ratio             Ï‡Â²  ReliefF\n",
       "Feature                                                           \n",
       "duration              0.023905    0.044353   43248.009189   0.0038\n",
       "protocol_type=icmp    0.005353    0.060931    9536.671847   0.0000\n",
       "protocol_type=tcp     0.008409    0.019306     960.404776   0.0000\n",
       "protocol_type=udp     0.020374    0.051269   20186.857387   0.0000\n",
       "service=OTHER         0.019971    0.033904   28282.340226   0.1740\n",
       "service=domain_u      0.017885    0.069328   15049.243399   0.0200\n",
       "service=http          0.318602    0.320082  179962.182996   0.0240\n",
       "service=private       0.440454    0.637750  568684.256737   0.2040\n",
       "service=smtp          0.031381    0.072012   28147.010045   0.0340\n",
       "flag=OTHER            0.026982    0.067874   43301.789919   0.0660"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank = pd.read_csv('kddcup\\Feature Scores.csv')\n",
    "rank = rank.iloc[2:,:]\n",
    "rank.index = rank.Feature\n",
    "rank = rank.drop(columns=[\"Feature\"], axis=1).astype('float64')\n",
    "rank.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "e2df6aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['protocol_type=icmp', 'protocol_type=udp', 'protocol_type=tcp',\n",
       "       'service=domain_u', 'service=smtp', 'service=OTHER', 'service=private',\n",
       "       'service=http', 'flag=OTHER', 'flag=S0', 'flag=SF', 'duration',\n",
       "       'src_bytes', 'dst_bytes', 'land', 'wrong_fragment', 'urgent', 'hot',\n",
       "       'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell',\n",
       "       'su_attempted', 'num_root', 'num_file_creations', 'num_shells',\n",
       "       'num_access_files', 'num_outbound_cmds', 'is_host_login',\n",
       "       'is_guest_login', 'count', 'srv_count', 'serror_rate',\n",
       "       'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate',\n",
       "       'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count',\n",
       "       'dst_host_srv_count', 'dst_host_same_srv_rate',\n",
       "       'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate',\n",
       "       'dst_host_srv_diff_host_rate', 'dst_host_serror_rate',\n",
       "       'dst_host_srv_serror_rate', 'dst_host_rerror_rate',\n",
       "       'dst_host_srv_rerror_rate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "7b95df0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for col in X_train.columns:\n",
    "    print(col in rank.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "d0fad54c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Info. gain', 'Gain ratio', 'Ï‡Â²', 'ReliefF']"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(rank.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "0c74e430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.87861000e-05, 5.80680039e-02, 1.16107222e-01, 1.74146439e-01,\n",
       "       2.32185657e-01, 2.90224875e-01, 3.48264093e-01, 4.06303311e-01,\n",
       "       4.64342528e-01, 5.22381746e-01])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_score = rank['Info. gain'].quantile(0.10)\n",
    "max_score = rank['Info. gain'].quantile(0.90)\n",
    "ths = np.round(np.linspace(min_score, max_score, num=10), 10)\n",
    "ths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "d27209f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________Info. gain________________________________________\n",
      "['DecisionTree', 44, 'Info. gain', 0.9999913177648454, 0.9997618586929019, 1.0, 0.9994051160023796, 0.999964400685541, 0.9996185826531391, 0.9999822000259371, 0.9995118379301929]\n",
      "['RandomForest', 44, 'Info. gain', 0.9999913177648454, 0.9998586035989105, 0.9999898286121142, 0.9999084235107374, 0.9999745719182437, 0.999511785796018, 0.9999822002069862, 0.9997100653116036]\n",
      "['ExtraTrees', 44, 'Info. gain', 0.9999913177648454, 0.9997879053983657, 1.0, 0.9997405451604041, 0.999964400685541, 0.9993897322450225, 0.9999822000259371, 0.9995651079219025]\n",
      "['GradientBoosting', 44, 'Info. gain', 0.9994753449327995, 0.9994716239748761, 0.9996231373307938, 0.9996943905383311, 0.9982251198934055, 0.9981386833473186, 0.9989236394726598, 0.9989159312303417]\n",
      "[17:59:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "['XGBoost', 44, 'Info. gain', 0.9999888371262298, 0.9998697664726808, 0.9999847429181712, 0.9998779110582059, 0.9999694863018923, 0.9995880692653902, 0.9999771145518394, 0.9997329691541227]\n",
      "['AdaBoost', 44, 'Info. gain', 0.9977599833301085, 0.9977934719514192, 0.9974619678175477, 0.9972896824181545, 0.9933429281961828, 0.993653215348234, 0.9953981867938663, 0.9954681278706315]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SVC', 44, 'Info. gain', 0.9955336101726029, 0.9956874097667704, 0.9945835425783772, 0.9947745366243507, 0.9870621920023597, 0.9875047677168357, 0.9908085936203829, 0.9911263216727534]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LogisticRegression', 44, 'Info. gain', 0.9953971750487446, 0.9955869439028383, 0.993977692882821, 0.994301162808559, 0.9871079625495212, 0.9875657944923335, 0.9905309167736223, 0.9909220335869449]\n",
      "['Lasso', 44, 'Info. gain', 0.9957382628583903, 0.995903225326328, 0.9936933023279585, 0.9939297320497884, 0.9888014727944954, 0.9892440308185216, 0.9912413522373299, 0.9915813459141618]\n",
      "['Ridge', 44, 'Info. gain', 0.9959838460813352, 0.9960743893908047, 0.9922320015067677, 0.9924855667898708, 0.9912934248066194, 0.9914104813486917, 0.9917624910959602, 0.9919477327715827]\n",
      "['ElasticNet', 44, 'Info. gain', 0.9957705111603932, 0.995966481611026, 0.9934671903810891, 0.9938556302958798, 0.9891625515554358, 0.9895796780837592, 0.9913101979032348, 0.9917130450736958]\n",
      "['DecisionTree', 22, 'Info. gain', 0.9999913177648454, 0.9996465089972763, 1.0, 0.9992219917012448, 0.999964400685541, 0.9993287054695248, 0.9999822000259371, 0.9992753457363632]\n",
      "['RandomForest', 22, 'Info. gain', 0.9999913177648454, 0.9997990682721359, 0.9999898286121142, 0.9999084011419325, 0.9999745719182437, 0.999267678694027, 0.9999822002069862, 0.9995879372443686]\n",
      "['ExtraTrees', 22, 'Info. gain', 0.9999913177648454, 0.9996948814502805, 1.0, 0.999664158028913, 0.999964400685541, 0.9990845983675337, 0.9999822000259371, 0.9993742941733051]\n",
      "['GradientBoosting', 22, 'Info. gain', 0.9991156523335367, 0.9991479006355396, 0.9992151986464725, 0.9993272582716654, 0.997157140459638, 0.9971775116332291, 0.9981851087280235, 0.9982512275771485]\n",
      "[18:13:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "['XGBoost', 22, 'Info. gain', 0.9999727129752284, 0.9998176730617531, 0.9999643992371265, 0.9998015933579562, 0.9999237157547309, 0.9994507590205203, 0.9999440570821192, 0.9996261454065479]\n",
      "['AdaBoost', 22, 'Info. gain', 0.9961748552547368, 0.9964204384776817, 0.9946281899913622, 0.9951241202716999, 0.9896609419578606, 0.9901746891448623, 0.9921383487473362, 0.9926432351411704]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SVC', 22, 'Info. gain', 0.9923918813659388, 0.9924390134996354, 0.9933699024650495, 0.9934428267321348, 0.9753144182309175, 0.9754367228621558, 0.9842593638052616, 0.9843574386845468]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LogisticRegression', 22, 'Info. gain', 0.9927590158810484, 0.9928259931236697, 0.9933137174800006, 0.9933309552243436, 0.976885873683461, 0.9771454725760927, 0.985031306568482, 0.9851717401670487]\n",
      "['Lasso', 22, 'Info. gain', 0.9932551436041694, 0.9932762290324021, 0.9923518656812504, 0.9921549247922908, 0.9798965585634151, 0.9801815546571058, 0.9860848827271377, 0.9861318966377332]\n",
      "['Ridge', 22, 'Info. gain', 0.9926945192770427, 0.9927106434280442, 0.9904604197415313, 0.990254433307633, 0.9794795380226107, 0.9797543672286215, 0.9849393739484411, 0.9849764178074312]\n",
      "['ElasticNet', 22, 'Info. gain', 0.9931745228491623, 0.9932204146635509, 0.991933657291109, 0.9917581145529472, 0.9799830140413868, 0.9803493782897246, 0.9859221227075163, 0.9860207463785907]\n",
      "['DecisionTree', 21, 'Info. gain', 0.9999900774455376, 0.9996427880393528, 1.0, 0.9991915185721912, 0.9999593150691898, 0.9993439621633992, 0.9999796571207705, 0.9992677345537757]\n",
      "['RandomForest', 21, 'Info. gain', 0.9999900774455376, 0.9997730215666721, 0.9999898285603853, 0.9998473375671715, 0.9999694863018923, 0.9992219086124037, 0.9999796573276849, 0.9995345252539127]\n",
      "['ExtraTrees', 21, 'Info. gain', 0.9999900774455376, 0.999679997618587, 1.0, 0.9996488817647508, 0.9999593150691898, 0.9990388282859104, 0.9999796571207705, 0.9993437619229301]\n",
      "['GradientBoosting', 21, 'Info. gain', 0.9991280555266148, 0.9991479006355396, 0.9992559447972195, 0.999296722113503, 0.9971673116923405, 0.9972080250209779, 0.998210535693831, 0.9982512809939444]\n",
      "[18:21:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "['XGBoost', 21, 'Info. gain', 0.9999665113786893, 0.9998139521038296, 0.9999898275774376, 0.9998473631992674, 0.9998728595912182, 0.9993897322450225, 0.9999313401637157, 0.9996184953456433]\n",
      "['AdaBoost', 21, 'Info. gain', 0.9961748552547368, 0.9964204384776817, 0.9946281899913622, 0.9951241202716999, 0.9896609419578606, 0.9901746891448623, 0.9921383487473362, 0.9926432351411704]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SVC', 21, 'Info. gain', 0.9924042845590169, 0.9924352925417119, 0.9934009126838188, 0.9934427248430605, 0.9753347606963226, 0.9754214661682813, 0.9842849444430187, 0.9843496200953034]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LogisticRegression', 21, 'Info. gain', 0.9927602562003562, 0.9928259931236697, 0.9933137520555171, 0.9933156531583927, 0.9768909592998123, 0.9771607292699672, 0.9850339089522198, 0.985171968252015]\n",
      "['Lasso', 21, 'Info. gain', 0.9932042905125495, 0.9932762290324021, 0.9920866198488375, 0.9920181559933304, 0.9799525003432791, 0.9803188649019757, 0.9859822289765415, 0.9861338121657189]\n",
      "['Ridge', 21, 'Info. gain', 0.992617619479959, 0.992617619479959, 0.9902304081118464, 0.9899332480305857, 0.979393082544639, 0.9796933404531238, 0.9847819305880127, 0.984786676072754]\n",
      "['ElasticNet', 21, 'Info. gain', 0.9932117324283963, 0.9932613452007085, 0.9920564644831811, 0.9918657776131382, 0.9800135277394944, 0.9804104050652224, 0.9859982245144917, 0.9861048237975033]\n",
      "['DecisionTree', 20, 'Info. gain', 0.9999900774455376, 0.9996204622918125, 0.999994914228463, 0.9991762139402908, 0.999964400685541, 0.999267678694027, 0.9999796572242282, 0.9992219442240801]\n",
      "['RandomForest', 20, 'Info. gain', 0.9999900774455376, 0.9997618586929019, 0.9999898285603853, 0.9998473305751058, 0.9999694863018923, 0.9991761385307804, 0.9999796573276849, 0.9995116218732353]\n",
      "['ExtraTrees', 20, 'Info. gain', 0.9999900774455376, 0.9997023233661274, 0.999994914228463, 0.9996946797954355, 0.999964400685541, 0.9990845983675337, 0.9999796572242282, 0.9993895459748188]\n",
      "['GradientBoosting', 20, 'Info. gain', 0.9991280555266148, 0.9991479006355396, 0.9992559447972195, 0.999296722113503, 0.9971673116923405, 0.9972080250209779, 0.998210535693831, 0.9982512809939444]\n",
      "[18:30:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "['XGBoost', 20, 'Info. gain', 0.9999677516979971, 0.9997990682721359, 0.9999847415989787, 0.9998015782163407, 0.9998830308239207, 0.9993744755511481, 0.9999338836250081, 0.9995879812607773]\n",
      "['AdaBoost', 20, 'Info. gain', 0.9962281889849723, 0.9963981127301412, 0.9943716929865779, 0.9946533895059364, 0.9901389898948804, 0.9905561064917232, 0.9922508275382299, 0.992600519798196]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SVC', 20, 'Info. gain', 0.9915149756153224, 0.9915608674297111, 0.993053318508204, 0.9930188708646939, 0.9720087676025896, 0.9722328171485239, 0.9824183562538067, 0.9825159191476897]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LogisticRegression', 20, 'Info. gain', 0.9922393220910791, 0.9922864542247756, 0.9920395335373419, 0.9921225654385312, 0.976011147671042, 0.9761232740865055, 0.9839600706505439, 0.9840578929963932]\n",
      "['Lasso', 20, 'Info. gain', 0.9924551376506368, 0.9924427344575587, 0.9906934344162667, 0.9905010502903744, 0.9782539044819537, 0.9783965214737966, 0.9844343738565036, 0.9844115773396065]\n",
      "['Ridge', 20, 'Info. gain', 0.9920173049349824, 0.9920036614225967, 0.9898373879047918, 0.9896502718734552, 0.9773028942242655, 0.977435349759707, 0.9835302065633509, 0.983504885593448]\n",
      "['ElasticNet', 20, 'Info. gain', 0.9924142071134793, 0.9923757572149374, 0.9903180477560621, 0.9899836404605364, 0.978462414752356, 0.9786406285757876, 0.9843545350360183, 0.9842794558804348]\n",
      "['DecisionTree', 19, 'Info. gain', 0.9999789145717674, 0.9996241832497358, 0.9999949139956668, 0.9993133335367901, 0.9999186301383797, 0.9991456251430315, 0.9999567706121536, 0.9992294723029623]\n",
      "['RandomForest', 19, 'Info. gain', 0.9999789145717674, 0.9997581377349785, 0.9999796566034665, 0.9998015448966507, 0.9999338869874335, 0.9992066519185293, 0.9999567712717129, 0.9995040098892798]\n",
      "['ExtraTrees', 19, 'Info. gain', 0.9999789145717674, 0.9996874395344337, 0.9999949139956668, 0.999725178252439, 0.9999186301383797, 0.9989930582042871, 0.9999567706121536, 0.9993589841424887]\n",
      "['GradientBoosting', 19, 'Info. gain', 0.9991491409548474, 0.9991813892568503, 0.9993272548430007, 0.9993578865293767, 0.9971825685413944, 0.9972843084903501, 0.9982537597621448, 0.9983200207706523]\n",
      "[18:39:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "['XGBoost', 19, 'Info. gain', 0.9999590694628425, 0.9997916263562892, 0.9999847410557154, 0.9997558034828529, 0.9998474315094618, 0.9993897322450225, 0.9999160815687151, 0.9995727343475805]\n",
      "['AdaBoost', 19, 'Info. gain', 0.9963881901756788, 0.9965655558366946, 0.994446060940188, 0.9946267834180393, 0.9907238357752768, 0.9912731711038218, 0.992581458742007, 0.9929471456189013]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SVC', 19, 'Info. gain', 0.9904768283546916, 0.9906306279488591, 0.9965365553704414, 0.9966901508345548, 0.9643040588304099, 0.9647875505377984, 0.980155386579686, 0.9804794095757876]\n",
      "['LogisticRegression', 19, 'Info. gain', 0.9895850387723816, 0.9896780627204668, 0.9918630781290828, 0.991542810605942, 0.965214384157288, 0.9659165458845068, 0.9783572991600147, 0.9785619339083125]\n",
      "['Lasso', 19, 'Info. gain', 0.9911317169492114, 0.9913524937860003, 0.9974273218420375, 0.9976855860820278, 0.9661297951005172, 0.9667861774353498, 0.9815291297249261, 0.9819928715326205]\n",
      "['Ridge', 19, 'Info. gain', 0.9905611700676222, 0.9907534195603316, 0.9948634709532163, 0.9950075357950263, 0.9662874492074067, 0.9669387443740941, 0.9803672688058863, 0.9807723555218544]\n",
      "['ElasticNet', 19, 'Info. gain', 0.9910213285308169, 0.9912110973849108, 0.9976823141121318, 0.9979195233817202, 0.9654279800440414, 0.9659775726600046, 0.9812901741753229, 0.9816887869015133]\n",
      "['DecisionTree', 17, 'Info. gain', 0.9999789145717674, 0.9996651137868933, 0.9999949139956668, 0.9992372816718785, 0.9999186301383797, 0.9993897322450225, 0.9999567706121536, 0.9993135011441647]\n",
      "['RandomForest', 17, 'Info. gain', 0.9999789145717674, 0.9997469748612082, 0.9999796566034665, 0.999755758750706, 0.9999338869874335, 0.9992066519185293, 0.9999567712717129, 0.9994811299159125]\n",
      "['ExtraTrees', 17, 'Info. gain', 0.9999789145717674, 0.9996725557027402, 0.9999949139956668, 0.9997099015191999, 0.9999186301383797, 0.9989472881226639, 0.9999567706121536, 0.9993284493284493]\n",
      "['GradientBoosting', 17, 'Info. gain', 0.9988613868754372, 0.9989097593284415, 0.9991430801169083, 0.9992196346053799, 0.9961857877365448, 0.9963078800823861, 0.9976622424137475, 0.9977616330147671]\n",
      "[18:48:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "['XGBoost', 17, 'Info. gain', 0.9999404646732255, 0.9997841844404424, 0.9999694807143548, 0.999755796028633, 0.9997864041132465, 0.9993592188572736, 0.9998779340335172, 0.9995574681071844]\n",
      "['AdaBoost', 17, 'Info. gain', 0.9961574907844275, 0.9963534612350603, 0.9957122878555804, 0.9963255077410329, 0.9885014214297702, 0.9886947898390419, 0.9920937520735399, 0.9924954819738414]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SVC', 17, 'Info. gain', 0.9897239545348554, 0.9897227142155477, 0.9962167516755891, 0.9960651696401763, 0.9615171410699119, 0.9616599282935387, 0.9785594319090516, 0.9785602285252977]\n",
      "['LogisticRegression', 17, 'Info. gain', 0.9894882938663729, 0.9894138747079048, 0.9930765199161425, 0.9926766406839326, 0.963617500622988, 0.9637043252727134, 0.9781252500432333, 0.9779759554719494]\n",
      "['Lasso', 17, 'Info. gain', 0.9906827213597869, 0.990775745307872, 0.9973648637986987, 0.9973502413173087, 0.9643447437612201, 0.9647417804561752, 0.9805769011986886, 0.9807750471123795]\n",
      "['Ridge', 17, 'Info. gain', 0.9901903145945893, 0.9903031836515993, 0.9950579199194157, 0.995013606405235, 0.9645685108806762, 0.9650774277214128, 0.9795760262988681, 0.9798169116622005]\n",
      "['ElasticNet', 17, 'Info. gain', 0.9906070618820109, 0.9907422566865614, 0.9973221519586696, 0.9975225260765965, 0.9640752060946026, 0.9644366465786864, 0.9804169004760661, 0.9807006112507369]\n",
      "['DecisionTree', 16, 'Info. gain', 0.9999789145717674, 0.9996651137868933, 0.9999949139956668, 0.9993134487756503, 0.9999186301383797, 0.9993134487756503, 0.9999567706121536, 0.9993134487756503]\n",
      "['RandomForest', 16, 'Info. gain', 0.9999789145717674, 0.9997506958191317, 0.9999796566034665, 0.9997557624790109, 0.9999338869874335, 0.9992219086124037, 0.9999567712717129, 0.9994887642592805]\n",
      "['ExtraTrees', 16, 'Info. gain', 0.9999789145717674, 0.9996502299551997, 0.9999949139956668, 0.9997403985645568, 0.9999186301383797, 0.9988252345716683, 0.9999567706121536, 0.9992826070365566]\n",
      "['GradientBoosting', 16, 'Info. gain', 0.9988613868754372, 0.9989097593284415, 0.9991430801169083, 0.9992196346053799, 0.9961857877365448, 0.9963078800823861, 0.9976622424137475, 0.9977616330147671]\n",
      "[18:56:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "['XGBoost', 16, 'Info. gain', 0.9999503872276879, 0.9998102311459062, 0.9999643959777628, 0.9998473608694325, 0.999832174660408, 0.9993744755511481, 0.9998982809480216, 0.999610862283399]\n",
      "['AdaBoost', 16, 'Info. gain', 0.9961574907844275, 0.9963534612350603, 0.9957122878555804, 0.9963255077410329, 0.9885014214297702, 0.9886947898390419, 0.9920937520735399, 0.9924954819738414]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SVC', 16, 'Info. gain', 0.9897475206017037, 0.989726435173471, 0.996264193692863, 0.995971182102569, 0.9615679972334247, 0.9617667251506599, 0.9786086569466226, 0.9785701534473257]\n",
      "['LogisticRegression', 16, 'Info. gain', 0.9894957357822197, 0.989425037581675, 0.9930353942417541, 0.9926150558584604, 0.9636886992519058, 0.9638111221298344, 0.9781419777780647, 0.9780010527293558]\n",
      "['Lasso', 16, 'Info. gain', 0.9907583808375628, 0.9908724902138807, 0.9975436049569736, 0.9976180711108307, 0.9644820554027045, 0.964879090701045, 0.9807342746846145, 0.9809755000426558]\n",
      "['Ridge', 16, 'Info. gain', 0.9902523305599794, 0.9904148123893015, 0.9954490100153275, 0.9956237701692248, 0.9644413704718944, 0.9649401174765428, 0.979699902619459, 0.9800418377624546]\n",
      "['ElasticNet', 16, 'Info. gain', 0.9907596211568707, 0.9908985369193445, 0.9975802591226861, 0.9977596516416074, 0.9644515417045969, 0.9648485773132962, 0.9807362128170121, 0.9810281707619757]\n",
      "['DecisionTree', 16, 'Info. gain', 0.9999789145717674, 0.9996651137868933, 0.9999949139956668, 0.9993134487756503, 0.9999186301383797, 0.9993134487756503, 0.9999567706121536, 0.9993134487756503]\n",
      "['RandomForest', 16, 'Info. gain', 0.9999789145717674, 0.9997506958191317, 0.9999796566034665, 0.9997557624790109, 0.9999338869874335, 0.9992219086124037, 0.9999567712717129, 0.9994887642592805]\n",
      "['ExtraTrees', 16, 'Info. gain', 0.9999789145717674, 0.9996502299551997, 0.9999949139956668, 0.9997403985645568, 0.9999186301383797, 0.9988252345716683, 0.9999567706121536, 0.9992826070365566]\n",
      "['GradientBoosting', 16, 'Info. gain', 0.9988613868754372, 0.9989097593284415, 0.9991430801169083, 0.9992196346053799, 0.9961857877365448, 0.9963078800823861, 0.9976622424137475, 0.9977616330147671]\n",
      "[19:03:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "['XGBoost', 16, 'Info. gain', 0.9999503872276879, 0.9998102311459062, 0.9999643959777628, 0.9998473608694325, 0.999832174660408, 0.9993744755511481, 0.9998982809480216, 0.999610862283399]\n",
      "['AdaBoost', 16, 'Info. gain', 0.9961574907844275, 0.9963534612350603, 0.9957122878555804, 0.9963255077410329, 0.9885014214297702, 0.9886947898390419, 0.9920937520735399, 0.9924954819738414]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SVC', 16, 'Info. gain', 0.9897475206017037, 0.989726435173471, 0.996264193692863, 0.995971182102569, 0.9615679972334247, 0.9617667251506599, 0.9786086569466226, 0.9785701534473257]\n",
      "['LogisticRegression', 16, 'Info. gain', 0.9894957357822197, 0.989425037581675, 0.9930353942417541, 0.9926150558584604, 0.9636886992519058, 0.9638111221298344, 0.9781419777780647, 0.9780010527293558]\n",
      "['Lasso', 16, 'Info. gain', 0.9907583808375628, 0.9908724902138807, 0.9975436049569736, 0.9976180711108307, 0.9644820554027045, 0.964879090701045, 0.9807342746846145, 0.9809755000426558]\n",
      "['Ridge', 16, 'Info. gain', 0.9902523305599794, 0.9904148123893015, 0.9954490100153275, 0.9956237701692248, 0.9644413704718944, 0.9649401174765428, 0.979699902619459, 0.9800418377624546]\n",
      "['ElasticNet', 16, 'Info. gain', 0.9907596211568707, 0.9908985369193445, 0.9975802591226861, 0.9977596516416074, 0.9644515417045969, 0.9648485773132962, 0.9807362128170121, 0.9810281707619757]\n",
      "['DecisionTree', 12, 'Info. gain', 0.9999268211608396, 0.9996316251655827, 0.9998525163757679, 0.9992067124332571, 0.9998474315094618, 0.9992829353879015, 0.9998499739361499, 0.9992448224569969]\n",
      "['RandomForest', 12, 'Info. gain', 0.9999268211608396, 0.999653950913123, 0.9998270969579235, 0.9994658282714203, 0.9998728595912182, 0.9991151117552827, 0.9998499777509375, 0.9992904392409989]\n",
      "['ExtraTrees', 12, 'Info. gain', 0.9999268211608396, 0.9993041808683227, 0.9998525163757679, 0.9990684178375077, 0.9998474315094618, 0.9980776565718209, 0.9998499739361499, 0.9985727914520129]\n",
      "['GradientBoosting', 12, 'Info. gain', 0.9982313046670734, 0.9983069641448494, 0.9989418313984695, 0.9990186758256923, 0.9938006336677974, 0.994034632695095, 0.996364600488459, 0.9965204224436575]\n",
      "[19:11:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "['XGBoost', 12, 'Info. gain', 0.9998610842375261, 0.9997767425245956, 0.9997406203750324, 0.9996642707808756, 0.9996897774025723, 0.9994202456327714, 0.9997151982423663, 0.9995422433129377]\n",
      "['AdaBoost', 12, 'Info. gain', 0.9941915846815604, 0.9942473990504115, 0.9940441872915208, 0.9944374913085802, 0.982068116745409, 0.9819055610649172, 0.9880198620096854, 0.9881317938954738]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SVC', 12, 'Info. gain', 0.9870299809983082, 0.9871031598374685, 0.9959720387025276, 0.9963381678046597, 0.9506644357762939, 0.9506140819284461, 0.9727909742116616, 0.9729392108180697]\n",
      "['LogisticRegression', 12, 'Info. gain', 0.9873884332782632, 0.9874417670084986, 0.99690872751499, 0.9971213817367663, 0.9512391104239878, 0.9512548630711725, 0.9735386120783431, 0.9736482529767714]\n",
      "['Lasso', 12, 'Info. gain', 0.986817886396674, 0.986760831708515, 0.997363509473718, 0.9973203254119799, 0.9484572782798412, 0.9482645510717828, 0.9722957896273434, 0.9721739946506499]\n",
      "['Ridge', 12, 'Info. gain', 0.9860178804431413, 0.9859161742599015, 0.9944832148878503, 0.9943647540983607, 0.9479283741793086, 0.9476237699290564, 0.9706478918713434, 0.9704317665164168]\n",
      "['ElasticNet', 12, 'Info. gain', 0.9869543215205322, 0.9869915310997663, 0.9972481231130941, 0.9974186721392955, 0.9491285796382093, 0.9491189259287512, 0.9725935306348983, 0.9726695644016385]\n",
      "['DecisionTree', 5, 'Info. gain', 0.9953822912170509, 0.9952334529001146, 0.9936688776972525, 0.9927767383369629, 0.9873571577507336, 0.9876420779617057, 0.9905029628817117, 0.9902027517953974]\n",
      "['RandomForest', 5, 'Info. gain', 0.9953822912170509, 0.9952222900263444, 0.9935274252967663, 0.9925648847940396, 0.9874995550085692, 0.9878099015943245, 0.9905043193486927, 0.9901816847127913]\n",
      "['ExtraTrees', 5, 'Info. gain', 0.9953822912170509, 0.9950399630880974, 0.9936688776972525, 0.992529070659344, 0.9873571577507336, 0.9870928369822259, 0.9905029628817117, 0.9898034896084326]\n",
      "['GradientBoosting', 5, 'Info. gain', 0.9949035279642391, 0.9949246133924717, 0.9948490705708176, 0.9944378534120148, 0.9841989899965926, 0.9846975360439393, 0.9894953740275743, 0.9895437262357415]\n",
      "[19:18:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "['XGBoost', 5, 'Info. gain', 0.9953587251502026, 0.9953153139744296, 0.9931280965747856, 0.992371557243957, 0.9878046919896457, 0.9883896559615531, 0.990459241430655, 0.9903766042177838]\n",
      "['AdaBoost', 5, 'Info. gain', 0.9897760479457831, 0.9897971333740158, 0.9968195531551298, 0.996756996187493, 0.961145891076269, 0.9612937676405523, 0.978657739320455, 0.9787042358533062]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SVC', 5, 'Info. gain', 0.9850343072320539, 0.9851012844746752, 0.9947938169203631, 0.9949174078780177, 0.9435750865826183, 0.9437333129910749, 0.9685077595251891, 0.9686496813291784]\n",
      "['LogisticRegression', 5, 'Info. gain', 0.9857512117919637, 0.9857971036063524, 0.9952122395485061, 0.9952980068684405, 0.9461280659909578, 0.9462354107864825, 0.9700496391774079, 0.9701468023369493]\n",
      "['Lasso', 5, 'Info. gain', 0.9846969403803315, 0.9847068629347939, 0.9942130188304827, 0.994255740237172, 0.9427410455010095, 0.9427416278892364, 0.9677931326125203, 0.9678136795777407]\n",
      "['Ridge', 5, 'Info. gain', 0.9847403515561046, 0.9847701192194919, 0.9942300061131906, 0.9942891155368231, 0.9429037852242502, 0.9429704782973529, 0.9678869269018441, 0.9679500732144675]\n",
      "['ElasticNet', 5, 'Info. gain', 0.9847155451699485, 0.9847403515561046, 0.9940862982264256, 0.9941452744000515, 0.9429393845387092, 0.9429857349912274, 0.96783757754816, 0.9678899441734461]\n",
      "________________________________________Gain ratio________________________________________\n",
      "['DecisionTree', 44, 'Gain ratio', 0.9999913177648454, 0.9997953473142126, 1.0, 0.9995423340961098, 0.999964400685541, 0.9996185826531391, 0.9999822000259371, 0.9995804569205539]\n",
      "['RandomForest', 44, 'Gain ratio', 0.9999913177648454, 0.9998437197672169, 0.9999898286121142, 0.9999084179195604, 0.9999745719182437, 0.9994507590205203, 0.9999822002069862, 0.9996795360903403]\n",
      "['ExtraTrees', 44, 'Gain ratio', 0.9999913177648454, 0.9997916263562892, 1.0, 0.9997863150022132, 0.999964400685541, 0.9993592188572736, 0.9999822000259371, 0.9995727213074728]\n",
      "['GradientBoosting', 44, 'Gain ratio', 0.999391003219869, 0.9994269724797952, 0.9995466585167074, 0.9996179764979142, 0.9979555822267879, 0.9980318864901976, 0.9987504866994272, 0.9988243018337839]\n",
      "[19:29:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "['XGBoost', 44, 'Gain ratio', 0.999987596806922, 0.9998846503043743, 0.9999796573276849, 0.9999084332936544, 0.9999694863018923, 0.9996185826531391, 0.9999745717889256, 0.99976348696508]\n",
      "['AdaBoost', 44, 'Gain ratio', 0.9973568795550727, 0.9975441677705509, 0.9962545287544012, 0.9966930508137238, 0.9928953939572707, 0.9932260279197498, 0.9945721250219689, 0.9949565190811696]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SVC', 44, 'Gain ratio', 0.9954864780389063, 0.9956055486924554, 0.9949884071649876, 0.9950772260168605, 0.9864620892729095, 0.9868639865741093, 0.9907069035525217, 0.9909535883078385]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LogisticRegression', 44, 'Gain ratio', 0.995513765063678, 0.9957060145563874, 0.9948569904933803, 0.9950640444082235, 0.9867061988577706, 0.9872911740025936, 0.9907648312928471, 0.9911623703839849]\n",
      "['Lasso', 44, 'Gain ratio', 0.9962009019602006, 0.9963385774033667, 0.9960636782056933, 0.9962794988085172, 0.9883285104738269, 0.9886795331451674, 0.9921810184842459, 0.9924649666896393]\n",
      "['Ridge', 44, 'Gain ratio', 0.9956154712469178, 0.9957618289252386, 0.9948845172070899, 0.9952936110000308, 0.9870977913168186, 0.9872911740025936, 0.9909758581869516, 0.991276242120662]\n",
      "['ElasticNet', 44, 'Gain ratio', 0.9962902049503625, 0.9964316013514519, 0.9968848790902, 0.9971366113488715, 0.9878758906185635, 0.9882065756350599, 0.9923599385934215, 0.9926515099269749]\n",
      "['DecisionTree', 23, 'Gain ratio', 0.9999913177648454, 0.9996204622918125, 1.0, 0.9991153007214875, 0.999964400685541, 0.9993287054695248, 0.9999822000259371, 0.9992219917012448]\n",
      "['RandomForest', 23, 'Gain ratio', 0.9999913177648454, 0.9997841844404424, 0.9999898286121142, 0.9998778681892433, 0.9999745719182437, 0.9992371653062782, 0.9999822002069862, 0.9995574140772847]\n",
      "['ExtraTrees', 23, 'Gain ratio', 0.9999913177648454, 0.999698602408204, 1.0, 0.9997099325211444, 0.999964400685541, 0.9990540849797849, 0.9999822000259371, 0.9993819011499692]\n",
      "['GradientBoosting', 23, 'Gain ratio', 0.9989382866725209, 0.9989953413606799, 0.999224810154987, 0.9994643813604713, 0.9964197260887033, 0.9964146769395072, 0.9978202967044719, 0.9979371991748797]\n",
      "[19:42:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "['XGBoost', 23, 'Gain ratio', 0.9999677516979971, 0.9998139521038296, 0.9999745698489958, 0.9998473631992674, 0.9998932020566232, 0.9993897322450225, 0.9999338842975207, 0.9996184953456433]\n",
      "['AdaBoost', 23, 'Gain ratio', 0.9964415239059143, 0.9965395091312308, 0.994255570973798, 0.9946110626310875, 0.9911357706997299, 0.9911816309405752, 0.9926932196440077, 0.9928933854994497]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SVC', 23, 'Gain ratio', 0.9925134326581035, 0.9925990146903418, 0.9935112349367954, 0.993600497048773, 0.975675496991858, 0.9759401937600122, 0.9845125931399717, 0.9846911679815278]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LogisticRegression', 23, 'Gain ratio', 0.9929301799455251, 0.9930269248515338, 0.9934306757979067, 0.9934588855304968, 0.9774758051802088, 0.9778472804943169, 0.9853886616014028, 0.9855912655697371]\n",
      "['Lasso', 23, 'Gain ratio', 0.9933667723418717, 0.9934734398023427, 0.9925684061986599, 0.9926022023506155, 0.9801406681482763, 0.9805477153100923, 0.9863153908353036, 0.9865381368290175]\n",
      "['Ridge', 23, 'Gain ratio', 0.9927788609899733, 0.9927850625865122, 0.9903528383830597, 0.9900761241409067, 0.9799372434942253, 0.9802425814326036, 0.98511751082572, 0.9851348139743482]\n",
      "['ElasticNet', 23, 'Gain ratio', 0.9932873919061723, 0.9933952996859512, 0.9926979464584783, 0.9925845821103043, 0.9796829626766616, 0.9802425814326036, 0.9861475141289213, 0.9863749760122817]\n",
      "['DecisionTree', 19, 'Gain ratio', 0.9999789145717674, 0.9996204622918125, 0.9999949139956668, 0.9991000747395555, 0.9999186301383797, 0.9993439621633992, 0.9999567706121536, 0.9992220035696308]\n",
      "['RandomForest', 19, 'Gain ratio', 0.9999789145717674, 0.9997618586929019, 0.9999796566034665, 0.9997557736632424, 0.9999338869874335, 0.999267678694027, 0.9999567712717129, 0.9995116665903645]\n",
      "['ExtraTrees', 19, 'Gain ratio', 0.9999789145717674, 0.9996576718710465, 0.9999949139956668, 0.9997709329138861, 0.9999186301383797, 0.9988252345716683, 0.9999567706121536, 0.9992978599993895]\n",
      "['GradientBoosting', 19, 'Gain ratio', 0.9985550280064099, 0.9986530132317264, 0.9993460178618871, 0.9994483181365412, 0.9947262158437292, 0.9950263177969334, 0.9970307653489042, 0.9972324159021406]\n",
      "[19:51:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "['XGBoost', 19, 'Gain ratio', 0.9999454259504567, 0.9997879053983657, 0.9999643952533787, 0.9997557997557998, 0.9998118321950029, 0.9993744755511481, 0.999888107904668, 0.9995651012856216]\n",
      "['AdaBoost', 19, 'Gain ratio', 0.9964117562425271, 0.9966995103219373, 0.9963060118248609, 0.9969563747040919, 0.9889540412850335, 0.9894881379205126, 0.992616413358345, 0.9932082175208078]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SVC', 19, 'Gain ratio', 0.990361478659066, 0.9903255093991398, 0.9968117680482338, 0.996638841110287, 0.963561558843124, 0.963582271721718, 0.9799046823564094, 0.9798318284774583]\n",
      "['LogisticRegression', 19, 'Gain ratio', 0.9898603896587137, 0.9897524818789349, 0.993847153653449, 0.9933994436673949, 0.9643955999247329, 0.9643908764970631, 0.9788999042429906, 0.9786802502012758]\n",
      "['Lasso', 19, 'Gain ratio', 0.9911763684442922, 0.9913562147439237, 0.9984482586305751, 0.9988322550102572, 0.9653211821006646, 0.9656876954763902, 0.9816053079313858, 0.9819803746654773]\n",
      "['Ridge', 19, 'Gain ratio', 0.9906839616790947, 0.9908724902138807, 0.996148801091348, 0.9963652956540895, 0.9655347779874182, 0.9660996262110001, 0.9806029084016188, 0.9809990782267872]\n",
      "['ElasticNet', 19, 'Gain ratio', 0.9910597784293589, 0.9912371440903747, 0.9986679373035471, 0.99913112164297, 0.9646295382768915, 0.964909604088794, 0.98135366976749, 0.9817222243781287]\n",
      "['DecisionTree', 17, 'Gain ratio', 0.9999789145717674, 0.9996651137868933, 0.9999949139956668, 0.9992372816718785, 0.9999186301383797, 0.9993897322450225, 0.9999567706121536, 0.9993135011441647]\n",
      "['RandomForest', 17, 'Gain ratio', 0.9999789145717674, 0.9997469748612082, 0.9999796566034665, 0.999755758750706, 0.9999338869874335, 0.9992066519185293, 0.9999567712717129, 0.9994811299159125]\n",
      "['ExtraTrees', 17, 'Gain ratio', 0.9999789145717674, 0.9996725557027402, 0.9999949139956668, 0.9997099015191999, 0.9999186301383797, 0.9989472881226639, 0.9999567706121536, 0.9993284493284493]\n",
      "['GradientBoosting', 17, 'Gain ratio', 0.9988613868754372, 0.9989097593284415, 0.9991430801169083, 0.9992196346053799, 0.9961857877365448, 0.9963078800823861, 0.9976622424137475, 0.9977616330147671]\n",
      "[20:00:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "['XGBoost', 17, 'Gain ratio', 0.9999404646732255, 0.9997841844404424, 0.9999694807143548, 0.999755796028633, 0.9997864041132465, 0.9993592188572736, 0.9998779340335172, 0.9995574681071844]\n",
      "['AdaBoost', 17, 'Gain ratio', 0.9961574907844275, 0.9963534612350603, 0.9957122878555804, 0.9963255077410329, 0.9885014214297702, 0.9886947898390419, 0.9920937520735399, 0.9924954819738414]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SVC', 17, 'Gain ratio', 0.9897239545348554, 0.9897227142155477, 0.9962167516755891, 0.9960651696401763, 0.9615171410699119, 0.9616599282935387, 0.9785594319090516, 0.9785602285252977]\n",
      "['LogisticRegression', 17, 'Gain ratio', 0.9894882938663729, 0.9894138747079048, 0.9930765199161425, 0.9926766406839326, 0.963617500622988, 0.9637043252727134, 0.9781252500432333, 0.9779759554719494]\n",
      "['Lasso', 17, 'Gain ratio', 0.9906827213597869, 0.990775745307872, 0.9973648637986987, 0.9973502413173087, 0.9643447437612201, 0.9647417804561752, 0.9805769011986886, 0.9807750471123795]\n",
      "['Ridge', 17, 'Gain ratio', 0.9901903145945893, 0.9903031836515993, 0.9950579199194157, 0.995013606405235, 0.9645685108806762, 0.9650774277214128, 0.9795760262988681, 0.9798169116622005]\n",
      "['ElasticNet', 17, 'Gain ratio', 0.9906070618820109, 0.9907422566865614, 0.9973221519586696, 0.9975225260765965, 0.9640752060946026, 0.9644366465786864, 0.9804169004760661, 0.9807006112507369]\n",
      "['DecisionTree', 12, 'Gain ratio', 0.9909952818253531, 0.9906343489067826, 0.9990828637841883, 0.9980560735847267, 0.9639633225348746, 0.9634754748645968, 0.9812089430936395, 0.9804609568464278]\n",
      "['RandomForest', 12, 'Gain ratio', 0.9909952818253531, 0.9906976051914805, 0.9990039578184041, 0.9982612819094286, 0.9640396067801437, 0.9635365016400946, 0.9812104020870429, 0.9805915689775638]\n",
      "['ExtraTrees', 12, 'Gain ratio', 0.9909952818253531, 0.9906790004018634, 0.9990828637841883, 0.9982768977836796, 0.9639633225348746, 0.963444961476848, 0.9812089430936395, 0.9805516952244903]\n",
      "['GradientBoosting', 12, 'Gain ratio', 0.9899571345647223, 0.9898157381636329, 0.9974984695277701, 0.9973079115728131, 0.9612323465542406, 0.9608360668243192, 0.9790296723531986, 0.9787323319838686]\n",
      "[20:06:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "['XGBoost', 12, 'Gain ratio', 0.9908997772386523, 0.9907236518969443, 0.9990088152178498, 0.9985135989879823, 0.9636429287047443, 0.9633991913952247, 0.9810072352156974, 0.9806421555305354]\n",
      "['AdaBoost', 12, 'Gain ratio', 0.9879217705806183, 0.9876985131052138, 0.9947270060935903, 0.994360514066943, 0.9555415418571653, 0.9549774963765352, 0.9747406100850797, 0.9742711721948106]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SVC', 12, 'Gain ratio', 0.9846733743134832, 0.9844947683331597, 0.9948175676401405, 0.9950477480965286, 0.9420646585262901, 0.9411091616446716, 0.9677227241738693, 0.9673271285979755]\n",
      "['LogisticRegression', 12, 'Gain ratio', 0.9873723091272617, 0.9871701370800899, 0.9958671531759624, 0.9957527662903767, 0.9521748638326222, 0.9514532000915401, 0.973531025195053, 0.9730990684538205]\n",
      "['Lasso', 12, 'Gain ratio', 0.9880854927292482, 0.9879478172860822, 0.9982948520517726, 0.9983363726525258, 0.9527749665620725, 0.9521702647036387, 0.9750039032006245, 0.9747069710055521]\n",
      "['Ridge', 12, 'Gain ratio', 0.9881202216698667, 0.9880073526128567, 0.9983641411208031, 0.9984324514539813, 0.9528512508073416, 0.9523228316423831, 0.975076892652133, 0.9748326995306997]\n",
      "['ElasticNet', 12, 'Gain ratio', 0.988117741031251, 0.9880147945287034, 0.9982897786302246, 0.9983368515320156, 0.9529122782035568, 0.9524448851933786, 0.9750733748256697, 0.9748510661555158]\n",
      "['DecisionTree', 10, 'Gain ratio', 0.9895403872773006, 0.9892315477696578, 0.9997079284159099, 0.9991554726962729, 0.957392706209029, 0.9566557327027233, 0.978092860501425, 0.9774438434319029]\n",
      "['RandomForest', 10, 'Gain ratio', 0.9895403872773006, 0.9892836411805855, 0.9995965001698947, 0.9991556610536713, 0.9574995041524057, 0.9568693264169654, 0.9780952504643038, 0.9775554100813617]\n",
      "['ExtraTrees', 10, 'Gain ratio', 0.9895403872773006, 0.9892575944751216, 0.9997079284159099, 0.9992351085189789, 0.957392706209029, 0.9566862460904721, 0.978092860501425, 0.9774978760551524]\n",
      "['GradientBoosting', 10, 'Gain ratio', 0.9887267378113822, 0.9885506124696742, 0.9989464722783867, 0.9987863302459278, 0.9547837850208256, 0.9542146616828133, 0.9763659955327078, 0.9759918854601489]\n",
      "[20:14:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "['XGBoost', 10, 'Gain ratio', 0.9894994567401432, 0.9893022459702026, 0.9996176537748724, 0.9993466343702193, 0.9573113363474086, 0.9567625295598444, 0.9780071906563033, 0.9775910582476597]\n",
      "['AdaBoost', 10, 'Gain ratio', 0.9866430013742737, 0.986478038906336, 0.9966757166983774, 0.9965830886953174, 0.9483962508836259, 0.9478068502555497, 0.9719368011236745, 0.9715831782424424]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SVC', 10, 'Gain ratio', 0.9845716681302434, 0.9843756976796106, 0.9947355415408747, 0.9948694782356168, 0.9417239222307547, 0.9407887710733084, 0.9675041210908416, 0.9670736393077545]\n",
      "['LogisticRegression', 10, 'Gain ratio', 0.9873549446569525, 0.9871478113325495, 0.9959143285773564, 0.9957523593567859, 0.9520578946565429, 0.9513616599282936, 0.9734924221348025, 0.9730509955683166]\n",
      "['Lasso', 10, 'Gain ratio', 0.9843756976796106, 0.9841152306249721, 0.9952476291966718, 0.9951035842409748, 0.94042709006118, 0.9394919520939813, 0.9670610692013022, 0.9664984657882553]\n",
      "['Ridge', 10, 'Gain ratio', 0.9842888753280644, 0.9841077887091253, 0.9950965616724439, 0.9951194285529591, 0.9402134941744265, 0.939446182012358, 0.9668768190031405, 0.9664817183710948]\n",
      "['ElasticNet', 10, 'Gain ratio', 0.9843049994790659, 0.9841152306249721, 0.9951715265404553, 0.9951515935095998, 0.9402084085580752, 0.939446182012358, 0.9669095150180699, 0.9664968882680248]\n",
      "['DecisionTree', 10, 'Gain ratio', 0.9895403872773006, 0.9892315477696578, 0.9997079284159099, 0.9991554726962729, 0.957392706209029, 0.9566557327027233, 0.978092860501425, 0.9774438434319029]\n",
      "['RandomForest', 10, 'Gain ratio', 0.9895403872773006, 0.9892836411805855, 0.9995965001698947, 0.9991556610536713, 0.9574995041524057, 0.9568693264169654, 0.9780952504643038, 0.9775554100813617]\n",
      "['ExtraTrees', 10, 'Gain ratio', 0.9895403872773006, 0.9892575944751216, 0.9997079284159099, 0.9992351085189789, 0.957392706209029, 0.9566862460904721, 0.978092860501425, 0.9774978760551524]\n",
      "['GradientBoosting', 10, 'Gain ratio', 0.9887267378113822, 0.9885506124696742, 0.9989464722783867, 0.9987863302459278, 0.9547837850208256, 0.9542146616828133, 0.9763659955327078, 0.9759918854601489]\n",
      "[20:21:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "['XGBoost', 10, 'Gain ratio', 0.9894994567401432, 0.9893022459702026, 0.9996176537748724, 0.9993466343702193, 0.9573113363474086, 0.9567625295598444, 0.9780071906563033, 0.9775910582476597]\n",
      "['AdaBoost', 10, 'Gain ratio', 0.9866430013742737, 0.986478038906336, 0.9966757166983774, 0.9965830886953174, 0.9483962508836259, 0.9478068502555497, 0.9719368011236745, 0.9715831782424424]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SVC', 10, 'Gain ratio', 0.9845716681302434, 0.9843756976796106, 0.9947355415408747, 0.9948694782356168, 0.9417239222307547, 0.9407887710733084, 0.9675041210908416, 0.9670736393077545]\n",
      "['LogisticRegression', 10, 'Gain ratio', 0.9873549446569525, 0.9871478113325495, 0.9959143285773564, 0.9957523593567859, 0.9520578946565429, 0.9513616599282936, 0.9734924221348025, 0.9730509955683166]\n",
      "['Lasso', 10, 'Gain ratio', 0.9843756976796106, 0.9841152306249721, 0.9952476291966718, 0.9951035842409748, 0.94042709006118, 0.9394919520939813, 0.9670610692013022, 0.9664984657882553]\n",
      "['Ridge', 10, 'Gain ratio', 0.9842888753280644, 0.9841077887091253, 0.9950965616724439, 0.9951194285529591, 0.9402134941744265, 0.939446182012358, 0.9668768190031405, 0.9664817183710948]\n",
      "['ElasticNet', 10, 'Gain ratio', 0.9843049994790659, 0.9841152306249721, 0.9951715265404553, 0.9951515935095998, 0.9402084085580752, 0.939446182012358, 0.9669095150180699, 0.9664968882680248]\n",
      "['DecisionTree', 9, 'Gain ratio', 0.9894337198168296, 0.9891013142423386, 0.9997131047380221, 0.9993301435406698, 0.9569502575864682, 0.9559539247844993, 0.9778643904847281, 0.9771609029591797]\n",
      "['RandomForest', 9, 'Gain ratio', 0.9894337198168296, 0.9891608495691131, 0.9996387782204516, 0.9993780896188805, 0.957021456215386, 0.9561522618048669, 0.9778660008366178, 0.9772874351877119]\n",
      "['ExtraTrees', 9, 'Gain ratio', 0.9894337198168296, 0.9891645705270364, 0.9997131047380221, 0.999409954231585, 0.9569502575864682, 0.9561370051109924, 0.9778643904847281, 0.9772947010572934]\n",
      "['GradientBoosting', 9, 'Gain ratio', 0.9889810032694817, 0.9888966615565511, 0.9992182639077233, 0.9993136143789806, 0.9555669699389218, 0.9551300633152796, 0.976905239734218, 0.9767224163754369]\n",
      "[20:28:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "['XGBoost', 9, 'Gain ratio', 0.9893754248093629, 0.9891720124428833, 0.9995537493027333, 0.9994099730501204, 0.9568638021084965, 0.9561675184987414, 0.9777430183855244, 0.9773106491805323]\n",
      "['AdaBoost', 9, 'Gain ratio', 0.9879279721771573, 0.9877840951374521, 0.9969105933149706, 0.996903431763767, 0.9534564391531432, 0.9528720726218628, 0.9746994372164962, 0.9743905768555716]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SVC', 9, 'Gain ratio', 0.9846646920783286, 0.9844910473752363, 0.9948014285330684, 0.9950636403232832, 0.942044316060885, 0.9410786482569228, 0.967704355367022, 0.9673185189831732]\n",
      "['LogisticRegression', 9, 'Gain ratio', 0.9877195985334465, 0.9876538616101329, 0.9960788064269319, 0.9962834766241845, 0.9534004973732791, 0.9529330993973606, 0.9742724917563358, 0.9741262340335939]\n",
      "['Lasso', 9, 'Gain ratio', 0.9842826737315254, 0.9840929048774316, 0.9951177499663572, 0.9951351176622705, 0.940167723627265, 0.9393698985429857, 0.9668626179368632, 0.9664487470274766]\n",
      "['Ridge', 9, 'Gain ratio', 0.9842888753280644, 0.9841077887091253, 0.99508590251464, 0.9951034259857789, 0.940223665407129, 0.9394614387062323, 0.9668771654572792, 0.9664822444575241]\n",
      "['ElasticNet', 9, 'Gain ratio', 0.9843049994790659, 0.9841226725408189, 0.9951395430201577, 0.9951517502181713, 0.9402389222561829, 0.9394766954001068, 0.9669105533735337, 0.9665131098781226]\n",
      "['DecisionTree', 6, 'Gain ratio', 0.9886002252419863, 0.9884650304374358, 0.9992116673236106, 0.9990250451515975, 0.954010771335432, 0.9536349073155848, 0.976088206446376, 0.9758024228799801]\n",
      "['RandomForest', 6, 'Gain ratio', 0.9886002252419863, 0.9884799142691294, 0.9991957133117436, 0.999057010884332, 0.9540260281844858, 0.9536654207033336, 0.976088579701699, 0.9758336455601347]\n",
      "['ExtraTrees', 6, 'Gain ratio', 0.9886002252419863, 0.9884761933112061, 0.9992116673236106, 0.9990569958124221, 0.954010771335432, 0.9536501640094591, 0.976088206446376, 0.975825651193106]\n",
      "['GradientBoosting', 6, 'Gain ratio', 0.9883918515982755, 0.9883124711625761, 0.9982758804184715, 0.9982912261650004, 0.9540514562662422, 0.9537111907849569, 0.9756627790563118, 0.9754921467194119]\n",
      "[20:34:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "['XGBoost', 6, 'Gain ratio', 0.9885927833261395, 0.9884836352270528, 0.9990308839190628, 0.9989453836566425, 0.9541531685932677, 0.9537874742543291, 0.9760764554551769, 0.9758442795039297]\n",
      "['AdaBoost', 6, 'Gain ratio', 0.9873760300851852, 0.9872668819860985, 0.9961944806663651, 0.9963724691180466, 0.9518748124678971, 0.9512548630711725, 0.973530497922074, 0.9732910819375282]\n",
      "['SVC', 6, 'Gain ratio', 0.9854708996284003, 0.9854064030243946, 0.9930778871023651, 0.993244433060656, 0.9470282200851332, 0.9466015714394691, 0.9695065443526973, 0.9693622472893166]\n",
      "['LogisticRegression', 6, 'Gain ratio', 0.9875645586199712, 0.9874566508401923, 0.9958389354476997, 0.995931976261885, 0.9529936480651773, 0.952460141887253, 0.9739453127030244, 0.973711094994112]\n",
      "['Lasso', 6, 'Gain ratio', 0.9874219218995738, 0.9873673478500306, 0.9954991338356732, 0.9956930929972883, 0.9527342816312623, 0.9523228316423831, 0.9736473510923316, 0.9735251686357079]\n",
      "['Ridge', 6, 'Gain ratio', 0.9874132396644192, 0.9873673478500306, 0.995435779450912, 0.9956456552252138, 0.9527597097130187, 0.9523686017240064, 0.9736303256452099, 0.9735264073112343]\n",
      "['ElasticNet', 6, 'Gain ratio', 0.9874318444540362, 0.9873710688079539, 0.9955256557411895, 0.9956931616978514, 0.9527495384803161, 0.9523380883362575, 0.9736680032327054, 0.9735331732118907]\n",
      "['DecisionTree', 5, 'Gain ratio', 0.9863924568740977, 0.986158036524923, 0.9970923383382955, 0.997009502066016, 0.9469671926889179, 0.9460828438477382, 0.9713835583923042, 0.9708788025864634]\n",
      "['RandomForest', 5, 'Gain ratio', 0.9863924568740977, 0.9861691993986932, 0.9970710445715265, 0.9970256278336924, 0.946987535154323, 0.9461133572354871, 0.9713841555182855, 0.9709025152063128]\n",
      "['ExtraTrees', 5, 'Gain ratio', 0.9863924568740977, 0.9861691993986932, 0.9970923383382955, 0.9970256278336924, 0.9469671926889179, 0.9461133572354871, 0.9713835583923042, 0.9709025152063128]\n",
      "['GradientBoosting', 5, 'Gain ratio', 0.9860178804431413, 0.9858343131855865, 0.9975305990981318, 0.9974377981178291, 0.9450092303936776, 0.9443435807460523, 0.9705598921948326, 0.9701648106206064]\n",
      "[20:37:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "['XGBoost', 5, 'Gain ratio', 0.9863825343196353, 0.9861617574828464, 0.9970070460240293, 0.9969775891450435, 0.9470078776197282, 0.9461286139293615, 0.9713644840312463, 0.9708877703585995]\n",
      "['AdaBoost', 5, 'Gain ratio', 0.9850330669127461, 0.9848482593358834, 0.9943855739250624, 0.9944341671358482, 0.9439615934253152, 0.9431535586238462, 0.968517721337351, 0.9681152611385171]\n",
      "['SVC', 5, 'Gain ratio', 0.9810020291623875, 0.9809784630955393, 0.9749277062989816, 0.975274077103355, 0.9464433742047368, 0.9459913036844916, 0.9604744000970269, 0.9604095351682904]\n",
      "['LogisticRegression', 5, 'Gain ratio', 0.9849772525438949, 0.9848929108309643, 0.9931685883352844, 0.9931187142100958, 0.9449024324503008, 0.9446029445419177, 0.968434494800761, 0.9682534717878143]\n",
      "['Lasso', 5, 'Gain ratio', 0.9854597367546302, 0.9853543096134669, 0.9971126548520303, 0.9972718614299321, 0.9431122954946525, 0.9425280341749943, 0.9693610059145306, 0.969127474665077]\n",
      "['Ridge', 5, 'Gain ratio', 0.9855130704848656, 0.9853766353610074, 0.9973485928180748, 0.9974487736351746, 0.9431072098783012, 0.942451750705622, 0.9694697991489183, 0.9691706674197494]\n",
      "['ElasticNet', 5, 'Gain ratio', 0.9855130704848656, 0.9853766353610074, 0.9973485928180748, 0.9974487736351746, 0.9431072098783012, 0.942451750705622, 0.9694697991489183, 0.9691706674197494]\n",
      "________________________________________Ï‡Â²________________________________________\n",
      "['DecisionTree', 44, 'Ï‡Â²', 0.9999913177648454, 0.9997618586929019, 1.0, 0.9994051160023796, 0.999964400685541, 0.9996185826531391, 0.9999822000259371, 0.9995118379301929]\n",
      "['RandomForest', 44, 'Ï‡Â²', 0.9999913177648454, 0.9998586035989105, 0.9999898286121142, 0.9999084235107374, 0.9999745719182437, 0.999511785796018, 0.9999822002069862, 0.9997100653116036]\n",
      "['ExtraTrees', 44, 'Ï‡Â²', 0.9999913177648454, 0.9997879053983657, 1.0, 0.9997405451604041, 0.999964400685541, 0.9993897322450225, 0.9999822000259371, 0.9995651079219025]\n",
      "['GradientBoosting', 44, 'Ï‡Â²', 0.9994753449327995, 0.9994716239748761, 0.9996231373307938, 0.9996943905383311, 0.9982251198934055, 0.9981386833473186, 0.9989236394726598, 0.9989159312303417]\n",
      "[20:46:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "['XGBoost', 44, 'Ï‡Â²', 0.9999888371262298, 0.9998697664726808, 0.9999847429181712, 0.9998779110582059, 0.9999694863018923, 0.9995880692653902, 0.9999771145518394, 0.9997329691541227]\n",
      "['AdaBoost', 44, 'Ï‡Â²', 0.9977599833301085, 0.9977934719514192, 0.9974619678175477, 0.9972896824181545, 0.9933429281961828, 0.993653215348234, 0.9953981867938663, 0.9954681278706315]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SVC', 44, 'Ï‡Â²', 0.9955336101726029, 0.9956874097667704, 0.9945835425783772, 0.9947745366243507, 0.9870621920023597, 0.9875047677168357, 0.9908085936203829, 0.9911263216727534]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LogisticRegression', 44, 'Ï‡Â²', 0.9953971750487446, 0.9955869439028383, 0.993977692882821, 0.994301162808559, 0.9871079625495212, 0.9875657944923335, 0.9905309167736223, 0.9909220335869449]\n",
      "['Lasso', 44, 'Ï‡Â²', 0.9957382628583903, 0.995903225326328, 0.9936933023279585, 0.9939297320497884, 0.9888014727944954, 0.9892440308185216, 0.9912413522373299, 0.9915813459141618]\n",
      "['Ridge', 44, 'Ï‡Â²', 0.9959838460813352, 0.9960743893908047, 0.9922320015067677, 0.9924855667898708, 0.9912934248066194, 0.9914104813486917, 0.9917624910959602, 0.9919477327715827]\n",
      "['ElasticNet', 44, 'Ï‡Â²', 0.9957705111603932, 0.995966481611026, 0.9934671903810891, 0.9938556302958798, 0.9891625515554358, 0.9895796780837592, 0.9913101979032348, 0.9917130450736958]\n",
      "['DecisionTree', 25, 'Ï‡Â²', 0.9999913177648454, 0.999635346123506, 1.0, 0.9992067245350948, 0.999964400685541, 0.9992981920817758, 0.9999822000259371, 0.9992524562152926]\n",
      "['RandomForest', 25, 'Ï‡Â²', 0.9999913177648454, 0.9997990682721359, 0.9999898286121142, 0.9998778756468775, 0.9999745719182437, 0.9992981920817758, 0.9999822002069862, 0.9995879498214449]\n",
      "['ExtraTrees', 25, 'Ï‡Â²', 0.9999913177648454, 0.9997134862398976, 1.0, 0.9996641836610086, 0.999964400685541, 0.999160881836906, 0.9999822000259371, 0.9994124693835507]\n",
      "['GradientBoosting', 25, 'Ï‡Â²', 0.9988291385734344, 0.9988985964546713, 0.9981975284754859, 0.9984416298718164, 0.9969994863527485, 0.9970402013883591, 0.9975981477240924, 0.9977404235179161]\n",
      "[20:59:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "['XGBoost', 25, 'Ï‡Â²', 0.9999727129752284, 0.9998102311459062, 0.9999694847500038, 0.9997710762468713, 0.9999186301383797, 0.9994507590205203, 0.9999440567976077, 0.9996108919729303]\n",
      "['AdaBoost', 25, 'Ï‡Â²', 0.9962753211186688, 0.9964613690148392, 0.9946556851043827, 0.9950490496627835, 0.9900474488005574, 0.9904187962468534, 0.9923462170738234, 0.9927285239132929]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SVC', 25, 'Ï‡Â²', 0.9923794781728609, 0.9924315715837886, 0.9934615803080622, 0.9935039706590828, 0.9751720209730819, 0.9753451826989091, 0.9842318412097135, 0.9843408370030486]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LogisticRegression', 25, 'Ï‡Â²', 0.9928135899305918, 0.9928334350395166, 0.9933764561713745, 0.9933617681271811, 0.9770486134067018, 0.9771454725760927, 0.9851448848049144, 0.9851868943239502]\n",
      "['Lasso', 25, 'Ï‡Â²', 0.9933642917032561, 0.993439951181032, 0.9928830941276509, 0.9928295472106321, 0.9798151887017947, 0.9801815546571058, 0.9863058580211838, 0.986465010940079]\n",
      "['Ridge', 25, 'Ï‡Â²', 0.9926635112943476, 0.9927069224701207, 0.9907923992259233, 0.9906931518266426, 0.9790167469346448, 0.9792966664123884, 0.9848693752573996, 0.9849619445126442]\n",
      "['ElasticNet', 25, 'Ï‡Â²', 0.9932911128640958, 0.9933692529804873, 0.9925406964764063, 0.9925381204715042, 0.979855873632605, 0.9801815546571058, 0.9861574959117396, 0.9863211385234198]\n",
      "['DecisionTree', 21, 'Ï‡Â²', 0.9999900774455376, 0.9996427880393528, 1.0, 0.9991915185721912, 0.9999593150691898, 0.9993439621633992, 0.9999796571207705, 0.9992677345537757]\n",
      "['RandomForest', 21, 'Ï‡Â²', 0.9999900774455376, 0.9997730215666721, 0.9999898285603853, 0.9998473375671715, 0.9999694863018923, 0.9992219086124037, 0.9999796573276849, 0.9995345252539127]\n",
      "['ExtraTrees', 21, 'Ï‡Â²', 0.9999900774455376, 0.999679997618587, 1.0, 0.9996488817647508, 0.9999593150691898, 0.9990388282859104, 0.9999796571207705, 0.9993437619229301]\n",
      "['GradientBoosting', 21, 'Ï‡Â²', 0.9991280555266148, 0.9991479006355396, 0.9992559447972195, 0.999296722113503, 0.9971673116923405, 0.9972080250209779, 0.998210535693831, 0.9982512809939444]\n",
      "[21:09:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "['XGBoost', 21, 'Ï‡Â²', 0.9999665113786893, 0.9998139521038296, 0.9999898275774376, 0.9998473631992674, 0.9998728595912182, 0.9993897322450225, 0.9999313401637157, 0.9996184953456433]\n",
      "['AdaBoost', 21, 'Ï‡Â²', 0.9961748552547368, 0.9964204384776817, 0.9946281899913622, 0.9951241202716999, 0.9896609419578606, 0.9901746891448623, 0.9921383487473362, 0.9926432351411704]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SVC', 21, 'Ï‡Â²', 0.9924042845590169, 0.9924352925417119, 0.9934009126838188, 0.9934427248430605, 0.9753347606963226, 0.9754214661682813, 0.9842849444430187, 0.9843496200953034]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LogisticRegression', 21, 'Ï‡Â²', 0.9927602562003562, 0.9928259931236697, 0.9933137520555171, 0.9933156531583927, 0.9768909592998123, 0.9771607292699672, 0.9850339089522198, 0.985171968252015]\n",
      "['Lasso', 21, 'Ï‡Â²', 0.9932042905125495, 0.9932762290324021, 0.9920866198488375, 0.9920181559933304, 0.9799525003432791, 0.9803188649019757, 0.9859822289765415, 0.9861338121657189]\n",
      "['Ridge', 21, 'Ï‡Â²', 0.992617619479959, 0.992617619479959, 0.9902304081118464, 0.9899332480305857, 0.979393082544639, 0.9796933404531238, 0.9847819305880127, 0.984786676072754]\n",
      "['ElasticNet', 21, 'Ï‡Â²', 0.9932117324283963, 0.9932613452007085, 0.9920564644831811, 0.9918657776131382, 0.9800135277394944, 0.9804104050652224, 0.9859982245144917, 0.9861048237975033]\n",
      "['DecisionTree', 16, 'Ï‡Â²', 0.9999900774455376, 0.9995609269650378, 0.999994914228463, 0.9991607794070525, 0.999964400685541, 0.9990388282859104, 0.9999796572242282, 0.9990998001251125]\n",
      "['RandomForest', 16, 'Ï‡Â²', 0.9999900774455376, 0.9997395329453614, 0.9999847429957637, 0.9998015297476375, 0.9999745719182437, 0.999130368449157, 0.9999796574311405, 0.9994658364238512]\n",
      "['ExtraTrees', 16, 'Ï‡Â²', 0.9999900774455376, 0.9996055784601188, 0.999994914228463, 0.9995724864493473, 0.999964400685541, 0.9988099778777939, 0.9999796572242282, 0.9991910866910867]\n",
      "['GradientBoosting', 16, 'Ï‡Â²', 0.9990437138136842, 0.9990846443508417, 0.9989707845475019, 0.9991744002935465, 0.9971062842961252, 0.997070714776108, 0.9980376636234757, 0.9981214490805791]\n",
      "[21:17:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "['XGBoost', 16, 'Ï‡Â²', 0.9999665113786893, 0.9998027892300594, 0.9999898275774376, 0.9998015812448487, 0.9998728595912182, 0.9993897322450225, 0.9999313401637157, 0.999595614322883]\n",
      "['AdaBoost', 16, 'Ï‡Â²', 0.9963174919751341, 0.9964836947623796, 0.9957100440258012, 0.9961902421039696, 0.9891625515554358, 0.9893660843695171, 0.9924254986950632, 0.9927664362642661]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SVC', 16, 'Ï‡Â²', 0.99000922797565, 0.9899869022281096, 0.991446888356093, 0.9911082635329416, 0.9673808567229305, 0.9676252955984438, 0.9792660356814666, 0.9792260126450357]\n",
      "['LogisticRegression', 16, 'Ï‡Â²', 0.9905636507062379, 0.9905227201690803, 0.9913390206750989, 0.9909904292795461, 0.9697812676407317, 0.9699595697612328, 0.9804416565978561, 0.9803622233016446]\n",
      "['Lasso', 16, 'Ï‡Â²', 0.9905041153794633, 0.9904855105898462, 0.9894128920311812, 0.9888702617118376, 0.971459521036652, 0.9719276832710352, 0.9803540177265472, 0.9803257750044242]\n",
      "['Ridge', 16, 'Ï‡Â²', 0.9899484523295677, 0.9899087621117181, 0.9891901709956148, 0.9886913372843654, 0.9693795039489811, 0.9697154626592417, 0.9791846463650187, 0.9791114671267485]\n",
      "['ElasticNet', 16, 'Ï‡Â²', 0.9905165185725413, 0.9904817896319228, 0.9908013857652613, 0.9903162024567577, 0.970122003936267, 0.9704630406590892, 0.9803526551924391, 0.9802891135495007]\n",
      "['DecisionTree', 13, 'Ï‡Â²', 0.9999751936138439, 0.9996279042076592, 0.9999949139180632, 0.9991914692376928, 0.9999033732893258, 0.9992829353879015, 0.9999491415086662, 0.9992372002196863]\n",
      "['RandomForest', 13, 'Ï‡Â²', 0.9999751936138439, 0.999717207197821, 0.9999796562930714, 0.9997557289201692, 0.9999186301383797, 0.9990845983675337, 0.9999491422846304, 0.999420050974467]\n",
      "['ExtraTrees', 13, 'Ï‡Â²', 0.9999751936138439, 0.999516275469957, 0.9999949139180632, 0.9995418098510882, 0.9999033732893258, 0.9984743306125563, 0.9999491415086662, 0.9990077850709816]\n",
      "['GradientBoosting', 13, 'Ï‡Â²', 0.9989047980512104, 0.9989395269918288, 0.9980814639905549, 0.998107101422727, 0.9974266781262555, 0.9975436722862155, 0.9977539636309989, 0.9978253073184131]\n",
      "[21:24:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "['XGBoost', 13, 'Ï‡Â²', 0.999924340522224, 0.9997804634825189, 0.9999491332302434, 0.9998168218592581, 0.999740633566085, 0.9992829353879015, 0.9998448725284507, 0.9995498073327992]\n",
      "['AdaBoost', 13, 'Ï‡Â²', 0.9958771786208641, 0.9959999702323367, 0.9955497449306571, 0.9957095405056283, 0.9875097262412718, 0.9878556716759478, 0.9915134370579914, 0.9917670575080606]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SVC', 13, 'Ï‡Â²', 0.9878337079097643, 0.987892002917231, 0.9895345302854028, 0.9892859948158039, 0.9602711650638499, 0.9607597833549469, 0.9746832502690662, 0.9748142414860681]\n",
      "['LogisticRegression', 13, 'Ï‡Â²', 0.9892327880889656, 0.9892315477696578, 0.9911723200752627, 0.9909876020752025, 0.9644413704718944, 0.9646197269051796, 0.9776241548807489, 0.9776259026177848]\n",
      "['Lasso', 13, 'Ï‡Â²', 0.989594961326844, 0.9896036435619986, 0.9921360299500136, 0.9917404592116605, 0.9649855314214806, 0.9654130749866504, 0.9783724557536384, 0.9783996907614999]\n",
      "['Ridge', 13, 'Ï‡Â²', 0.9890182128487158, 0.9889748016729427, 0.9898216307302237, 0.9891205802357208, 0.9648939903271577, 0.9654130749866504, 0.9771988648361893, 0.9771230475837523]\n",
      "['ElasticNet', 13, 'Ï‡Â²', 0.9896185273936923, 0.9896036435619986, 0.9921985704350917, 0.991771288851272, 0.9650211307359395, 0.9653825615989016, 0.9784211611838712, 0.9783990227761199]\n",
      "['DecisionTree', 12, 'Ï‡Â²', 0.9999677516979971, 0.9996204622918125, 0.9999694841292042, 0.9991914445681856, 0.9998982876729745, 0.9992524220001525, 0.9999338846337716, 0.9992219323538835]\n",
      "['RandomForest', 12, 'Ï‡Â²', 0.9999677516979971, 0.9997469748612082, 0.9999491422846303, 0.9997405015951519, 0.9999186301383797, 0.9992219086124037, 0.9999338859787418, 0.9994811378342083]\n",
      "['ExtraTrees', 12, 'Ï‡Â²', 0.9999677516979971, 0.9994120886481016, 0.9999694841292042, 0.9994500374280084, 0.9998982876729745, 0.9981386833473186, 0.9999338846337716, 0.9987939299563373]\n",
      "['GradientBoosting', 12, 'Ï‡Â²', 0.9988154950610485, 0.9988465030437436, 0.9981416235591218, 0.998243336133812, 0.9969994863527485, 0.9970249446944847, 0.9975702280423672, 0.9976337684146249]\n",
      "[21:31:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "['XGBoost', 12, 'Ï‡Â²', 0.9999094566905304, 0.9997544167770551, 0.9998728447179696, 0.9997405095171951, 0.9997558904151389, 0.9992524220001525, 0.9998143641463421, 0.9994964061713134]\n",
      "['AdaBoost', 12, 'Ï‡Â²', 0.9958771786208641, 0.9959999702323367, 0.9955497449306571, 0.9957095405056283, 0.9875097262412718, 0.9878556716759478, 0.9915134370579914, 0.9917670575080606]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SVC', 12, 'Ï‡Â²', 0.9880892136871716, 0.98817479571941, 0.9900126806468178, 0.9898521811527042, 0.9608560109442464, 0.9613700511099245, 0.9752164655784245, 0.9754032382898362]\n",
      "['LogisticRegression', 12, 'Ï‡Â²', 0.9895986822847674, 0.9896036435619986, 0.9920332470791187, 0.991540160736946, 0.96510250059756, 0.965611412007018, 0.9783825864593431, 0.9784040316596587]\n",
      "['Lasso', 12, 'Ï‡Â²', 0.9895900000496127, 0.9895962016461518, 0.9920329555434737, 0.9916169165922374, 0.965066901283101, 0.965504615149897, 0.978364151463829, 0.9783865681333292]\n",
      "['Ridge', 12, 'Ï‡Â²', 0.9889611581605569, 0.9889078244303213, 0.9892677129647487, 0.988521722834744, 0.9652092985409366, 0.9657334655580135, 0.9770904335828502, 0.9769947290841879]\n",
      "['ElasticNet', 12, 'Ï‡Â²', 0.9895875194109972, 0.9895962016461518, 0.9921666649236015, 0.9917710308939012, 0.9649245040252653, 0.9653520482111526, 0.9783559828497913, 0.9783832261256803]\n",
      "['DecisionTree', 8, 'Ï‡Â²', 0.9895093792946056, 0.9891906172325003, 0.9992465204633368, 0.9987102321582115, 0.957708014422808, 0.9569150964985887, 0.9780364172717169, 0.9773660467326856]\n",
      "['RandomForest', 8, 'Ï‡Â²', 0.9895093792946056, 0.9892501525592748, 0.9991617636916351, 0.9987899630620303, 0.9577893842844284, 0.9570829201312075, 0.9780382422284771, 0.9774917610028593]\n",
      "['ExtraTrees', 8, 'Ï‡Â²', 0.9895093792946056, 0.9892352687275813, 0.9992465204633368, 0.998869318724719, 0.957708014422808, 0.9569456098863376, 0.9780364172717169, 0.9774581382120788]\n",
      "['GradientBoosting', 8, 'Ï‡Â²', 0.9885084416132089, 0.9885468915117508, 0.9971239360686011, 0.9972299609965772, 0.9556381685678396, 0.9556945609886338, 0.9759403767999273, 0.976020567154877]\n",
      "[21:36:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "['XGBoost', 8, 'Ï‡Â²', 0.989406432792058, 0.9892575944751216, 0.9993257090673547, 0.9992191981643189, 0.9572096240203831, 0.9567015027843466, 0.9778143742905456, 0.9774982268259795]\n",
      "['AdaBoost', 8, 'Ï‡Â²', 0.9869543215205322, 0.9869506005626089, 0.9918810489092802, 0.9921775831429297, 0.9543209939328597, 0.9540163246624457, 0.9727385827587993, 0.9727228180976752]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SVC', 8, 'Ï‡Â²', 0.973484453837796, 0.9734360813847917, 0.975376085671041, 0.9756963674865613, 0.9143633062609023, 0.913845449691052, 0.9438847561199686, 0.9437586166148029]\n",
      "['LogisticRegression', 8, 'Ï‡Â²', 0.9739247671920659, 0.9738714334618304, 0.9744164685541388, 0.9748316430020284, 0.9171654808704541, 0.9165306278129529, 0.9449245899406099, 0.944782574506566]\n",
      "['Lasso', 8, 'Ï‡Â²', 0.9731818159266922, 0.9731458466667658, 0.9743025480641542, 0.9746899313128683, 0.9141497103741488, 0.9136165992829354, 0.9432681055608906, 0.9431656205948827]\n",
      "['Ridge', 8, 'Ï‡Â²', 0.9731818159266922, 0.9731458466667658, 0.9743025480641542, 0.9746899313128683, 0.9141497103741488, 0.9136165992829354, 0.9432681055608906, 0.9431656205948827]\n",
      "['ElasticNet', 8, 'Ï‡Â²', 0.9731818159266922, 0.9731458466667658, 0.9743025480641542, 0.9746899313128683, 0.9141497103741488, 0.9136165992829354, 0.9432681055608906, 0.9431656205948827]\n",
      "['DecisionTree', 8, 'Ï‡Â²', 0.9895093792946056, 0.9891906172325003, 0.9992465204633368, 0.9987102321582115, 0.957708014422808, 0.9569150964985887, 0.9780364172717169, 0.9773660467326856]\n",
      "['RandomForest', 8, 'Ï‡Â²', 0.9895093792946056, 0.9892501525592748, 0.9991617636916351, 0.9987899630620303, 0.9577893842844284, 0.9570829201312075, 0.9780382422284771, 0.9774917610028593]\n",
      "['ExtraTrees', 8, 'Ï‡Â²', 0.9895093792946056, 0.9892352687275813, 0.9992465204633368, 0.998869318724719, 0.957708014422808, 0.9569456098863376, 0.9780364172717169, 0.9774581382120788]\n",
      "['GradientBoosting', 8, 'Ï‡Â²', 0.9885084416132089, 0.9885468915117508, 0.9971239360686011, 0.9972299609965772, 0.9556381685678396, 0.9556945609886338, 0.9759403767999273, 0.976020567154877]\n",
      "[21:43:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "['XGBoost', 8, 'Ï‡Â²', 0.989406432792058, 0.9892575944751216, 0.9993257090673547, 0.9992191981643189, 0.9572096240203831, 0.9567015027843466, 0.9778143742905456, 0.9774982268259795]\n",
      "['AdaBoost', 8, 'Ï‡Â²', 0.9869543215205322, 0.9869506005626089, 0.9918810489092802, 0.9921775831429297, 0.9543209939328597, 0.9540163246624457, 0.9727385827587993, 0.9727228180976752]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SVC', 8, 'Ï‡Â²', 0.973484453837796, 0.9734360813847917, 0.975376085671041, 0.9756963674865613, 0.9143633062609023, 0.913845449691052, 0.9438847561199686, 0.9437586166148029]\n",
      "['LogisticRegression', 8, 'Ï‡Â²', 0.9739247671920659, 0.9738714334618304, 0.9744164685541388, 0.9748316430020284, 0.9171654808704541, 0.9165306278129529, 0.9449245899406099, 0.944782574506566]\n",
      "['Lasso', 8, 'Ï‡Â²', 0.9731818159266922, 0.9731458466667658, 0.9743025480641542, 0.9746899313128683, 0.9141497103741488, 0.9136165992829354, 0.9432681055608906, 0.9431656205948827]\n",
      "['Ridge', 8, 'Ï‡Â²', 0.9731818159266922, 0.9731458466667658, 0.9743025480641542, 0.9746899313128683, 0.9141497103741488, 0.9136165992829354, 0.9432681055608906, 0.9431656205948827]\n",
      "['ElasticNet', 8, 'Ï‡Â²', 0.9731818159266922, 0.9731458466667658, 0.9743025480641542, 0.9746899313128683, 0.9141497103741488, 0.9136165992829354, 0.9432681055608906, 0.9431656205948827]\n",
      "['DecisionTree', 5, 'Ï‡Â²', 0.9861940057848493, 0.9858231503118162, 0.9974577634754626, 0.9970371801684299, 0.9458025865444762, 0.94467922801129, 0.9709436336250891, 0.9701522938079721]\n",
      "['RandomForest', 5, 'Ï‡Â²', 0.9861940057848493, 0.9858603598910504, 0.9973830693164877, 0.9970696678420197, 0.945873785173394, 0.9448012815622855, 0.9709457572348482, 0.9702320334654614]\n",
      "['ExtraTrees', 5, 'Ï‡Â²', 0.9861940057848493, 0.9858529179752036, 0.9974577634754626, 0.9971496207546259, 0.9458025865444762, 0.9446944847051644, 0.9709436336250891, 0.9702135660675952]\n",
      "['GradientBoosting', 5, 'Ï‡Â²', 0.9856904361458814, 0.9855626832571778, 0.9970461234398161, 0.9969857670175213, 0.9441243331485559, 0.9436570295217026, 0.969863829542694, 0.9695886631552546]\n",
      "[21:50:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "['XGBoost', 5, 'Ï‡Â²', 0.9861505946090762, 0.9858454760593567, 0.9974519491248116, 0.997181556103139, 0.945629675588533, 0.9446334579296667, 0.9708497585171649, 0.9701964962863143]\n",
      "['AdaBoost', 5, 'Ï‡Â²', 0.9840631372140444, 0.9839738342238826, 0.9961396006781345, 0.9960791938044782, 0.938291131193645, 0.937981539400412, 0.9663503968867112, 0.9661577628136123]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SVC', 5, 'Ï‡Â²', 0.9456504482513979, 0.9457707592242547, 0.99825886219579, 0.9984353914455028, 0.7785112366693281, 0.7788694789839042, 0.8747960603575622, 0.875089992800576]\n",
      "['LogisticRegression', 5, 'Ï‡Â²', 0.9466116957149449, 0.9469168142646643, 0.9967463372036611, 0.9970147517785488, 0.7836527948004658, 0.7846975360439393, 0.8774471283610645, 0.8782057849264078]\n",
      "['Lasso', 5, 'Ï‡Â²', 0.9450414514712667, 0.9451940107461265, 0.99850764830245, 0.9984697480969944, 0.7758158600031531, 0.7764741780456175, 0.8731869540828592, 0.873589261652806]\n",
      "['Ridge', 5, 'Ï‡Â²', 0.9450364901940356, 0.9451754059565094, 0.9985271881075349, 0.9984695979751604, 0.7757802606886942, 0.7763978945762453, 0.8731718765204549, 0.8735409228234001]\n",
      "['ElasticNet', 5, 'Ï‡Â²', 0.9450389708326512, 0.9451828478723563, 0.9985337339381681, 0.9984696580274285, 0.7757853463050455, 0.7764284079639941, 0.8731776005861444, 0.8735602588530134]\n",
      "['DecisionTree', 5, 'Ï‡Â²', 0.9861940057848493, 0.9858231503118162, 0.9974577634754626, 0.9970371801684299, 0.9458025865444762, 0.94467922801129, 0.9709436336250891, 0.9701522938079721]\n",
      "['RandomForest', 5, 'Ï‡Â²', 0.9861940057848493, 0.9858603598910504, 0.9973830693164877, 0.9970696678420197, 0.945873785173394, 0.9448012815622855, 0.9709457572348482, 0.9702320334654614]\n",
      "['ExtraTrees', 5, 'Ï‡Â²', 0.9861940057848493, 0.9858529179752036, 0.9974577634754626, 0.9971496207546259, 0.9458025865444762, 0.9446944847051644, 0.9709436336250891, 0.9702135660675952]\n",
      "['GradientBoosting', 5, 'Ï‡Â²', 0.9856904361458814, 0.9855626832571778, 0.9970461234398161, 0.9969857670175213, 0.9441243331485559, 0.9436570295217026, 0.969863829542694, 0.9695886631552546]\n",
      "[21:55:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "['XGBoost', 5, 'Ï‡Â²', 0.9861505946090762, 0.9858454760593567, 0.9974519491248116, 0.997181556103139, 0.945629675588533, 0.9446334579296667, 0.9708497585171649, 0.9701964962863143]\n",
      "['AdaBoost', 5, 'Ï‡Â²', 0.9840631372140444, 0.9839738342238826, 0.9961396006781345, 0.9960791938044782, 0.938291131193645, 0.937981539400412, 0.9663503968867112, 0.9661577628136123]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SVC', 5, 'Ï‡Â²', 0.9456504482513979, 0.9457707592242547, 0.99825886219579, 0.9984353914455028, 0.7785112366693281, 0.7788694789839042, 0.8747960603575622, 0.875089992800576]\n",
      "['LogisticRegression', 5, 'Ï‡Â²', 0.9466116957149449, 0.9469168142646643, 0.9967463372036611, 0.9970147517785488, 0.7836527948004658, 0.7846975360439393, 0.8774471283610645, 0.8782057849264078]\n",
      "['Lasso', 5, 'Ï‡Â²', 0.9450414514712667, 0.9451940107461265, 0.99850764830245, 0.9984697480969944, 0.7758158600031531, 0.7764741780456175, 0.8731869540828592, 0.873589261652806]\n",
      "['Ridge', 5, 'Ï‡Â²', 0.9450364901940356, 0.9451754059565094, 0.9985271881075349, 0.9984695979751604, 0.7757802606886942, 0.7763978945762453, 0.8731718765204549, 0.8735409228234001]\n",
      "['ElasticNet', 5, 'Ï‡Â²', 0.9450389708326512, 0.9451828478723563, 0.9985337339381681, 0.9984696580274285, 0.7757853463050455, 0.7764284079639941, 0.8731776005861444, 0.8735602588530134]\n",
      "________________________________________ReliefF________________________________________\n",
      "['DecisionTree', 49, 'ReliefF', 0.9999913177648454, 0.9997655796508254, 1.0, 0.9994660727361484, 0.999964400685541, 0.9995728125715158, 0.9999822000259371, 0.9995194398041145]\n",
      "['RandomForest', 49, 'ReliefF', 0.9999913177648454, 0.9998660455147573, 0.9999898286121142, 0.9999389471434895, 0.9999745719182437, 0.999511785796018, 0.9999822002069862, 0.9997253208405182]\n",
      "['ExtraTrees', 49, 'ReliefF', 0.9999913177648454, 0.9998139521038296, 1.0, 0.999771079740557, 0.999964400685541, 0.9994660157143946, 0.9999822000259371, 0.9996185244525825]\n",
      "['GradientBoosting', 49, 'ReliefF', 0.9994629417397215, 0.9995088335541101, 0.9996383860814293, 0.9996791688946605, 0.9981590068808389, 0.9983065069799375, 0.998898148737197, 0.9989923664122138]\n",
      "[22:05:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "['XGBoost', 49, 'ReliefF', 0.999987596806922, 0.9998883712622978, 0.9999847428405779, 0.9999236932468524, 0.999964400685541, 0.9996185826531391, 0.999974571659606, 0.9997711146715496]\n",
      "['AdaBoost', 49, 'ReliefF', 0.9977599833301085, 0.9977934719514192, 0.9974619678175477, 0.9972896824181545, 0.9933429281961828, 0.993653215348234, 0.9953981867938663, 0.9954681278706315]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SVC', 49, 'ReliefF', 0.9954269427121318, 0.9955088037864468, 0.9937256266696691, 0.9936318438497422, 0.9874842981595154, 0.9879166984514456, 0.9905951315074574, 0.9907660293926389]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LogisticRegression', 49, 'ReliefF', 0.9954095782418225, 0.9955981067766085, 0.993932473809792, 0.9942558746736292, 0.9872045892601954, 0.9876573346555801, 0.990557107683672, 0.9909456201446557]\n",
      "['Lasso', 49, 'ReliefF', 0.996097955457653, 0.9962381115394348, 0.9960009638702466, 0.996094831032256, 0.9879674317128865, 0.9884506827370508, 0.9919679330065359, 0.9922580348733028]\n",
      "['Ridge', 49, 'ReliefF', 0.995921830115945, 0.996022295979877, 0.9921147610248265, 0.992378654122247, 0.9911561131651351, 0.9913036844915707, 0.9916352054055705, 0.9918408780405894]\n",
      "['ElasticNet', 49, 'ReliefF', 0.9962914452696702, 0.9965022995519967, 0.9951873161999745, 0.9957792955260533, 0.9895795720962403, 0.9898542985734992, 0.9923755221109859, 0.9928079571537873]\n",
      "['DecisionTree', 20, 'ReliefF', 0.99944681758872, 0.9984074300087815, 0.9994043406764043, 0.9977678912687856, 0.998326832220431, 0.9956976123274086, 0.9988652958626549, 0.9967316767719964]\n",
      "['RandomForest', 20, 'ReliefF', 0.99944681758872, 0.9987944096328158, 0.9989775623254608, 0.9982429603825763, 0.998754023993938, 0.9968113509802425, 0.9988657806531679, 0.9975266420348714]\n",
      "['ExtraTrees', 20, 'ReliefF', 0.99944681758872, 0.9986195246104157, 0.9994043406764043, 0.9984245946772713, 0.998326832220431, 0.9959112060416507, 0.9988652958626549, 0.9971663165934695]\n",
      "['GradientBoosting', 20, 'ReliefF', 0.9967937745893303, 0.9968892791760311, 0.9970695520308209, 0.9974324677521025, 0.9897626542848861, 0.9897932717980014, 0.9934026670069547, 0.9935981866633994]\n",
      "[22:18:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "['XGBoost', 20, 'ReliefF', 0.9992421649029326, 0.9990251090240672, 0.998555369042169, 0.9982446232045549, 0.9983370034531335, 0.9977572660004577, 0.9984461743082169, 0.9980008851043051]\n",
      "['AdaBoost', 20, 'ReliefF', 0.9941655379760965, 0.9942734457558754, 0.9923907745196131, 0.9923538461538461, 0.9836192297325475, 0.9841025249828362, 0.9879855336016837, 0.9882109617373319]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SVC', 20, 'ReliefF', 0.9936495651440507, 0.9937971631416792, 0.995883026157025, 0.9961012736874806, 0.9780047092807412, 0.9783965214737966, 0.9868629020670402, 0.9871695208774294]\n",
      "['LogisticRegression', 20, 'ReliefF', 0.9946331383551381, 0.9948315894443865, 0.9958794042412741, 0.9962561881188119, 0.9820579455127064, 0.9825005721260203, 0.988920383984104, 0.9893305680377923]\n",
      "['Lasso', 20, 'ReliefF', 0.995394694410129, 0.9956464792296129, 0.9961270611955191, 0.9964984806182419, 0.9849465756002299, 0.9856129376764056, 0.9905052690259015, 0.9910258180312026]\n",
      "['Ridge', 20, 'ReliefF', 0.9955881842221461, 0.9958213642520131, 0.996125066809193, 0.9965316315205327, 0.9857450173673798, 0.9862994889007553, 0.9909078593210418, 0.9913891593887298]\n",
      "['ElasticNet', 20, 'ReliefF', 0.9953810508977431, 0.9956278744399958, 0.9960553992686803, 0.9964216306259062, 0.9849618324492837, 0.9856129376764056, 0.9904775542349824, 0.9909878124544598]\n",
      "['DecisionTree', 16, 'ReliefF', 0.9990846443508417, 0.9976557965082531, 0.9990472260010496, 0.9965577908666717, 0.9971978253904482, 0.9938210389808528, 0.9981216690167013, 0.9951875334199067]\n",
      "['RandomForest', 16, 'ReliefF', 0.9990846443508417, 0.9980948695432152, 0.9983515057773616, 0.9968978743562708, 0.9978945548305727, 0.9952856815927988, 0.9981229780047611, 0.9960911256336652]\n",
      "['ExtraTrees', 16, 'ReliefF', 0.9990846443508417, 0.9978418444044235, 0.9990472260010496, 0.9971380033364453, 0.9971978253904482, 0.9940041193073461, 0.9981216690167013, 0.995568595091837]\n",
      "['GradientBoosting', 16, 'ReliefF', 0.9960458620467253, 0.9960595055591112, 0.9961680320510519, 0.9960461538461538, 0.9875860104865409, 0.9877641315127011, 0.9918584577038195, 0.9918878547627256]\n",
      "[22:26:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "['XGBoost', 16, 'ReliefF', 0.9986356487614172, 0.9983218479765431, 0.9970360805087977, 0.9964914421698142, 0.9973707363463915, 0.9966282706537494, 0.9972033803504419, 0.9965598517151161]\n",
      "['AdaBoost', 16, 'ReliefF', 0.9921326546306081, 0.9921673835712266, 0.9913194803048768, 0.9910520775280203, 0.9762908565703621, 0.976703028453734, 0.9837477740625441, 0.9838252357058881]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SVC', 16, 'ReliefF', 0.9909022578772679, 0.9910473752362808, 0.9971687607681641, 0.9972749468378357, 0.965438151276744, 0.9659318025783813, 0.9810469523964559, 0.9813531736805394]\n",
      "['LogisticRegression', 16, 'ReliefF', 0.9930232038936103, 0.9931497164630062, 0.9947983586852903, 0.9949190465831753, 0.9764993668407642, 0.9769013654741018, 0.985563930614476, 0.98582788696181]\n",
      "['Lasso', 16, 'ReliefF', 0.9925245955318738, 0.9926697128908867, 0.9964370175127882, 0.9964702391178721, 0.9728275518351447, 0.9733923258829812, 0.9844907580151671, 0.9847960979223906]\n",
      "['Ridge', 16, 'ReliefF', 0.9929276993069096, 0.9931162278416956, 0.9960509428373976, 0.9962138327542419, 0.9748668839920054, 0.9754824929437791, 0.9853450668750192, 0.9857391733345666]\n",
      "['ElasticNet', 16, 'ReliefF', 0.9927875432251279, 0.9929264589876018, 0.9963686307969243, 0.9963965931426075, 0.9739769011305325, 0.9745213212296895, 0.9850455320473092, 0.9853375600650979]\n",
      "['DecisionTree', 15, 'ReliefF', 0.9990846443508417, 0.9976446336344829, 0.9990472260010496, 0.9965728274173806, 0.9971978253904482, 0.9937600122053551, 0.9981216690167013, 0.9951644322218403]\n",
      "['RandomForest', 15, 'ReliefF', 0.9990846443508417, 0.9980613809219046, 0.9983464346587295, 0.9969126367915877, 0.9978996404469239, 0.9951331146540545, 0.9981229875527114, 0.9960220808869004]\n",
      "['ExtraTrees', 15, 'ReliefF', 0.9990846443508417, 0.9978344024885767, 0.9990472260010496, 0.997183572882705, 0.9971978253904482, 0.993927835837974, 0.9981216690167013, 0.9955530425746508]\n",
      "['GradientBoosting', 15, 'ReliefF', 0.9960458620467253, 0.9960595055591112, 0.9961680320510519, 0.9960461538461538, 0.9875860104865409, 0.9877641315127011, 0.9918584577038195, 0.9918878547627256]\n",
      "[22:32:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "['XGBoost', 15, 'ReliefF', 0.9986406100386483, 0.9983106851027729, 0.9969856092068543, 0.9963549848251461, 0.9974419349753093, 0.996719810816996, 0.9972137198873285, 0.9965373644309533]\n",
      "['AdaBoost', 15, 'ReliefF', 0.9926907983191193, 0.9927032015121973, 0.9902535315526494, 0.9897858573409336, 0.979672791443959, 0.9801968113509802, 0.9849347462068436, 0.9849679966271896]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SVC', 15, 'ReliefF', 0.9913338889963832, 0.9915124949767068, 0.9972312823148158, 0.9973272121250236, 0.9671520039871232, 0.9677931192310626, 0.9819613512850633, 0.9823382294868718]\n",
      "['LogisticRegression', 15, 'ReliefF', 0.9930157619777635, 0.9931832050843169, 0.9946546776749919, 0.9948890028118252, 0.9766112504004922, 0.9770691891067206, 0.9855503863238037, 0.9858985806213245]\n",
      "['Lasso', 15, 'ReliefF', 0.9921301739919925, 0.9923162218881629, 0.9962446799632814, 0.996340776881216, 0.9713934080240855, 0.9720649935159051, 0.9836621081931503, 0.9840531920644359]\n",
      "['Ridge', 15, 'ReliefF', 0.992177306125689, 0.992353431467397, 0.9965354232105774, 0.9966208816995713, 0.9713018669297625, 0.9719429399649097, 0.9837568602605804, 0.9841272293325712]\n",
      "['ElasticNet', 15, 'ReliefF', 0.9922889348633912, 0.9924166877520949, 0.9963610201655788, 0.9964664863428133, 0.9719324833573205, 0.9723548706995194, 0.9839951601899882, 0.9842630343464294]\n",
      "['DecisionTree', 10, 'ReliefF', 0.998297041590387, 0.9963646241088305, 0.9983003787144126, 0.9943193997856378, 0.9947109589946753, 0.990754443512091, 0.9965024365764127, 0.992533720530358]\n",
      "['RandomForest', 10, 'ReliefF', 0.998297041590387, 0.9967850923541757, 0.9975284105386536, 0.9949192746193282, 0.9954839726800689, 0.9918834388587993, 0.9965051430142313, 0.9933990373596149]\n",
      "['ExtraTrees', 10, 'ReliefF', 0.998297041590387, 0.9966027654159286, 0.9983003787144126, 0.9951884768617837, 0.9947109589946753, 0.990861240369212, 0.9965024365764127, 0.9930201444898896]\n",
      "['GradientBoosting', 10, 'ReliefF', 0.9955807423062993, 0.9955683391132213, 0.9951020617499231, 0.99506123453751, 0.9867367125558782, 0.9867266763292395, 0.9909017320671173, 0.9908764296274735]\n",
      "[22:39:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "['XGBoost', 10, 'ReliefF', 0.9975813773497849, 0.997354398916457, 0.996622569602106, 0.9962342711937054, 0.9934497261395595, 0.9929056373483865, 0.9950336185819072, 0.9945671691971483]\n",
      "['AdaBoost', 10, 'ReliefF', 0.991185050679447, 0.9911515620581363, 0.9900807811255572, 0.9900389443142853, 0.9736107367532408, 0.9735143794339767, 0.9817766894447366, 0.9817071294501369]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\envs\\py\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SVC', 10, 'ReliefF', 0.9896755820818511, 0.9897338770893179, 0.9939563408581786, 0.9937869636340757, 0.963525959528665, 0.9639331756808299, 0.9785046198023996, 0.9786324455355829]\n",
      "['LogisticRegression', 10, 'ReliefF', 0.9896210080323078, 0.9899087621117181, 0.9907309418676787, 0.9911206990886211, 0.9664857882451063, 0.9672896483332062, 0.978458195822414, 0.9790601788223667]\n",
      "['Lasso', 10, 'ReliefF', 0.9894138747079048, 0.9894957357822197, 0.9923000418760469, 0.9919063901872823, 0.9640752060946026, 0.9648028072316729, 0.9779840226169993, 0.9781668845080008]\n",
      "['Ridge', 10, 'ReliefF', 0.9893865876831331, 0.9894771309926027, 0.9922476156576179, 0.9918440328120833, 0.9640141786983873, 0.9647875505377984, 0.9779271598855731, 0.9781287219068536]\n",
      "['ElasticNet', 10, 'ReliefF', 0.9894027118341345, 0.9894734100346794, 0.9922429901650327, 0.9917821968508876, 0.9640853773273051, 0.9648333206194217, 0.9779615461997595, 0.9781221724705936]\n",
      "['DecisionTree', 6, 'ReliefF', 0.9938678613422239, 0.9916576123357197, 0.9967863825552405, 0.9919183127923783, 0.9780097948970925, 0.9737279731482188, 0.9873088237559104, 0.9827389751170239]\n",
      "['RandomForest', 6, 'ReliefF', 0.9938678613422239, 0.9919292422641285, 0.9959534910195443, 0.9920955368512594, 0.9788336647459989, 0.9746738881684339, 0.9873193702774657, 0.9833075520051716]\n",
      "['ExtraTrees', 6, 'ReliefF', 0.9938678613422239, 0.9917990087368092, 0.9967863825552405, 0.9925963946308307, 0.9780097948970925, 0.9736364329849722, 0.9873088237559104, 0.9830250003850953]\n",
      "['GradientBoosting', 6, 'ReliefF', 0.9912334231324512, 0.9909134207510382, 0.9922410972563398, 0.991954471037655, 0.9716527744580005, 0.9706156075978335, 0.9818390178475073, 0.9811690314620605]\n",
      "[22:43:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "['XGBoost', 6, 'ReliefF', 0.9926982402349661, 0.9922827332668522, 0.9950327000934288, 0.9944379527927085, 0.9749279113882207, 0.973804256617591, 0.9848777142152568, 0.9840129499730209]\n",
      "['AdaBoost', 6, 'ReliefF', 0.9866814512728157, 0.9865636209385744, 0.9916478447842668, 0.9913992827446126, 0.9534208398386842, 0.9531772064993516, 0.9721586990453374, 0.9719126031595405]\n",
      "['SVC', 6, 'ReliefF', 0.9839701132659592, 0.9838063911173293, 0.986066940071438, 0.9858669588553824, 0.9476639221290424, 0.9471813258066977, 0.9664840978402937, 0.9661370391696106]\n",
      "['LogisticRegression', 6, 'ReliefF', 0.9847081032541017, 0.9845022102490065, 0.9814729670421535, 0.9812004139358399, 0.9553330315867632, 0.9547486459684187, 0.9682266016199821, 0.9677938185782885]\n",
      "['Lasso', 6, 'ReliefF', 0.9812451317467169, 0.9812277672764076, 0.9755457279691478, 0.9759881671701913, 0.9468349666637849, 0.9463116942558547, 0.960975949664369, 0.9609208579595188]\n",
      "['Ridge', 6, 'ReliefF', 0.981231488234331, 0.9812017205709438, 0.9754346994692973, 0.9758956527211794, 0.9468909084436489, 0.9462964375619803, 0.960950886682219, 0.9608681507645117]\n",
      "['ElasticNet', 6, 'ReliefF', 0.98123768983087, 0.9812091624867906, 0.9754602512652326, 0.9759113866293249, 0.9468909084436489, 0.9463116942558547, 0.9609632858245141, 0.9608836423912874]\n",
      "['DecisionTree', 6, 'ReliefF', 0.9938678613422239, 0.9916576123357197, 0.9967863825552405, 0.9919183127923783, 0.9780097948970925, 0.9737279731482188, 0.9873088237559104, 0.9827389751170239]\n",
      "['RandomForest', 6, 'ReliefF', 0.9938678613422239, 0.9919292422641285, 0.9959534910195443, 0.9920955368512594, 0.9788336647459989, 0.9746738881684339, 0.9873193702774657, 0.9833075520051716]\n",
      "['ExtraTrees', 6, 'ReliefF', 0.9938678613422239, 0.9917990087368092, 0.9967863825552405, 0.9925963946308307, 0.9780097948970925, 0.9736364329849722, 0.9873088237559104, 0.9830250003850953]\n",
      "['GradientBoosting', 6, 'ReliefF', 0.9912334231324512, 0.9909134207510382, 0.9922410972563398, 0.991954471037655, 0.9716527744580005, 0.9706156075978335, 0.9818390178475073, 0.9811690314620605]\n",
      "[22:47:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "['XGBoost', 6, 'ReliefF', 0.9926982402349661, 0.9922827332668522, 0.9950327000934288, 0.9944379527927085, 0.9749279113882207, 0.973804256617591, 0.9848777142152568, 0.9840129499730209]\n",
      "['AdaBoost', 6, 'ReliefF', 0.9866814512728157, 0.9865636209385744, 0.9916478447842668, 0.9913992827446126, 0.9534208398386842, 0.9531772064993516, 0.9721586990453374, 0.9719126031595405]\n",
      "['SVC', 6, 'ReliefF', 0.9839701132659592, 0.9838063911173293, 0.986066940071438, 0.9858669588553824, 0.9476639221290424, 0.9471813258066977, 0.9664840978402937, 0.9661370391696106]\n",
      "['LogisticRegression', 6, 'ReliefF', 0.9847081032541017, 0.9845022102490065, 0.9814729670421535, 0.9812004139358399, 0.9553330315867632, 0.9547486459684187, 0.9682266016199821, 0.9677938185782885]\n",
      "['Lasso', 6, 'ReliefF', 0.9812451317467169, 0.9812277672764076, 0.9755457279691478, 0.9759881671701913, 0.9468349666637849, 0.9463116942558547, 0.960975949664369, 0.9609208579595188]\n",
      "['Ridge', 6, 'ReliefF', 0.981231488234331, 0.9812017205709438, 0.9754346994692973, 0.9758956527211794, 0.9468909084436489, 0.9462964375619803, 0.960950886682219, 0.9608681507645117]\n",
      "['ElasticNet', 6, 'ReliefF', 0.98123768983087, 0.9812091624867906, 0.9754602512652326, 0.9759113866293249, 0.9468909084436489, 0.9463116942558547, 0.9609632858245141, 0.9608836423912874]\n",
      "['DecisionTree', 6, 'ReliefF', 0.9938678613422239, 0.9916576123357197, 0.9967863825552405, 0.9919183127923783, 0.9780097948970925, 0.9737279731482188, 0.9873088237559104, 0.9827389751170239]\n",
      "['RandomForest', 6, 'ReliefF', 0.9938678613422239, 0.9919292422641285, 0.9959534910195443, 0.9920955368512594, 0.9788336647459989, 0.9746738881684339, 0.9873193702774657, 0.9833075520051716]\n",
      "['ExtraTrees', 6, 'ReliefF', 0.9938678613422239, 0.9917990087368092, 0.9967863825552405, 0.9925963946308307, 0.9780097948970925, 0.9736364329849722, 0.9873088237559104, 0.9830250003850953]\n",
      "['GradientBoosting', 6, 'ReliefF', 0.9912334231324512, 0.9909134207510382, 0.9922410972563398, 0.991954471037655, 0.9716527744580005, 0.9706156075978335, 0.9818390178475073, 0.9811690314620605]\n",
      "[22:51:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "['XGBoost', 6, 'ReliefF', 0.9926982402349661, 0.9922827332668522, 0.9950327000934288, 0.9944379527927085, 0.9749279113882207, 0.973804256617591, 0.9848777142152568, 0.9840129499730209]\n",
      "['AdaBoost', 6, 'ReliefF', 0.9866814512728157, 0.9865636209385744, 0.9916478447842668, 0.9913992827446126, 0.9534208398386842, 0.9531772064993516, 0.9721586990453374, 0.9719126031595405]\n",
      "['SVC', 6, 'ReliefF', 0.9839701132659592, 0.9838063911173293, 0.986066940071438, 0.9858669588553824, 0.9476639221290424, 0.9471813258066977, 0.9664840978402937, 0.9661370391696106]\n",
      "['LogisticRegression', 6, 'ReliefF', 0.9847081032541017, 0.9845022102490065, 0.9814729670421535, 0.9812004139358399, 0.9553330315867632, 0.9547486459684187, 0.9682266016199821, 0.9677938185782885]\n",
      "['Lasso', 6, 'ReliefF', 0.9812451317467169, 0.9812277672764076, 0.9755457279691478, 0.9759881671701913, 0.9468349666637849, 0.9463116942558547, 0.960975949664369, 0.9609208579595188]\n",
      "['Ridge', 6, 'ReliefF', 0.981231488234331, 0.9812017205709438, 0.9754346994692973, 0.9758956527211794, 0.9468909084436489, 0.9462964375619803, 0.960950886682219, 0.9608681507645117]\n",
      "['ElasticNet', 6, 'ReliefF', 0.98123768983087, 0.9812091624867906, 0.9754602512652326, 0.9759113866293249, 0.9468909084436489, 0.9463116942558547, 0.9609632858245141, 0.9608836423912874]\n",
      "['DecisionTree', 6, 'ReliefF', 0.9938678613422239, 0.9916576123357197, 0.9967863825552405, 0.9919183127923783, 0.9780097948970925, 0.9737279731482188, 0.9873088237559104, 0.9827389751170239]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RandomForest', 6, 'ReliefF', 0.9938678613422239, 0.9919292422641285, 0.9959534910195443, 0.9920955368512594, 0.9788336647459989, 0.9746738881684339, 0.9873193702774657, 0.9833075520051716]\n",
      "['ExtraTrees', 6, 'ReliefF', 0.9938678613422239, 0.9917990087368092, 0.9967863825552405, 0.9925963946308307, 0.9780097948970925, 0.9736364329849722, 0.9873088237559104, 0.9830250003850953]\n",
      "['GradientBoosting', 6, 'ReliefF', 0.9912334231324512, 0.9909134207510382, 0.9922410972563398, 0.991954471037655, 0.9716527744580005, 0.9706156075978335, 0.9818390178475073, 0.9811690314620605]\n",
      "[22:55:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "['XGBoost', 6, 'ReliefF', 0.9926982402349661, 0.9922827332668522, 0.9950327000934288, 0.9944379527927085, 0.9749279113882207, 0.973804256617591, 0.9848777142152568, 0.9840129499730209]\n",
      "['AdaBoost', 6, 'ReliefF', 0.9866814512728157, 0.9865636209385744, 0.9916478447842668, 0.9913992827446126, 0.9534208398386842, 0.9531772064993516, 0.9721586990453374, 0.9719126031595405]\n",
      "['SVC', 6, 'ReliefF', 0.9839701132659592, 0.9838063911173293, 0.986066940071438, 0.9858669588553824, 0.9476639221290424, 0.9471813258066977, 0.9664840978402937, 0.9661370391696106]\n",
      "['LogisticRegression', 6, 'ReliefF', 0.9847081032541017, 0.9845022102490065, 0.9814729670421535, 0.9812004139358399, 0.9553330315867632, 0.9547486459684187, 0.9682266016199821, 0.9677938185782885]\n",
      "['Lasso', 6, 'ReliefF', 0.9812451317467169, 0.9812277672764076, 0.9755457279691478, 0.9759881671701913, 0.9468349666637849, 0.9463116942558547, 0.960975949664369, 0.9609208579595188]\n",
      "['Ridge', 6, 'ReliefF', 0.981231488234331, 0.9812017205709438, 0.9754346994692973, 0.9758956527211794, 0.9468909084436489, 0.9462964375619803, 0.960950886682219, 0.9608681507645117]\n",
      "['ElasticNet', 6, 'ReliefF', 0.98123768983087, 0.9812091624867906, 0.9754602512652326, 0.9759113866293249, 0.9468909084436489, 0.9463116942558547, 0.9609632858245141, 0.9608836423912874]\n",
      "['DecisionTree', 5, 'ReliefF', 0.9893779054479785, 0.9887961956926191, 0.9987482828668566, 0.9973911106869014, 0.9576469870265927, 0.9565641925394767, 0.9777658928172722, 0.9765511226023503]\n",
      "['RandomForest', 5, 'ReliefF', 0.9893779054479785, 0.9888780567669341, 0.9985578936764699, 0.9973920234081801, 0.9578300692152385, 0.9568998398047143, 0.9777700482289239, 0.9767264402899656]\n",
      "['ExtraTrees', 5, 'ReliefF', 0.9893779054479785, 0.9888408471877, 0.9987482828668566, 0.9975023862551702, 0.9576469870265927, 0.9566404760088488, 0.9777658928172722, 0.9766442116740002]\n",
      "['GradientBoosting', 5, 'ReliefF', 0.9882765019026498, 0.988156190929793, 0.9947402085943405, 0.9946852392435588, 0.9569909425172783, 0.9565489358456023, 0.9755005132139635, 0.9752444060757367]\n",
      "[22:59:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "['XGBoost', 5, 'ReliefF', 0.9892216252151954, 0.988978522630866, 0.9984934566152638, 0.9979313527361838, 0.9572503089511933, 0.9567930429475933, 0.977437010572669, 0.9769293080350189]\n",
      "['AdaBoost', 5, 'ReliefF', 0.9870560277037721, 0.98684269278283, 0.990831685778305, 0.9906318737834887, 0.9557703945929727, 0.9550842932336563, 0.9729852863518229, 0.9725333623328]\n",
      "['SVC', 5, 'ReliefF', 0.9839614310308046, 0.983795228243559, 0.9860252719806968, 0.9858354241432973, 0.9476690077453938, 0.9471660691128233, 0.9664667273486387, 0.9661139598036089]\n",
      "['LogisticRegression', 5, 'ReliefF', 0.9853840772768542, 0.9851124473484454, 0.9836927795018866, 0.9831982915646003, 0.9559178774671596, 0.9552826302540239, 0.9696064624955508, 0.9690394570878054]\n",
      "['Lasso', 5, 'ReliefF', 0.9812290075957154, 0.9812203253605608, 0.975424479125738, 0.9759274992919853, 0.9468909084436489, 0.9463422076436037, 0.9609459271148914, 0.9609071826371193]\n",
      "['Ridge', 5, 'ReliefF', 0.9812079221674828, 0.9811905576971736, 0.9753077366298256, 0.9758046754554321, 0.9469214221417565, 0.9463422076436037, 0.9609049834469982, 0.9608476427260265]\n",
      "['ElasticNet', 5, 'ReliefF', 0.9812327285536389, 0.9812091624867906, 0.9754198841193172, 0.9758814367300703, 0.9469112509090539, 0.9463422076436037, 0.960954172569603, 0.9608848543057642]\n"
     ]
    }
   ],
   "source": [
    "models = define_models()\n",
    "results = []\n",
    "for scoring_method in list(rank.columns):\n",
    "    print(40*\"_\" + scoring_method + 40*\"_\")\n",
    "    min_score = rank[scoring_method].quantile(0.10)\n",
    "    max_score = rank[scoring_method].quantile(0.90)\n",
    "    ths = np.round(np.linspace(min_score, max_score, num=10), 5)\n",
    "    for th in ths:\n",
    "        new_fs = rank.index[rank[scoring_method] >= th]\n",
    "        X_train_sel = X_train_[new_fs]\n",
    "        num_features = len(X_train_sel.columns)\n",
    "        X_train, X_valid, y_train, y_valid = train_test_split(X_train_sel, y_train_, random_state=32,\n",
    "                                                          stratify=y_train_)\n",
    "        for model_name, model in models.items():\n",
    "            result = []\n",
    "            model.fit(X_train, list(y_train.values))\n",
    "            #print(40*\"_\")\n",
    "            y_pred_train = model.predict(X_train)\n",
    "            y_pred_valid = model.predict(X_valid)\n",
    "            precision_train = precision_score(list(y_train.values), y_pred_train)\n",
    "            precision_valid = precision_score(list(y_valid.values), y_pred_valid)\n",
    "            recal_train = recall_score(list(y_train.values), y_pred_train)\n",
    "            recal_valid = recall_score(list(y_valid.values), y_pred_valid)\n",
    "            f1_train = f1_score(list(y_train.values), y_pred_train)\n",
    "            f1_valid = f1_score(list(y_valid.values), y_pred_valid)\n",
    "            acc_train = accuracy_score(list(y_train.values), y_pred_train)\n",
    "            acc_valid = accuracy_score(list(y_valid.values), y_pred_valid)\n",
    "            result.extend([model_name,num_features,scoring_method,acc_train, acc_valid, precision_train, precision_valid, recal_train,\n",
    "                          recal_valid, f1_train, f1_valid])\n",
    "            print(result)\n",
    "            results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "fbdd8bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(data=results,\n",
    "                       columns=[\"Model\", \"num_features\",\"scoring_method\",\"Acc_train\" ,\"Acc_valid\",\n",
    "                                \"Precision_train\", \"Precision_valid\",\"Recall_train\",\n",
    "                                \"Recall_valid\", \"F1-score_train\", \"F1-score_valid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "6e4c12b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>num_features</th>\n",
       "      <th>scoring_method</th>\n",
       "      <th>Acc_train</th>\n",
       "      <th>Acc_valid</th>\n",
       "      <th>Precision_train</th>\n",
       "      <th>Precision_valid</th>\n",
       "      <th>Recall_train</th>\n",
       "      <th>Recall_valid</th>\n",
       "      <th>F1-score_train</th>\n",
       "      <th>F1-score_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>49</td>\n",
       "      <td>ReliefF</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>0.999888</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999924</td>\n",
       "      <td>0.999964</td>\n",
       "      <td>0.999619</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.999771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>44</td>\n",
       "      <td>Gain ratio</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>0.999885</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>0.999908</td>\n",
       "      <td>0.999969</td>\n",
       "      <td>0.999619</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.999763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>44</td>\n",
       "      <td>Ï‡Â²</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999870</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999878</td>\n",
       "      <td>0.999969</td>\n",
       "      <td>0.999588</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>0.999733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>44</td>\n",
       "      <td>Info. gain</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.999870</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999878</td>\n",
       "      <td>0.999969</td>\n",
       "      <td>0.999588</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>0.999733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>49</td>\n",
       "      <td>ReliefF</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999866</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>0.999939</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.999512</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>44</td>\n",
       "      <td>Ï‡Â²</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999859</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>0.999908</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.999512</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>44</td>\n",
       "      <td>Info. gain</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999859</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>0.999908</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.999512</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>44</td>\n",
       "      <td>Gain ratio</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999844</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>0.999908</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.999451</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>22</td>\n",
       "      <td>Info. gain</td>\n",
       "      <td>0.999973</td>\n",
       "      <td>0.999818</td>\n",
       "      <td>0.999964</td>\n",
       "      <td>0.999802</td>\n",
       "      <td>0.999924</td>\n",
       "      <td>0.999451</td>\n",
       "      <td>0.999944</td>\n",
       "      <td>0.999626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>21</td>\n",
       "      <td>Ï‡Â²</td>\n",
       "      <td>0.999967</td>\n",
       "      <td>0.999814</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>0.999847</td>\n",
       "      <td>0.999873</td>\n",
       "      <td>0.999390</td>\n",
       "      <td>0.999931</td>\n",
       "      <td>0.999618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>23</td>\n",
       "      <td>Gain ratio</td>\n",
       "      <td>0.999968</td>\n",
       "      <td>0.999814</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.999847</td>\n",
       "      <td>0.999893</td>\n",
       "      <td>0.999390</td>\n",
       "      <td>0.999934</td>\n",
       "      <td>0.999618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>ExtraTrees</td>\n",
       "      <td>49</td>\n",
       "      <td>ReliefF</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999814</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999771</td>\n",
       "      <td>0.999964</td>\n",
       "      <td>0.999466</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>21</td>\n",
       "      <td>Info. gain</td>\n",
       "      <td>0.999967</td>\n",
       "      <td>0.999814</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>0.999847</td>\n",
       "      <td>0.999873</td>\n",
       "      <td>0.999390</td>\n",
       "      <td>0.999931</td>\n",
       "      <td>0.999618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>25</td>\n",
       "      <td>Ï‡Â²</td>\n",
       "      <td>0.999973</td>\n",
       "      <td>0.999810</td>\n",
       "      <td>0.999969</td>\n",
       "      <td>0.999771</td>\n",
       "      <td>0.999919</td>\n",
       "      <td>0.999451</td>\n",
       "      <td>0.999944</td>\n",
       "      <td>0.999611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>16</td>\n",
       "      <td>Info. gain</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.999810</td>\n",
       "      <td>0.999964</td>\n",
       "      <td>0.999847</td>\n",
       "      <td>0.999832</td>\n",
       "      <td>0.999374</td>\n",
       "      <td>0.999898</td>\n",
       "      <td>0.999611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>16</td>\n",
       "      <td>Info. gain</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.999810</td>\n",
       "      <td>0.999964</td>\n",
       "      <td>0.999847</td>\n",
       "      <td>0.999832</td>\n",
       "      <td>0.999374</td>\n",
       "      <td>0.999898</td>\n",
       "      <td>0.999611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>16</td>\n",
       "      <td>Ï‡Â²</td>\n",
       "      <td>0.999967</td>\n",
       "      <td>0.999803</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>0.999802</td>\n",
       "      <td>0.999873</td>\n",
       "      <td>0.999390</td>\n",
       "      <td>0.999931</td>\n",
       "      <td>0.999596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>22</td>\n",
       "      <td>Info. gain</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999799</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>0.999908</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.999268</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>25</td>\n",
       "      <td>Ï‡Â²</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999799</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>0.999878</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.999298</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>20</td>\n",
       "      <td>Info. gain</td>\n",
       "      <td>0.999968</td>\n",
       "      <td>0.999799</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999802</td>\n",
       "      <td>0.999883</td>\n",
       "      <td>0.999374</td>\n",
       "      <td>0.999934</td>\n",
       "      <td>0.999588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>44</td>\n",
       "      <td>Gain ratio</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999795</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999542</td>\n",
       "      <td>0.999964</td>\n",
       "      <td>0.999619</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>ExtraTrees</td>\n",
       "      <td>44</td>\n",
       "      <td>Gain ratio</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999792</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999786</td>\n",
       "      <td>0.999964</td>\n",
       "      <td>0.999359</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>19</td>\n",
       "      <td>Info. gain</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>0.999792</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999756</td>\n",
       "      <td>0.999847</td>\n",
       "      <td>0.999390</td>\n",
       "      <td>0.999916</td>\n",
       "      <td>0.999573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>19</td>\n",
       "      <td>Gain ratio</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>0.999788</td>\n",
       "      <td>0.999964</td>\n",
       "      <td>0.999756</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>0.999374</td>\n",
       "      <td>0.999888</td>\n",
       "      <td>0.999565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>ExtraTrees</td>\n",
       "      <td>44</td>\n",
       "      <td>Ï‡Â²</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999788</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999741</td>\n",
       "      <td>0.999964</td>\n",
       "      <td>0.999390</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ExtraTrees</td>\n",
       "      <td>44</td>\n",
       "      <td>Info. gain</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999788</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999741</td>\n",
       "      <td>0.999964</td>\n",
       "      <td>0.999390</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>23</td>\n",
       "      <td>Gain ratio</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999784</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>0.999878</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.999237</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>17</td>\n",
       "      <td>Gain ratio</td>\n",
       "      <td>0.999940</td>\n",
       "      <td>0.999784</td>\n",
       "      <td>0.999969</td>\n",
       "      <td>0.999756</td>\n",
       "      <td>0.999786</td>\n",
       "      <td>0.999359</td>\n",
       "      <td>0.999878</td>\n",
       "      <td>0.999557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>17</td>\n",
       "      <td>Info. gain</td>\n",
       "      <td>0.999940</td>\n",
       "      <td>0.999784</td>\n",
       "      <td>0.999969</td>\n",
       "      <td>0.999756</td>\n",
       "      <td>0.999786</td>\n",
       "      <td>0.999359</td>\n",
       "      <td>0.999878</td>\n",
       "      <td>0.999557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>13</td>\n",
       "      <td>Ï‡Â²</td>\n",
       "      <td>0.999924</td>\n",
       "      <td>0.999780</td>\n",
       "      <td>0.999949</td>\n",
       "      <td>0.999817</td>\n",
       "      <td>0.999741</td>\n",
       "      <td>0.999283</td>\n",
       "      <td>0.999845</td>\n",
       "      <td>0.999550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>12</td>\n",
       "      <td>Info. gain</td>\n",
       "      <td>0.999861</td>\n",
       "      <td>0.999777</td>\n",
       "      <td>0.999741</td>\n",
       "      <td>0.999664</td>\n",
       "      <td>0.999690</td>\n",
       "      <td>0.999420</td>\n",
       "      <td>0.999715</td>\n",
       "      <td>0.999542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>21</td>\n",
       "      <td>Info. gain</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>0.999773</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>0.999847</td>\n",
       "      <td>0.999969</td>\n",
       "      <td>0.999222</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>0.999535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>21</td>\n",
       "      <td>Ï‡Â²</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>0.999773</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>0.999847</td>\n",
       "      <td>0.999969</td>\n",
       "      <td>0.999222</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>0.999535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>49</td>\n",
       "      <td>ReliefF</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999766</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999466</td>\n",
       "      <td>0.999964</td>\n",
       "      <td>0.999573</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>19</td>\n",
       "      <td>Gain ratio</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999762</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>0.999756</td>\n",
       "      <td>0.999934</td>\n",
       "      <td>0.999268</td>\n",
       "      <td>0.999957</td>\n",
       "      <td>0.999512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>44</td>\n",
       "      <td>Info. gain</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999762</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999405</td>\n",
       "      <td>0.999964</td>\n",
       "      <td>0.999619</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>44</td>\n",
       "      <td>Ï‡Â²</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999762</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999405</td>\n",
       "      <td>0.999964</td>\n",
       "      <td>0.999619</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>20</td>\n",
       "      <td>Info. gain</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>0.999762</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>0.999847</td>\n",
       "      <td>0.999969</td>\n",
       "      <td>0.999176</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>0.999512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>19</td>\n",
       "      <td>Info. gain</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999758</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>0.999802</td>\n",
       "      <td>0.999934</td>\n",
       "      <td>0.999207</td>\n",
       "      <td>0.999957</td>\n",
       "      <td>0.999504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>12</td>\n",
       "      <td>Ï‡Â²</td>\n",
       "      <td>0.999909</td>\n",
       "      <td>0.999754</td>\n",
       "      <td>0.999873</td>\n",
       "      <td>0.999741</td>\n",
       "      <td>0.999756</td>\n",
       "      <td>0.999252</td>\n",
       "      <td>0.999814</td>\n",
       "      <td>0.999496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>16</td>\n",
       "      <td>Info. gain</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999751</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>0.999756</td>\n",
       "      <td>0.999934</td>\n",
       "      <td>0.999222</td>\n",
       "      <td>0.999957</td>\n",
       "      <td>0.999489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>16</td>\n",
       "      <td>Info. gain</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999751</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>0.999756</td>\n",
       "      <td>0.999934</td>\n",
       "      <td>0.999222</td>\n",
       "      <td>0.999957</td>\n",
       "      <td>0.999489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>17</td>\n",
       "      <td>Gain ratio</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999747</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>0.999756</td>\n",
       "      <td>0.999934</td>\n",
       "      <td>0.999207</td>\n",
       "      <td>0.999957</td>\n",
       "      <td>0.999481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>17</td>\n",
       "      <td>Info. gain</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.999747</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>0.999756</td>\n",
       "      <td>0.999934</td>\n",
       "      <td>0.999207</td>\n",
       "      <td>0.999957</td>\n",
       "      <td>0.999481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>12</td>\n",
       "      <td>Ï‡Â²</td>\n",
       "      <td>0.999968</td>\n",
       "      <td>0.999747</td>\n",
       "      <td>0.999949</td>\n",
       "      <td>0.999741</td>\n",
       "      <td>0.999919</td>\n",
       "      <td>0.999222</td>\n",
       "      <td>0.999934</td>\n",
       "      <td>0.999481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>16</td>\n",
       "      <td>Ï‡Â²</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>0.999740</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0.999802</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.999130</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>0.999466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>13</td>\n",
       "      <td>Ï‡Â²</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.999717</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>0.999756</td>\n",
       "      <td>0.999919</td>\n",
       "      <td>0.999085</td>\n",
       "      <td>0.999949</td>\n",
       "      <td>0.999420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>ExtraTrees</td>\n",
       "      <td>25</td>\n",
       "      <td>Ï‡Â²</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999713</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999664</td>\n",
       "      <td>0.999964</td>\n",
       "      <td>0.999161</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>ExtraTrees</td>\n",
       "      <td>20</td>\n",
       "      <td>Info. gain</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>0.999702</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.999695</td>\n",
       "      <td>0.999964</td>\n",
       "      <td>0.999085</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>0.999390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>ExtraTrees</td>\n",
       "      <td>23</td>\n",
       "      <td>Gain ratio</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>0.999699</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999710</td>\n",
       "      <td>0.999964</td>\n",
       "      <td>0.999054</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.999382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model  num_features scoring_method  Acc_train  Acc_valid  \\\n",
       "334       XGBoost            49        ReliefF   0.999988   0.999888   \n",
       "114       XGBoost            44     Gain ratio   0.999988   0.999885   \n",
       "224       XGBoost            44             Ï‡Â²   0.999989   0.999870   \n",
       "4         XGBoost            44     Info. gain   0.999989   0.999870   \n",
       "331  RandomForest            49        ReliefF   0.999991   0.999866   \n",
       "221  RandomForest            44             Ï‡Â²   0.999991   0.999859   \n",
       "1    RandomForest            44     Info. gain   0.999991   0.999859   \n",
       "111  RandomForest            44     Gain ratio   0.999991   0.999844   \n",
       "15        XGBoost            22     Info. gain   0.999973   0.999818   \n",
       "246       XGBoost            21             Ï‡Â²   0.999967   0.999814   \n",
       "125       XGBoost            23     Gain ratio   0.999968   0.999814   \n",
       "332    ExtraTrees            49        ReliefF   0.999991   0.999814   \n",
       "26        XGBoost            21     Info. gain   0.999967   0.999814   \n",
       "235       XGBoost            25             Ï‡Â²   0.999973   0.999810   \n",
       "81        XGBoost            16     Info. gain   0.999950   0.999810   \n",
       "70        XGBoost            16     Info. gain   0.999950   0.999810   \n",
       "257       XGBoost            16             Ï‡Â²   0.999967   0.999803   \n",
       "12   RandomForest            22     Info. gain   0.999991   0.999799   \n",
       "232  RandomForest            25             Ï‡Â²   0.999991   0.999799   \n",
       "37        XGBoost            20     Info. gain   0.999968   0.999799   \n",
       "110  DecisionTree            44     Gain ratio   0.999991   0.999795   \n",
       "112    ExtraTrees            44     Gain ratio   0.999991   0.999792   \n",
       "48        XGBoost            19     Info. gain   0.999959   0.999792   \n",
       "136       XGBoost            19     Gain ratio   0.999945   0.999788   \n",
       "222    ExtraTrees            44             Ï‡Â²   0.999991   0.999788   \n",
       "2      ExtraTrees            44     Info. gain   0.999991   0.999788   \n",
       "122  RandomForest            23     Gain ratio   0.999991   0.999784   \n",
       "147       XGBoost            17     Gain ratio   0.999940   0.999784   \n",
       "59        XGBoost            17     Info. gain   0.999940   0.999784   \n",
       "268       XGBoost            13             Ï‡Â²   0.999924   0.999780   \n",
       "92        XGBoost            12     Info. gain   0.999861   0.999777   \n",
       "23   RandomForest            21     Info. gain   0.999990   0.999773   \n",
       "243  RandomForest            21             Ï‡Â²   0.999990   0.999773   \n",
       "330  DecisionTree            49        ReliefF   0.999991   0.999766   \n",
       "133  RandomForest            19     Gain ratio   0.999979   0.999762   \n",
       "0    DecisionTree            44     Info. gain   0.999991   0.999762   \n",
       "220  DecisionTree            44             Ï‡Â²   0.999991   0.999762   \n",
       "34   RandomForest            20     Info. gain   0.999990   0.999762   \n",
       "45   RandomForest            19     Info. gain   0.999979   0.999758   \n",
       "279       XGBoost            12             Ï‡Â²   0.999909   0.999754   \n",
       "78   RandomForest            16     Info. gain   0.999979   0.999751   \n",
       "67   RandomForest            16     Info. gain   0.999979   0.999751   \n",
       "144  RandomForest            17     Gain ratio   0.999979   0.999747   \n",
       "56   RandomForest            17     Info. gain   0.999979   0.999747   \n",
       "276  RandomForest            12             Ï‡Â²   0.999968   0.999747   \n",
       "254  RandomForest            16             Ï‡Â²   0.999990   0.999740   \n",
       "265  RandomForest            13             Ï‡Â²   0.999975   0.999717   \n",
       "233    ExtraTrees            25             Ï‡Â²   0.999991   0.999713   \n",
       "35     ExtraTrees            20     Info. gain   0.999990   0.999702   \n",
       "123    ExtraTrees            23     Gain ratio   0.999991   0.999699   \n",
       "\n",
       "     Precision_train  Precision_valid  Recall_train  Recall_valid  \\\n",
       "334         0.999985         0.999924      0.999964      0.999619   \n",
       "114         0.999980         0.999908      0.999969      0.999619   \n",
       "224         0.999985         0.999878      0.999969      0.999588   \n",
       "4           0.999985         0.999878      0.999969      0.999588   \n",
       "331         0.999990         0.999939      0.999975      0.999512   \n",
       "221         0.999990         0.999908      0.999975      0.999512   \n",
       "1           0.999990         0.999908      0.999975      0.999512   \n",
       "111         0.999990         0.999908      0.999975      0.999451   \n",
       "15          0.999964         0.999802      0.999924      0.999451   \n",
       "246         0.999990         0.999847      0.999873      0.999390   \n",
       "125         0.999975         0.999847      0.999893      0.999390   \n",
       "332         1.000000         0.999771      0.999964      0.999466   \n",
       "26          0.999990         0.999847      0.999873      0.999390   \n",
       "235         0.999969         0.999771      0.999919      0.999451   \n",
       "81          0.999964         0.999847      0.999832      0.999374   \n",
       "70          0.999964         0.999847      0.999832      0.999374   \n",
       "257         0.999990         0.999802      0.999873      0.999390   \n",
       "12          0.999990         0.999908      0.999975      0.999268   \n",
       "232         0.999990         0.999878      0.999975      0.999298   \n",
       "37          0.999985         0.999802      0.999883      0.999374   \n",
       "110         1.000000         0.999542      0.999964      0.999619   \n",
       "112         1.000000         0.999786      0.999964      0.999359   \n",
       "48          0.999985         0.999756      0.999847      0.999390   \n",
       "136         0.999964         0.999756      0.999812      0.999374   \n",
       "222         1.000000         0.999741      0.999964      0.999390   \n",
       "2           1.000000         0.999741      0.999964      0.999390   \n",
       "122         0.999990         0.999878      0.999975      0.999237   \n",
       "147         0.999969         0.999756      0.999786      0.999359   \n",
       "59          0.999969         0.999756      0.999786      0.999359   \n",
       "268         0.999949         0.999817      0.999741      0.999283   \n",
       "92          0.999741         0.999664      0.999690      0.999420   \n",
       "23          0.999990         0.999847      0.999969      0.999222   \n",
       "243         0.999990         0.999847      0.999969      0.999222   \n",
       "330         1.000000         0.999466      0.999964      0.999573   \n",
       "133         0.999980         0.999756      0.999934      0.999268   \n",
       "0           1.000000         0.999405      0.999964      0.999619   \n",
       "220         1.000000         0.999405      0.999964      0.999619   \n",
       "34          0.999990         0.999847      0.999969      0.999176   \n",
       "45          0.999980         0.999802      0.999934      0.999207   \n",
       "279         0.999873         0.999741      0.999756      0.999252   \n",
       "78          0.999980         0.999756      0.999934      0.999222   \n",
       "67          0.999980         0.999756      0.999934      0.999222   \n",
       "144         0.999980         0.999756      0.999934      0.999207   \n",
       "56          0.999980         0.999756      0.999934      0.999207   \n",
       "276         0.999949         0.999741      0.999919      0.999222   \n",
       "254         0.999985         0.999802      0.999975      0.999130   \n",
       "265         0.999980         0.999756      0.999919      0.999085   \n",
       "233         1.000000         0.999664      0.999964      0.999161   \n",
       "35          0.999995         0.999695      0.999964      0.999085   \n",
       "123         1.000000         0.999710      0.999964      0.999054   \n",
       "\n",
       "     F1-score_train  F1-score_valid  \n",
       "334        0.999975        0.999771  \n",
       "114        0.999975        0.999763  \n",
       "224        0.999977        0.999733  \n",
       "4          0.999977        0.999733  \n",
       "331        0.999982        0.999725  \n",
       "221        0.999982        0.999710  \n",
       "1          0.999982        0.999710  \n",
       "111        0.999982        0.999680  \n",
       "15         0.999944        0.999626  \n",
       "246        0.999931        0.999618  \n",
       "125        0.999934        0.999618  \n",
       "332        0.999982        0.999619  \n",
       "26         0.999931        0.999618  \n",
       "235        0.999944        0.999611  \n",
       "81         0.999898        0.999611  \n",
       "70         0.999898        0.999611  \n",
       "257        0.999931        0.999596  \n",
       "12         0.999982        0.999588  \n",
       "232        0.999982        0.999588  \n",
       "37         0.999934        0.999588  \n",
       "110        0.999982        0.999580  \n",
       "112        0.999982        0.999573  \n",
       "48         0.999916        0.999573  \n",
       "136        0.999888        0.999565  \n",
       "222        0.999982        0.999565  \n",
       "2          0.999982        0.999565  \n",
       "122        0.999982        0.999557  \n",
       "147        0.999878        0.999557  \n",
       "59         0.999878        0.999557  \n",
       "268        0.999845        0.999550  \n",
       "92         0.999715        0.999542  \n",
       "23         0.999980        0.999535  \n",
       "243        0.999980        0.999535  \n",
       "330        0.999982        0.999519  \n",
       "133        0.999957        0.999512  \n",
       "0          0.999982        0.999512  \n",
       "220        0.999982        0.999512  \n",
       "34         0.999980        0.999512  \n",
       "45         0.999957        0.999504  \n",
       "279        0.999814        0.999496  \n",
       "78         0.999957        0.999489  \n",
       "67         0.999957        0.999489  \n",
       "144        0.999957        0.999481  \n",
       "56         0.999957        0.999481  \n",
       "276        0.999934        0.999481  \n",
       "254        0.999980        0.999466  \n",
       "265        0.999949        0.999420  \n",
       "233        0.999982        0.999412  \n",
       "35         0.999980        0.999390  \n",
       "123        0.999982        0.999382  "
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sort_values(\"Acc_valid\",ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "ff231873",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(\"kddcup/results/features_selected.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbd7f6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
